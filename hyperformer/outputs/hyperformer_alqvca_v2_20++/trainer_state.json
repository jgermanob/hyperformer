{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 485.45185185185187,
  "global_step": 65536,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.007407407407407408,
      "learning_rate": 6e-07,
      "loss": 4579.236328125,
      "step": 1
    },
    {
      "epoch": 1.4814814814814814,
      "learning_rate": 0.00011999999999999999,
      "loss": 2932.196362672739,
      "step": 200
    },
    {
      "epoch": 2.962962962962963,
      "learning_rate": 0.00023999999999999998,
      "loss": 1941.0815625,
      "step": 400
    },
    {
      "epoch": 4.444444444444445,
      "learning_rate": 0.00029953871701826677,
      "loss": 1779.049375,
      "step": 600
    },
    {
      "epoch": 5.925925925925926,
      "learning_rate": 0.0002986161510548004,
      "loss": 1534.06375,
      "step": 800
    },
    {
      "epoch": 7.407407407407407,
      "learning_rate": 0.000297693585091334,
      "loss": 1474.993125,
      "step": 1000
    },
    {
      "epoch": 8.88888888888889,
      "learning_rate": 0.0002967710191278676,
      "loss": 1489.189375,
      "step": 1200
    },
    {
      "epoch": 10.37037037037037,
      "learning_rate": 0.0002958484531644012,
      "loss": 1488.73125,
      "step": 1400
    },
    {
      "epoch": 11.851851851851851,
      "learning_rate": 0.00029492588720093487,
      "loss": 1427.4075,
      "step": 1600
    },
    {
      "epoch": 13.333333333333334,
      "learning_rate": 0.00029400332123746847,
      "loss": 1404.26875,
      "step": 1800
    },
    {
      "epoch": 14.814814814814815,
      "learning_rate": 0.00029308075527400206,
      "loss": 1335.785,
      "step": 2000
    },
    {
      "epoch": 16.296296296296298,
      "learning_rate": 0.00029215818931053566,
      "loss": 1421.44875,
      "step": 2200
    },
    {
      "epoch": 17.77777777777778,
      "learning_rate": 0.0002912356233470693,
      "loss": 1379.5075,
      "step": 2400
    },
    {
      "epoch": 19.25925925925926,
      "learning_rate": 0.0002903130573836029,
      "loss": 1357.1075,
      "step": 2600
    },
    {
      "epoch": 20.74074074074074,
      "learning_rate": 0.0002893904914201365,
      "loss": 1337.125,
      "step": 2800
    },
    {
      "epoch": 22.22222222222222,
      "learning_rate": 0.0002884679254566701,
      "loss": 1302.77,
      "step": 3000
    },
    {
      "epoch": 23.703703703703702,
      "learning_rate": 0.00028754535949320376,
      "loss": 1386.89,
      "step": 3200
    },
    {
      "epoch": 25.185185185185187,
      "learning_rate": 0.00028662279352973736,
      "loss": 1353.9725,
      "step": 3400
    },
    {
      "epoch": 26.666666666666668,
      "learning_rate": 0.00028570022756627095,
      "loss": 1339.2725,
      "step": 3600
    },
    {
      "epoch": 28.14814814814815,
      "learning_rate": 0.00028477766160280455,
      "loss": 1353.41,
      "step": 3800
    },
    {
      "epoch": 29.62962962962963,
      "learning_rate": 0.0002838550956393382,
      "loss": 1282.3525,
      "step": 4000
    },
    {
      "epoch": 31.11111111111111,
      "learning_rate": 0.0002829325296758718,
      "loss": 1324.95,
      "step": 4200
    },
    {
      "epoch": 32.592592592592595,
      "learning_rate": 0.0002820099637124054,
      "loss": 1348.375,
      "step": 4400
    },
    {
      "epoch": 34.074074074074076,
      "learning_rate": 0.00028108739774893905,
      "loss": 1286.58,
      "step": 4600
    },
    {
      "epoch": 35.55555555555556,
      "learning_rate": 0.0002801648317854726,
      "loss": 1287.9375,
      "step": 4800
    },
    {
      "epoch": 37.03703703703704,
      "learning_rate": 0.00027924226582200625,
      "loss": 1290.335,
      "step": 5000
    },
    {
      "epoch": 38.51851851851852,
      "learning_rate": 0.00027831969985853984,
      "loss": 1289.9575,
      "step": 5200
    },
    {
      "epoch": 40.0,
      "learning_rate": 0.0002773971338950735,
      "loss": 1315.1825,
      "step": 5400
    },
    {
      "epoch": 41.48148148148148,
      "learning_rate": 0.0002764745679316071,
      "loss": 1304.09,
      "step": 5600
    },
    {
      "epoch": 42.96296296296296,
      "learning_rate": 0.0002755520019681407,
      "loss": 1338.11,
      "step": 5800
    },
    {
      "epoch": 44.44444444444444,
      "learning_rate": 0.0002746294360046743,
      "loss": 1347.885,
      "step": 6000
    },
    {
      "epoch": 45.925925925925924,
      "learning_rate": 0.00027370687004120794,
      "loss": 1347.81,
      "step": 6200
    },
    {
      "epoch": 47.407407407407405,
      "learning_rate": 0.00027278430407774154,
      "loss": 1250.68,
      "step": 6400
    },
    {
      "epoch": 48.888888888888886,
      "learning_rate": 0.00027186173811427514,
      "loss": 1305.225,
      "step": 6600
    },
    {
      "epoch": 50.370370370370374,
      "learning_rate": 0.00027093917215080873,
      "loss": 1276.45,
      "step": 6800
    },
    {
      "epoch": 51.851851851851855,
      "learning_rate": 0.0002700166061873424,
      "loss": 1295.695,
      "step": 7000
    },
    {
      "epoch": 53.333333333333336,
      "learning_rate": 0.000269094040223876,
      "loss": 1249.27,
      "step": 7200
    },
    {
      "epoch": 54.81481481481482,
      "learning_rate": 0.0002681714742604096,
      "loss": 1267.11,
      "step": 7400
    },
    {
      "epoch": 56.2962962962963,
      "learning_rate": 0.0002672489082969432,
      "loss": 1255.49,
      "step": 7600
    },
    {
      "epoch": 57.77777777777778,
      "learning_rate": 0.00026632634233347683,
      "loss": 1282.035,
      "step": 7800
    },
    {
      "epoch": 59.25925925925926,
      "learning_rate": 0.00026540377637001043,
      "loss": 1293.765,
      "step": 8000
    },
    {
      "epoch": 60.74074074074074,
      "learning_rate": 0.000264481210406544,
      "loss": 1281.695,
      "step": 8200
    },
    {
      "epoch": 62.22222222222222,
      "learning_rate": 0.0002635586444430776,
      "loss": 1282.215,
      "step": 8400
    },
    {
      "epoch": 63.7037037037037,
      "learning_rate": 0.0002626360784796113,
      "loss": 1265.605,
      "step": 8600
    },
    {
      "epoch": 65.18518518518519,
      "learning_rate": 0.0002617135125161449,
      "loss": 1279.355,
      "step": 8800
    },
    {
      "epoch": 66.66666666666667,
      "learning_rate": 0.0002607909465526785,
      "loss": 1221.005,
      "step": 9000
    },
    {
      "epoch": 68.14814814814815,
      "learning_rate": 0.0002598683805892121,
      "loss": 1302.21,
      "step": 9200
    },
    {
      "epoch": 69.62962962962963,
      "learning_rate": 0.0002589458146257457,
      "loss": 1236.93,
      "step": 9400
    },
    {
      "epoch": 71.11111111111111,
      "learning_rate": 0.0002580232486622793,
      "loss": 1316.405,
      "step": 9600
    },
    {
      "epoch": 72.5925925925926,
      "learning_rate": 0.00025710068269881297,
      "loss": 1313.56,
      "step": 9800
    },
    {
      "epoch": 74.07407407407408,
      "learning_rate": 0.00025617811673534657,
      "loss": 1267.57,
      "step": 10000
    },
    {
      "epoch": 75.55555555555556,
      "learning_rate": 0.00025525555077188017,
      "loss": 1242.885,
      "step": 10200
    },
    {
      "epoch": 77.03703703703704,
      "learning_rate": 0.00025433298480841376,
      "loss": 1236.64,
      "step": 10400
    },
    {
      "epoch": 78.51851851851852,
      "learning_rate": 0.0002534104188449474,
      "loss": 1289.2,
      "step": 10600
    },
    {
      "epoch": 80.0,
      "learning_rate": 0.000252487852881481,
      "loss": 1289.965,
      "step": 10800
    },
    {
      "epoch": 81.48148148148148,
      "learning_rate": 0.0002515652869180146,
      "loss": 1246.865,
      "step": 11000
    },
    {
      "epoch": 82.96296296296296,
      "learning_rate": 0.0002506427209545482,
      "loss": 1278.635,
      "step": 11200
    },
    {
      "epoch": 84.44444444444444,
      "learning_rate": 0.00024972015499108186,
      "loss": 1286.48,
      "step": 11400
    },
    {
      "epoch": 85.92592592592592,
      "learning_rate": 0.00024879758902761546,
      "loss": 1249.135,
      "step": 11600
    },
    {
      "epoch": 87.4074074074074,
      "learning_rate": 0.00024787502306414905,
      "loss": 1277.67,
      "step": 11800
    },
    {
      "epoch": 88.88888888888889,
      "learning_rate": 0.00024695245710068265,
      "loss": 1247.405,
      "step": 12000
    },
    {
      "epoch": 90.37037037037037,
      "learning_rate": 0.00024602989113721625,
      "loss": 1275.47,
      "step": 12200
    },
    {
      "epoch": 91.85185185185185,
      "learning_rate": 0.0002451073251737499,
      "loss": 1233.74,
      "step": 12400
    },
    {
      "epoch": 93.33333333333333,
      "learning_rate": 0.0002441847592102835,
      "loss": 1317.5,
      "step": 12600
    },
    {
      "epoch": 94.81481481481481,
      "learning_rate": 0.00024326219324681712,
      "loss": 1323.25,
      "step": 12800
    },
    {
      "epoch": 96.29629629629629,
      "learning_rate": 0.00024233962728335072,
      "loss": 1266.08,
      "step": 13000
    },
    {
      "epoch": 97.77777777777777,
      "learning_rate": 0.00024141706131988435,
      "loss": 1281.76,
      "step": 13200
    },
    {
      "epoch": 99.25925925925925,
      "learning_rate": 0.00024049449535641794,
      "loss": 1301.91,
      "step": 13400
    },
    {
      "epoch": 100.74074074074075,
      "learning_rate": 0.00023957192939295157,
      "loss": 1220.55,
      "step": 13600
    },
    {
      "epoch": 102.22222222222223,
      "learning_rate": 0.00023864936342948517,
      "loss": 1266.75,
      "step": 13800
    },
    {
      "epoch": 103.70370370370371,
      "learning_rate": 0.0002377267974660188,
      "loss": 1287.66,
      "step": 14000
    },
    {
      "epoch": 105.18518518518519,
      "learning_rate": 0.0002368042315025524,
      "loss": 1291.04,
      "step": 14200
    },
    {
      "epoch": 106.66666666666667,
      "learning_rate": 0.00023588166553908604,
      "loss": 1286.42,
      "step": 14400
    },
    {
      "epoch": 108.14814814814815,
      "learning_rate": 0.0002349590995756196,
      "loss": 1300.76,
      "step": 14600
    },
    {
      "epoch": 109.62962962962963,
      "learning_rate": 0.00023403653361215326,
      "loss": 1303.06,
      "step": 14800
    },
    {
      "epoch": 111.11111111111111,
      "learning_rate": 0.00023311396764868686,
      "loss": 1307.9,
      "step": 15000
    },
    {
      "epoch": 112.5925925925926,
      "learning_rate": 0.00023219140168522049,
      "loss": 1289.33,
      "step": 15200
    },
    {
      "epoch": 114.07407407407408,
      "learning_rate": 0.00023126883572175408,
      "loss": 1222.85,
      "step": 15400
    },
    {
      "epoch": 115.55555555555556,
      "learning_rate": 0.0002303462697582877,
      "loss": 1294.48,
      "step": 15600
    },
    {
      "epoch": 117.03703703703704,
      "learning_rate": 0.0002294237037948213,
      "loss": 1261.16,
      "step": 15800
    },
    {
      "epoch": 118.51851851851852,
      "learning_rate": 0.00022850113783135493,
      "loss": 1253.27,
      "step": 16000
    },
    {
      "epoch": 120.0,
      "learning_rate": 0.00022757857186788853,
      "loss": 1258.5,
      "step": 16200
    },
    {
      "epoch": 121.48148148148148,
      "learning_rate": 0.00022665600590442215,
      "loss": 1278.02,
      "step": 16400
    },
    {
      "epoch": 122.96296296296296,
      "learning_rate": 0.00022573343994095575,
      "loss": 1195.49,
      "step": 16600
    },
    {
      "epoch": 124.44444444444444,
      "learning_rate": 0.00022481087397748938,
      "loss": 1255.35,
      "step": 16800
    },
    {
      "epoch": 125.92592592592592,
      "learning_rate": 0.00022388830801402297,
      "loss": 1311.73,
      "step": 17000
    },
    {
      "epoch": 127.4074074074074,
      "learning_rate": 0.0002229657420505566,
      "loss": 1326.13,
      "step": 17200
    },
    {
      "epoch": 128.88888888888889,
      "learning_rate": 0.0002220431760870902,
      "loss": 1295.94,
      "step": 17400
    },
    {
      "epoch": 130.37037037037038,
      "learning_rate": 0.00022112061012362382,
      "loss": 1249.01,
      "step": 17600
    },
    {
      "epoch": 131.85185185185185,
      "learning_rate": 0.00022019804416015742,
      "loss": 1274.72,
      "step": 17800
    },
    {
      "epoch": 133.33333333333334,
      "learning_rate": 0.00021927547819669104,
      "loss": 1207.69,
      "step": 18000
    },
    {
      "epoch": 134.8148148148148,
      "learning_rate": 0.00021835291223322464,
      "loss": 1228.69,
      "step": 18200
    },
    {
      "epoch": 136.2962962962963,
      "learning_rate": 0.0002174303462697583,
      "loss": 1259.75,
      "step": 18400
    },
    {
      "epoch": 137.77777777777777,
      "learning_rate": 0.0002165077803062919,
      "loss": 1357.57,
      "step": 18600
    },
    {
      "epoch": 139.25925925925927,
      "learning_rate": 0.00021558521434282552,
      "loss": 1294.09,
      "step": 18800
    },
    {
      "epoch": 140.74074074074073,
      "learning_rate": 0.0002146626483793591,
      "loss": 1205.83,
      "step": 19000
    },
    {
      "epoch": 142.22222222222223,
      "learning_rate": 0.00021374008241589274,
      "loss": 1299.59,
      "step": 19200
    },
    {
      "epoch": 143.7037037037037,
      "learning_rate": 0.00021281751645242634,
      "loss": 1354.97,
      "step": 19400
    },
    {
      "epoch": 145.1851851851852,
      "learning_rate": 0.00021189495048895996,
      "loss": 1324.82,
      "step": 19600
    },
    {
      "epoch": 146.66666666666666,
      "learning_rate": 0.00021097238452549356,
      "loss": 1262.81,
      "step": 19800
    },
    {
      "epoch": 148.14814814814815,
      "learning_rate": 0.00021004981856202716,
      "loss": 1344.15,
      "step": 20000
    },
    {
      "epoch": 149.62962962962962,
      "learning_rate": 0.00020912725259856078,
      "loss": 1256.61,
      "step": 20200
    },
    {
      "epoch": 151.11111111111111,
      "learning_rate": 0.00020820468663509438,
      "loss": 1224.9,
      "step": 20400
    },
    {
      "epoch": 152.59259259259258,
      "learning_rate": 0.000207282120671628,
      "loss": 1268.63,
      "step": 20600
    },
    {
      "epoch": 154.07407407407408,
      "learning_rate": 0.0002063595547081616,
      "loss": 1334.55,
      "step": 20800
    },
    {
      "epoch": 155.55555555555554,
      "learning_rate": 0.00020543698874469523,
      "loss": 1280.64,
      "step": 21000
    },
    {
      "epoch": 157.03703703703704,
      "learning_rate": 0.00020451442278122882,
      "loss": 1252.03,
      "step": 21200
    },
    {
      "epoch": 158.5185185185185,
      "learning_rate": 0.00020359185681776245,
      "loss": 1252.23,
      "step": 21400
    },
    {
      "epoch": 160.0,
      "learning_rate": 0.00020266929085429605,
      "loss": 1298.1,
      "step": 21600
    },
    {
      "epoch": 161.4814814814815,
      "learning_rate": 0.00020174672489082967,
      "loss": 1273.17,
      "step": 21800
    },
    {
      "epoch": 162.96296296296296,
      "learning_rate": 0.00020082415892736327,
      "loss": 1219.35,
      "step": 22000
    },
    {
      "epoch": 164.44444444444446,
      "learning_rate": 0.00019990159296389692,
      "loss": 1276.34,
      "step": 22200
    },
    {
      "epoch": 165.92592592592592,
      "learning_rate": 0.0001989790270004305,
      "loss": 1310.57,
      "step": 22400
    },
    {
      "epoch": 167.40740740740742,
      "learning_rate": 0.00019805646103696414,
      "loss": 1302.67,
      "step": 22600
    },
    {
      "epoch": 168.88888888888889,
      "learning_rate": 0.00019713389507349774,
      "loss": 1220.99,
      "step": 22800
    },
    {
      "epoch": 170.37037037037038,
      "learning_rate": 0.00019621132911003136,
      "loss": 1244.28,
      "step": 23000
    },
    {
      "epoch": 171.85185185185185,
      "learning_rate": 0.00019528876314656496,
      "loss": 1285.43,
      "step": 23200
    },
    {
      "epoch": 173.33333333333334,
      "learning_rate": 0.0001943661971830986,
      "loss": 1228.89,
      "step": 23400
    },
    {
      "epoch": 174.8148148148148,
      "learning_rate": 0.00019344363121963218,
      "loss": 1205.43,
      "step": 23600
    },
    {
      "epoch": 176.2962962962963,
      "learning_rate": 0.0001925210652561658,
      "loss": 1261.47,
      "step": 23800
    },
    {
      "epoch": 177.77777777777777,
      "learning_rate": 0.0001915984992926994,
      "loss": 1279.21,
      "step": 24000
    },
    {
      "epoch": 179.25925925925927,
      "learning_rate": 0.00019067593332923303,
      "loss": 1271.61,
      "step": 24200
    },
    {
      "epoch": 180.74074074074073,
      "learning_rate": 0.00018975336736576663,
      "loss": 1281.08,
      "step": 24400
    },
    {
      "epoch": 182.22222222222223,
      "learning_rate": 0.00018883080140230025,
      "loss": 1312.65,
      "step": 24600
    },
    {
      "epoch": 183.7037037037037,
      "learning_rate": 0.00018790823543883385,
      "loss": 1282.74,
      "step": 24800
    },
    {
      "epoch": 185.1851851851852,
      "learning_rate": 0.00018698566947536748,
      "loss": 1195.09,
      "step": 25000
    },
    {
      "epoch": 186.66666666666666,
      "learning_rate": 0.00018606310351190107,
      "loss": 1288.75,
      "step": 25200
    },
    {
      "epoch": 188.14814814814815,
      "learning_rate": 0.0001851405375484347,
      "loss": 1287.32,
      "step": 25400
    },
    {
      "epoch": 189.62962962962962,
      "learning_rate": 0.0001842179715849683,
      "loss": 1309.18,
      "step": 25600
    },
    {
      "epoch": 191.11111111111111,
      "learning_rate": 0.00018329540562150192,
      "loss": 1283.92,
      "step": 25800
    },
    {
      "epoch": 192.59259259259258,
      "learning_rate": 0.00018237283965803552,
      "loss": 1312.26,
      "step": 26000
    },
    {
      "epoch": 194.07407407407408,
      "learning_rate": 0.00018145027369456917,
      "loss": 1232.5,
      "step": 26200
    },
    {
      "epoch": 195.55555555555554,
      "learning_rate": 0.00018052770773110277,
      "loss": 1265.14,
      "step": 26400
    },
    {
      "epoch": 197.03703703703704,
      "learning_rate": 0.0001796051417676364,
      "loss": 1217.94,
      "step": 26600
    },
    {
      "epoch": 198.5185185185185,
      "learning_rate": 0.00017868257580417,
      "loss": 1249.5,
      "step": 26800
    },
    {
      "epoch": 200.0,
      "learning_rate": 0.00017776000984070362,
      "loss": 1332.24,
      "step": 27000
    },
    {
      "epoch": 201.4814814814815,
      "learning_rate": 0.0001768374438772372,
      "loss": 1272.22,
      "step": 27200
    },
    {
      "epoch": 202.96296296296296,
      "learning_rate": 0.00017591487791377084,
      "loss": 1260.92,
      "step": 27400
    },
    {
      "epoch": 204.44444444444446,
      "learning_rate": 0.00017499231195030444,
      "loss": 1251.32,
      "step": 27600
    },
    {
      "epoch": 205.92592592592592,
      "learning_rate": 0.00017406974598683803,
      "loss": 1222.98,
      "step": 27800
    },
    {
      "epoch": 207.40740740740742,
      "learning_rate": 0.00017314718002337166,
      "loss": 1285.94,
      "step": 28000
    },
    {
      "epoch": 208.88888888888889,
      "learning_rate": 0.00017222461405990526,
      "loss": 1251.98,
      "step": 28200
    },
    {
      "epoch": 210.37037037037038,
      "learning_rate": 0.00017130204809643888,
      "loss": 1223.5,
      "step": 28400
    },
    {
      "epoch": 211.85185185185185,
      "learning_rate": 0.00017037948213297248,
      "loss": 1243.28,
      "step": 28600
    },
    {
      "epoch": 213.33333333333334,
      "learning_rate": 0.0001694569161695061,
      "loss": 1250.84,
      "step": 28800
    },
    {
      "epoch": 214.8148148148148,
      "learning_rate": 0.0001685343502060397,
      "loss": 1276.58,
      "step": 29000
    },
    {
      "epoch": 216.2962962962963,
      "learning_rate": 0.00016761178424257333,
      "loss": 1254.42,
      "step": 29200
    },
    {
      "epoch": 217.77777777777777,
      "learning_rate": 0.00016668921827910692,
      "loss": 1257.32,
      "step": 29400
    },
    {
      "epoch": 219.25925925925927,
      "learning_rate": 0.00016576665231564055,
      "loss": 1239.42,
      "step": 29600
    },
    {
      "epoch": 220.74074074074073,
      "learning_rate": 0.00016484408635217415,
      "loss": 1244.64,
      "step": 29800
    },
    {
      "epoch": 222.22222222222223,
      "learning_rate": 0.00016392152038870777,
      "loss": 1245.92,
      "step": 30000
    },
    {
      "epoch": 223.7037037037037,
      "learning_rate": 0.00016299895442524137,
      "loss": 1228.8,
      "step": 30200
    },
    {
      "epoch": 225.1851851851852,
      "learning_rate": 0.00016207638846177502,
      "loss": 1306.66,
      "step": 30400
    },
    {
      "epoch": 226.66666666666666,
      "learning_rate": 0.00016115382249830862,
      "loss": 1223.38,
      "step": 30600
    },
    {
      "epoch": 228.14814814814815,
      "learning_rate": 0.00016023125653484224,
      "loss": 1270.34,
      "step": 30800
    },
    {
      "epoch": 229.62962962962962,
      "learning_rate": 0.00015930869057137584,
      "loss": 1240.32,
      "step": 31000
    },
    {
      "epoch": 231.11111111111111,
      "learning_rate": 0.00015838612460790946,
      "loss": 1351.18,
      "step": 31200
    },
    {
      "epoch": 232.59259259259258,
      "learning_rate": 0.00015746355864444306,
      "loss": 1178.9,
      "step": 31400
    },
    {
      "epoch": 234.07407407407408,
      "learning_rate": 0.0001565409926809767,
      "loss": 1257.6,
      "step": 31600
    },
    {
      "epoch": 235.55555555555554,
      "learning_rate": 0.00015561842671751028,
      "loss": 1262.44,
      "step": 31800
    },
    {
      "epoch": 237.03703703703704,
      "learning_rate": 0.0001546958607540439,
      "loss": 1298.54,
      "step": 32000
    },
    {
      "epoch": 238.5185185185185,
      "learning_rate": 0.0001537732947905775,
      "loss": 1309.92,
      "step": 32200
    },
    {
      "epoch": 240.0,
      "learning_rate": 0.00015285072882711113,
      "loss": 1234.52,
      "step": 32400
    },
    {
      "epoch": 241.4814814814815,
      "learning_rate": 0.00015192816286364473,
      "loss": 1241.9,
      "step": 32600
    },
    {
      "epoch": 242.96296296296296,
      "learning_rate": 0.00015100559690017835,
      "loss": 1290.42,
      "step": 32800
    },
    {
      "epoch": 244.44444444444446,
      "learning_rate": 0.00015008303093671195,
      "loss": 1325.6,
      "step": 33000
    },
    {
      "epoch": 245.92592592592592,
      "learning_rate": 0.00014916046497324558,
      "loss": 1307.68,
      "step": 33200
    },
    {
      "epoch": 247.40740740740742,
      "learning_rate": 0.00014823789900977917,
      "loss": 1256.04,
      "step": 33400
    },
    {
      "epoch": 248.88888888888889,
      "learning_rate": 0.0001473153330463128,
      "loss": 1218.84,
      "step": 33600
    },
    {
      "epoch": 250.37037037037038,
      "learning_rate": 0.0001463927670828464,
      "loss": 1188.34,
      "step": 33800
    },
    {
      "epoch": 251.85185185185185,
      "learning_rate": 0.00014547020111938002,
      "loss": 1333.22,
      "step": 34000
    },
    {
      "epoch": 253.33333333333334,
      "learning_rate": 0.00014454763515591362,
      "loss": 1265.84,
      "step": 34200
    },
    {
      "epoch": 254.8148148148148,
      "learning_rate": 0.00014362506919244724,
      "loss": 1278.98,
      "step": 34400
    },
    {
      "epoch": 256.2962962962963,
      "learning_rate": 0.00014270250322898087,
      "loss": 1250.16,
      "step": 34600
    },
    {
      "epoch": 257.77777777777777,
      "learning_rate": 0.00014177993726551447,
      "loss": 1254.2,
      "step": 34800
    },
    {
      "epoch": 259.25925925925924,
      "learning_rate": 0.0001408573713020481,
      "loss": 1286.56,
      "step": 35000
    },
    {
      "epoch": 260.74074074074076,
      "learning_rate": 0.0001399348053385817,
      "loss": 1246.68,
      "step": 35200
    },
    {
      "epoch": 262.22222222222223,
      "learning_rate": 0.00013901223937511531,
      "loss": 1278.56,
      "step": 35400
    },
    {
      "epoch": 263.7037037037037,
      "learning_rate": 0.0001380896734116489,
      "loss": 1263.02,
      "step": 35600
    },
    {
      "epoch": 265.18518518518516,
      "learning_rate": 0.00013716710744818254,
      "loss": 1293.32,
      "step": 35800
    },
    {
      "epoch": 266.6666666666667,
      "learning_rate": 0.00013624454148471613,
      "loss": 1257.62,
      "step": 36000
    },
    {
      "epoch": 268.14814814814815,
      "learning_rate": 0.00013532197552124976,
      "loss": 1252.88,
      "step": 36200
    },
    {
      "epoch": 269.6296296296296,
      "learning_rate": 0.00013439940955778338,
      "loss": 1258.32,
      "step": 36400
    },
    {
      "epoch": 271.1111111111111,
      "learning_rate": 0.00013347684359431698,
      "loss": 1254.6,
      "step": 36600
    },
    {
      "epoch": 272.5925925925926,
      "learning_rate": 0.0001325542776308506,
      "loss": 1322.4,
      "step": 36800
    },
    {
      "epoch": 274.0740740740741,
      "learning_rate": 0.0001316317116673842,
      "loss": 1234.76,
      "step": 37000
    },
    {
      "epoch": 275.55555555555554,
      "learning_rate": 0.00013070914570391783,
      "loss": 1195.34,
      "step": 37200
    },
    {
      "epoch": 277.037037037037,
      "learning_rate": 0.00012978657974045143,
      "loss": 1264.54,
      "step": 37400
    },
    {
      "epoch": 278.51851851851853,
      "learning_rate": 0.00012886401377698505,
      "loss": 1259.78,
      "step": 37600
    },
    {
      "epoch": 280.0,
      "learning_rate": 0.00012794144781351865,
      "loss": 1272.08,
      "step": 37800
    },
    {
      "epoch": 281.48148148148147,
      "learning_rate": 0.00012701888185005227,
      "loss": 1306.4,
      "step": 38000
    },
    {
      "epoch": 282.962962962963,
      "learning_rate": 0.0001260963158865859,
      "loss": 1318.46,
      "step": 38200
    },
    {
      "epoch": 284.44444444444446,
      "learning_rate": 0.0001251737499231195,
      "loss": 1314.16,
      "step": 38400
    },
    {
      "epoch": 285.9259259259259,
      "learning_rate": 0.00012425118395965312,
      "loss": 1240.46,
      "step": 38600
    },
    {
      "epoch": 287.4074074074074,
      "learning_rate": 0.00012332861799618672,
      "loss": 1196.6,
      "step": 38800
    },
    {
      "epoch": 288.8888888888889,
      "learning_rate": 0.00012240605203272034,
      "loss": 1286.76,
      "step": 39000
    },
    {
      "epoch": 290.3703703703704,
      "learning_rate": 0.00012148348606925395,
      "loss": 1235.12,
      "step": 39200
    },
    {
      "epoch": 291.85185185185185,
      "learning_rate": 0.00012056092010578755,
      "loss": 1323.68,
      "step": 39400
    },
    {
      "epoch": 293.3333333333333,
      "learning_rate": 0.00011963835414232116,
      "loss": 1285.72,
      "step": 39600
    },
    {
      "epoch": 294.81481481481484,
      "learning_rate": 0.00011871578817885477,
      "loss": 1282.18,
      "step": 39800
    },
    {
      "epoch": 296.2962962962963,
      "learning_rate": 0.00011779322221538839,
      "loss": 1227.42,
      "step": 40000
    },
    {
      "epoch": 297.77777777777777,
      "learning_rate": 0.000116870656251922,
      "loss": 1214.52,
      "step": 40200
    },
    {
      "epoch": 299.25925925925924,
      "learning_rate": 0.00011594809028845561,
      "loss": 1265.46,
      "step": 40400
    },
    {
      "epoch": 300.74074074074076,
      "learning_rate": 0.00011502552432498922,
      "loss": 1283.58,
      "step": 40600
    },
    {
      "epoch": 302.22222222222223,
      "learning_rate": 0.00011410295836152283,
      "loss": 1267.44,
      "step": 40800
    },
    {
      "epoch": 303.7037037037037,
      "learning_rate": 0.00011318039239805644,
      "loss": 1263.62,
      "step": 41000
    },
    {
      "epoch": 305.18518518518516,
      "learning_rate": 0.00011225782643459005,
      "loss": 1249.64,
      "step": 41200
    },
    {
      "epoch": 306.6666666666667,
      "learning_rate": 0.00011133526047112368,
      "loss": 1254.24,
      "step": 41400
    },
    {
      "epoch": 308.14814814814815,
      "learning_rate": 0.00011041269450765729,
      "loss": 1270.94,
      "step": 41600
    },
    {
      "epoch": 309.6296296296296,
      "learning_rate": 0.0001094901285441909,
      "loss": 1246.92,
      "step": 41800
    },
    {
      "epoch": 311.1111111111111,
      "learning_rate": 0.00010856756258072451,
      "loss": 1280.48,
      "step": 42000
    },
    {
      "epoch": 312.5925925925926,
      "learning_rate": 0.00010764499661725812,
      "loss": 1276.94,
      "step": 42200
    },
    {
      "epoch": 314.0740740740741,
      "learning_rate": 0.00010672243065379173,
      "loss": 1277.98,
      "step": 42400
    },
    {
      "epoch": 315.55555555555554,
      "learning_rate": 0.00010579986469032534,
      "loss": 1197.64,
      "step": 42600
    },
    {
      "epoch": 317.037037037037,
      "learning_rate": 0.00010487729872685896,
      "loss": 1265.14,
      "step": 42800
    },
    {
      "epoch": 318.51851851851853,
      "learning_rate": 0.00010395473276339257,
      "loss": 1261.18,
      "step": 43000
    },
    {
      "epoch": 320.0,
      "learning_rate": 0.00010303216679992619,
      "loss": 1263.28,
      "step": 43200
    },
    {
      "epoch": 321.48148148148147,
      "learning_rate": 0.0001021096008364598,
      "loss": 1259.42,
      "step": 43400
    },
    {
      "epoch": 322.962962962963,
      "learning_rate": 0.00010118703487299341,
      "loss": 1224.3,
      "step": 43600
    },
    {
      "epoch": 324.44444444444446,
      "learning_rate": 0.00010026446890952703,
      "loss": 1285.74,
      "step": 43800
    },
    {
      "epoch": 325.9259259259259,
      "learning_rate": 9.934190294606064e-05,
      "loss": 1254.46,
      "step": 44000
    },
    {
      "epoch": 327.4074074074074,
      "learning_rate": 9.841933698259425e-05,
      "loss": 1300.12,
      "step": 44200
    },
    {
      "epoch": 328.8888888888889,
      "learning_rate": 9.749677101912786e-05,
      "loss": 1296.0,
      "step": 44400
    },
    {
      "epoch": 330.3703703703704,
      "learning_rate": 9.657420505566147e-05,
      "loss": 1253.68,
      "step": 44600
    },
    {
      "epoch": 331.85185185185185,
      "learning_rate": 9.565163909219508e-05,
      "loss": 1282.28,
      "step": 44800
    },
    {
      "epoch": 333.3333333333333,
      "learning_rate": 9.472907312872869e-05,
      "loss": 1259.66,
      "step": 45000
    },
    {
      "epoch": 334.81481481481484,
      "learning_rate": 9.380650716526232e-05,
      "loss": 1280.76,
      "step": 45200
    },
    {
      "epoch": 336.2962962962963,
      "learning_rate": 9.288394120179593e-05,
      "loss": 1288.68,
      "step": 45400
    },
    {
      "epoch": 337.77777777777777,
      "learning_rate": 9.196137523832954e-05,
      "loss": 1230.32,
      "step": 45600
    },
    {
      "epoch": 339.25925925925924,
      "learning_rate": 9.103880927486315e-05,
      "loss": 1257.1,
      "step": 45800
    },
    {
      "epoch": 340.74074074074076,
      "learning_rate": 9.011624331139676e-05,
      "loss": 1212.18,
      "step": 46000
    },
    {
      "epoch": 342.22222222222223,
      "learning_rate": 8.919367734793037e-05,
      "loss": 1281.0,
      "step": 46200
    },
    {
      "epoch": 343.7037037037037,
      "learning_rate": 8.827111138446399e-05,
      "loss": 1312.46,
      "step": 46400
    },
    {
      "epoch": 345.18518518518516,
      "learning_rate": 8.73485454209976e-05,
      "loss": 1269.34,
      "step": 46600
    },
    {
      "epoch": 346.6666666666667,
      "learning_rate": 8.642597945753121e-05,
      "loss": 1216.06,
      "step": 46800
    },
    {
      "epoch": 348.14814814814815,
      "learning_rate": 8.550341349406483e-05,
      "loss": 1182.1,
      "step": 47000
    },
    {
      "epoch": 349.6296296296296,
      "learning_rate": 8.458084753059842e-05,
      "loss": 1258.44,
      "step": 47200
    },
    {
      "epoch": 351.1111111111111,
      "learning_rate": 8.365828156713204e-05,
      "loss": 1232.52,
      "step": 47400
    },
    {
      "epoch": 352.5925925925926,
      "learning_rate": 8.273571560366565e-05,
      "loss": 1267.58,
      "step": 47600
    },
    {
      "epoch": 354.0740740740741,
      "learning_rate": 8.181314964019926e-05,
      "loss": 1232.72,
      "step": 47800
    },
    {
      "epoch": 355.55555555555554,
      "learning_rate": 8.089058367673287e-05,
      "loss": 1226.96,
      "step": 48000
    },
    {
      "epoch": 357.037037037037,
      "learning_rate": 7.996801771326649e-05,
      "loss": 1275.96,
      "step": 48200
    },
    {
      "epoch": 358.51851851851853,
      "learning_rate": 7.90454517498001e-05,
      "loss": 1241.06,
      "step": 48400
    },
    {
      "epoch": 360.0,
      "learning_rate": 7.812288578633371e-05,
      "loss": 1275.04,
      "step": 48600
    },
    {
      "epoch": 361.48148148148147,
      "learning_rate": 7.720031982286732e-05,
      "loss": 1266.84,
      "step": 48800
    },
    {
      "epoch": 362.962962962963,
      "learning_rate": 7.627775385940093e-05,
      "loss": 1238.8,
      "step": 49000
    },
    {
      "epoch": 364.44444444444446,
      "learning_rate": 7.535518789593456e-05,
      "loss": 1265.76,
      "step": 49200
    },
    {
      "epoch": 365.9259259259259,
      "learning_rate": 7.443262193246817e-05,
      "loss": 1265.4,
      "step": 49400
    },
    {
      "epoch": 367.4074074074074,
      "learning_rate": 7.351005596900178e-05,
      "loss": 1358.62,
      "step": 49600
    },
    {
      "epoch": 368.8888888888889,
      "learning_rate": 7.258749000553539e-05,
      "loss": 1265.88,
      "step": 49800
    },
    {
      "epoch": 370.3703703703704,
      "learning_rate": 7.1664924042069e-05,
      "loss": 1297.4,
      "step": 50000
    },
    {
      "epoch": 371.85185185185185,
      "learning_rate": 7.074235807860261e-05,
      "loss": 1257.44,
      "step": 50200
    },
    {
      "epoch": 373.3333333333333,
      "learning_rate": 6.981979211513622e-05,
      "loss": 1259.42,
      "step": 50400
    },
    {
      "epoch": 374.81481481481484,
      "learning_rate": 6.889722615166983e-05,
      "loss": 1220.7,
      "step": 50600
    },
    {
      "epoch": 376.2962962962963,
      "learning_rate": 6.797466018820345e-05,
      "loss": 1279.18,
      "step": 50800
    },
    {
      "epoch": 377.77777777777777,
      "learning_rate": 6.705209422473706e-05,
      "loss": 1196.88,
      "step": 51000
    },
    {
      "epoch": 379.25925925925924,
      "learning_rate": 6.612952826127068e-05,
      "loss": 1257.24,
      "step": 51200
    },
    {
      "epoch": 380.74074074074076,
      "learning_rate": 6.520696229780429e-05,
      "loss": 1293.36,
      "step": 51400
    },
    {
      "epoch": 382.22222222222223,
      "learning_rate": 6.42843963343379e-05,
      "loss": 1236.26,
      "step": 51600
    },
    {
      "epoch": 383.7037037037037,
      "learning_rate": 6.336183037087151e-05,
      "loss": 1233.14,
      "step": 51800
    },
    {
      "epoch": 385.18518518518516,
      "learning_rate": 6.243926440740513e-05,
      "loss": 1261.82,
      "step": 52000
    },
    {
      "epoch": 386.6666666666667,
      "learning_rate": 6.151669844393874e-05,
      "loss": 1273.62,
      "step": 52200
    },
    {
      "epoch": 388.14814814814815,
      "learning_rate": 6.059413248047235e-05,
      "loss": 1328.2,
      "step": 52400
    },
    {
      "epoch": 389.6296296296296,
      "learning_rate": 5.967156651700597e-05,
      "loss": 1321.64,
      "step": 52600
    },
    {
      "epoch": 391.1111111111111,
      "learning_rate": 5.874900055353958e-05,
      "loss": 1255.88,
      "step": 52800
    },
    {
      "epoch": 392.5925925925926,
      "learning_rate": 5.782643459007318e-05,
      "loss": 1247.24,
      "step": 53000
    },
    {
      "epoch": 394.0740740740741,
      "learning_rate": 5.6903868626606793e-05,
      "loss": 1262.16,
      "step": 53200
    },
    {
      "epoch": 395.55555555555554,
      "learning_rate": 5.5981302663140405e-05,
      "loss": 1261.08,
      "step": 53400
    },
    {
      "epoch": 397.037037037037,
      "learning_rate": 5.5058736699674016e-05,
      "loss": 1250.52,
      "step": 53600
    },
    {
      "epoch": 398.51851851851853,
      "learning_rate": 5.4136170736207634e-05,
      "loss": 1313.0,
      "step": 53800
    },
    {
      "epoch": 400.0,
      "learning_rate": 5.3213604772741245e-05,
      "loss": 1306.36,
      "step": 54000
    },
    {
      "epoch": 401.48148148148147,
      "learning_rate": 5.2291038809274856e-05,
      "loss": 1231.44,
      "step": 54200
    },
    {
      "epoch": 402.962962962963,
      "learning_rate": 5.136847284580847e-05,
      "loss": 1269.2,
      "step": 54400
    },
    {
      "epoch": 404.44444444444446,
      "learning_rate": 5.0445906882342086e-05,
      "loss": 1206.76,
      "step": 54600
    },
    {
      "epoch": 405.9259259259259,
      "learning_rate": 4.95233409188757e-05,
      "loss": 1268.56,
      "step": 54800
    },
    {
      "epoch": 407.4074074074074,
      "learning_rate": 4.860077495540931e-05,
      "loss": 1241.4,
      "step": 55000
    },
    {
      "epoch": 408.8888888888889,
      "learning_rate": 4.767820899194292e-05,
      "loss": 1286.04,
      "step": 55200
    },
    {
      "epoch": 410.3703703703704,
      "learning_rate": 4.675564302847653e-05,
      "loss": 1244.92,
      "step": 55400
    },
    {
      "epoch": 411.85185185185185,
      "learning_rate": 4.583307706501015e-05,
      "loss": 1222.8,
      "step": 55600
    },
    {
      "epoch": 413.3333333333333,
      "learning_rate": 4.491051110154376e-05,
      "loss": 1213.64,
      "step": 55800
    },
    {
      "epoch": 414.81481481481484,
      "learning_rate": 4.398794513807737e-05,
      "loss": 1257.24,
      "step": 56000
    },
    {
      "epoch": 416.2962962962963,
      "learning_rate": 4.306537917461098e-05,
      "loss": 1263.68,
      "step": 56200
    },
    {
      "epoch": 417.77777777777777,
      "learning_rate": 4.214281321114459e-05,
      "loss": 1218.04,
      "step": 56400
    },
    {
      "epoch": 419.25925925925924,
      "learning_rate": 4.122024724767821e-05,
      "loss": 1300.76,
      "step": 56600
    },
    {
      "epoch": 420.74074074074076,
      "learning_rate": 4.0297681284211816e-05,
      "loss": 1333.64,
      "step": 56800
    },
    {
      "epoch": 422.22222222222223,
      "learning_rate": 3.937511532074543e-05,
      "loss": 1338.08,
      "step": 57000
    },
    {
      "epoch": 423.7037037037037,
      "learning_rate": 3.845254935727904e-05,
      "loss": 1261.44,
      "step": 57200
    },
    {
      "epoch": 425.18518518518516,
      "learning_rate": 3.752998339381265e-05,
      "loss": 1245.76,
      "step": 57400
    },
    {
      "epoch": 426.6666666666667,
      "learning_rate": 3.660741743034627e-05,
      "loss": 1266.16,
      "step": 57600
    },
    {
      "epoch": 428.14814814814815,
      "learning_rate": 3.568485146687988e-05,
      "loss": 1219.72,
      "step": 57800
    },
    {
      "epoch": 429.6296296296296,
      "learning_rate": 3.476228550341349e-05,
      "loss": 1241.2,
      "step": 58000
    },
    {
      "epoch": 431.1111111111111,
      "learning_rate": 3.38397195399471e-05,
      "loss": 1223.84,
      "step": 58200
    },
    {
      "epoch": 432.5925925925926,
      "learning_rate": 3.291715357648071e-05,
      "loss": 1318.88,
      "step": 58400
    },
    {
      "epoch": 434.0740740740741,
      "learning_rate": 3.199458761301433e-05,
      "loss": 1271.64,
      "step": 58600
    },
    {
      "epoch": 435.55555555555554,
      "learning_rate": 3.107202164954794e-05,
      "loss": 1285.04,
      "step": 58800
    },
    {
      "epoch": 437.037037037037,
      "learning_rate": 3.0149455686081553e-05,
      "loss": 1264.96,
      "step": 59000
    },
    {
      "epoch": 438.51851851851853,
      "learning_rate": 2.9226889722615164e-05,
      "loss": 1262.12,
      "step": 59200
    },
    {
      "epoch": 440.0,
      "learning_rate": 2.830432375914878e-05,
      "loss": 1300.32,
      "step": 59400
    },
    {
      "epoch": 441.48148148148147,
      "learning_rate": 2.738175779568239e-05,
      "loss": 1244.88,
      "step": 59600
    },
    {
      "epoch": 442.962962962963,
      "learning_rate": 2.6459191832216e-05,
      "loss": 1273.64,
      "step": 59800
    },
    {
      "epoch": 444.44444444444446,
      "learning_rate": 2.5536625868749612e-05,
      "loss": 1237.84,
      "step": 60000
    },
    {
      "epoch": 445.9259259259259,
      "learning_rate": 2.4614059905283223e-05,
      "loss": 1263.28,
      "step": 60200
    },
    {
      "epoch": 447.4074074074074,
      "learning_rate": 2.3691493941816838e-05,
      "loss": 1243.76,
      "step": 60400
    },
    {
      "epoch": 448.8888888888889,
      "learning_rate": 2.276892797835045e-05,
      "loss": 1283.2,
      "step": 60600
    },
    {
      "epoch": 450.3703703703704,
      "learning_rate": 2.1846362014884064e-05,
      "loss": 1258.32,
      "step": 60800
    },
    {
      "epoch": 451.85185185185185,
      "learning_rate": 2.0923796051417675e-05,
      "loss": 1222.36,
      "step": 61000
    },
    {
      "epoch": 453.3333333333333,
      "learning_rate": 2.000123008795129e-05,
      "loss": 1269.28,
      "step": 61200
    },
    {
      "epoch": 454.81481481481484,
      "learning_rate": 1.90786641244849e-05,
      "loss": 1211.92,
      "step": 61400
    },
    {
      "epoch": 456.2962962962963,
      "learning_rate": 1.8156098161018512e-05,
      "loss": 1272.24,
      "step": 61600
    },
    {
      "epoch": 457.77777777777777,
      "learning_rate": 1.7233532197552123e-05,
      "loss": 1230.16,
      "step": 61800
    },
    {
      "epoch": 459.25925925925924,
      "learning_rate": 1.6310966234085738e-05,
      "loss": 1216.16,
      "step": 62000
    },
    {
      "epoch": 460.74074074074076,
      "learning_rate": 1.5388400270619346e-05,
      "loss": 1277.56,
      "step": 62200
    },
    {
      "epoch": 462.22222222222223,
      "learning_rate": 1.446583430715296e-05,
      "loss": 1355.64,
      "step": 62400
    },
    {
      "epoch": 463.7037037037037,
      "learning_rate": 1.3543268343686573e-05,
      "loss": 1286.64,
      "step": 62600
    },
    {
      "epoch": 465.18518518518516,
      "learning_rate": 1.2620702380220184e-05,
      "loss": 1283.96,
      "step": 62800
    },
    {
      "epoch": 466.6666666666667,
      "learning_rate": 1.1698136416753797e-05,
      "loss": 1277.72,
      "step": 63000
    },
    {
      "epoch": 468.14814814814815,
      "learning_rate": 1.0775570453287409e-05,
      "loss": 1255.68,
      "step": 63200
    },
    {
      "epoch": 469.6296296296296,
      "learning_rate": 9.853004489821021e-06,
      "loss": 1276.88,
      "step": 63400
    },
    {
      "epoch": 471.1111111111111,
      "learning_rate": 8.930438526354634e-06,
      "loss": 1263.36,
      "step": 63600
    },
    {
      "epoch": 472.5925925925926,
      "learning_rate": 8.007872562888246e-06,
      "loss": 1283.56,
      "step": 63800
    },
    {
      "epoch": 474.0740740740741,
      "learning_rate": 7.085306599421858e-06,
      "loss": 1225.52,
      "step": 64000
    },
    {
      "epoch": 475.55555555555554,
      "learning_rate": 6.1627406359554705e-06,
      "loss": 1252.88,
      "step": 64200
    },
    {
      "epoch": 477.037037037037,
      "learning_rate": 5.240174672489083e-06,
      "loss": 1199.48,
      "step": 64400
    },
    {
      "epoch": 478.51851851851853,
      "learning_rate": 4.317608709022695e-06,
      "loss": 1295.2,
      "step": 64600
    },
    {
      "epoch": 480.0,
      "learning_rate": 3.395042745556307e-06,
      "loss": 1279.24,
      "step": 64800
    },
    {
      "epoch": 481.48148148148147,
      "learning_rate": 2.4724767820899192e-06,
      "loss": 1282.76,
      "step": 65000
    },
    {
      "epoch": 482.962962962963,
      "learning_rate": 1.5499108186235313e-06,
      "loss": 1202.36,
      "step": 65200
    },
    {
      "epoch": 484.44444444444446,
      "learning_rate": 6.273448551571438e-07,
      "loss": 1289.64,
      "step": 65400
    },
    {
      "epoch": 485.45185185185187,
      "step": 65536
    }
  ],
  "max_steps": 65536,
  "num_train_epochs": 486,
  "total_flos": 1208102946451928064,
  "trial_name": null,
  "trial_params": null
}
