05/24/2024 22:14:16 - WARNING - __main__ -   Process rank: 3, device: cuda:3, n_gpu: 1, distributed training: True, 16-bits training: False
05/24/2024 22:14:16 - WARNING - __main__ -   Process rank: 1, device: cuda:1, n_gpu: 1, distributed training: True, 16-bits training: False
05/24/2024 22:14:16 - WARNING - __main__ -   Process rank: 2, device: cuda:2, n_gpu: 1, distributed training: True, 16-bits training: False
05/24/2024 22:14:16 - WARNING - __main__ -   Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: True, 16-bits training: False
05/24/2024 22:14:16 - INFO - __main__ -   Training/evaluation parameters Seq2SeqTrainingArguments(output_dir='outputs/hyperformer_al++/', overwrite_output_dir=True, do_train=True, do_eval=True, do_predict=False, evaluate_during_training=False, evaluation_strategy=<EvaluationStrategy.STEPS: 'steps'>, prediction_loss_only=False, per_device_train_batch_size=32, per_device_eval_batch_size=32, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=0.0003, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100, max_steps=65536, warmup_steps=500, logging_dir='runs/May24_22-14-10_gpu-16', logging_first_step=True, logging_steps=200, save_steps=1000, save_total_limit=1, no_cuda=False, seed=42, fp16=False, fp16_opt_level='O1', local_rank=0, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=1000, dataloader_num_workers=0, past_index=-1, run_name='outputs/hyperformer_al++/', disable_tqdm=True, remove_unused_columns=True, label_names=None, load_best_model_at_end=True, metric_for_best_model='average_metrics', greater_is_better=True, label_smoothing=0.1, predict_with_generate=True, adafactor=False, encoder_layerdrop=None, decoder_layerdrop=None, dropout=None, attention_dropout=None, lr_scheduler='linear', temperature=10, train_adapters=True, do_test=True, eval_output_dir=None, generate_classifier_weights=False, optimize_from_scratch=False, optimize_from_scratch_with_loading_model=False, split_validation_test=True, print_num_parameters=True, compute_memory=False, compute_time=False)
05/24/2024 22:14:17 - WARNING - __main__ -   model path loaded from : t5-base
05/24/2024 22:14:17 - WARNING - __main__ -   model path loaded from : t5-base
05/24/2024 22:14:17 - WARNING - __main__ -   model path loaded from : t5-base
05/24/2024 22:14:18 - WARNING - __main__ -   model path loaded from : t5-base
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
Some weights of the model checkpoint at t5-base were not used when initializing T5ForConditionalGeneration: ['encoder.block.0.layer.0.SelfAttention.q.weight', 'encoder.block.0.layer.0.SelfAttention.v.weight', 'encoder.block.1.layer.0.SelfAttention.q.weight', 'encoder.block.1.layer.0.SelfAttention.v.weight', 'encoder.block.2.layer.0.SelfAttention.q.weight', 'encoder.block.2.layer.0.SelfAttention.v.weight', 'encoder.block.3.layer.0.SelfAttention.q.weight', 'encoder.block.3.layer.0.SelfAttention.v.weight', 'encoder.block.4.layer.0.SelfAttention.q.weight', 'encoder.block.4.layer.0.SelfAttention.v.weight', 'encoder.block.5.layer.0.SelfAttention.q.weight', 'encoder.block.5.layer.0.SelfAttention.v.weight', 'encoder.block.6.layer.0.SelfAttention.q.weight', 'encoder.block.6.layer.0.SelfAttention.v.weight', 'encoder.block.7.layer.0.SelfAttention.q.weight', 'encoder.block.7.layer.0.SelfAttention.v.weight', 'encoder.block.8.layer.0.SelfAttention.q.weight', 'encoder.block.8.layer.0.SelfAttention.v.weight', 'encoder.block.9.layer.0.SelfAttention.q.weight', 'encoder.block.9.layer.0.SelfAttention.v.weight', 'encoder.block.10.layer.0.SelfAttention.q.weight', 'encoder.block.10.layer.0.SelfAttention.v.weight', 'encoder.block.11.layer.0.SelfAttention.q.weight', 'encoder.block.11.layer.0.SelfAttention.v.weight', 'decoder.block.0.layer.0.SelfAttention.q.weight', 'decoder.block.0.layer.0.SelfAttention.v.weight', 'decoder.block.1.layer.0.SelfAttention.q.weight', 'decoder.block.1.layer.0.SelfAttention.v.weight', 'decoder.block.2.layer.0.SelfAttention.q.weight', 'decoder.block.2.layer.0.SelfAttention.v.weight', 'decoder.block.3.layer.0.SelfAttention.q.weight', 'decoder.block.3.layer.0.SelfAttention.v.weight', 'decoder.block.4.layer.0.SelfAttention.q.weight', 'decoder.block.4.layer.0.SelfAttention.v.weight', 'decoder.block.5.layer.0.SelfAttention.q.weight', 'decoder.block.5.layer.0.SelfAttention.v.weight', 'decoder.block.6.layer.0.SelfAttention.q.weight', 'decoder.block.6.layer.0.SelfAttention.v.weight', 'decoder.block.7.layer.0.SelfAttention.q.weight', 'decoder.block.7.layer.0.SelfAttention.v.weight', 'decoder.block.8.layer.0.SelfAttention.q.weight', 'decoder.block.8.layer.0.SelfAttention.v.weight', 'decoder.block.9.layer.0.SelfAttention.q.weight', 'decoder.block.9.layer.0.SelfAttention.v.weight', 'decoder.block.10.layer.0.SelfAttention.q.weight', 'decoder.block.10.layer.0.SelfAttention.v.weight', 'decoder.block.11.layer.0.SelfAttention.q.weight', 'decoder.block.11.layer.0.SelfAttention.v.weight']
- This IS expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of T5ForConditionalGeneration were not initialized from the model checkpoint at t5-base and are newly initialized: ['task_embedding_controller.task_to_embeddings.movieTrivia', 'task_embedding_controller.task_to_embeddings.movie', 'task_embedding_controller.task_to_embeddings.restaurant', 'task_embedding_controller.task_to_embeddings.atis', 'task_embedding_controller.task_to_embeddings.snips', 'task_embedding_controller.task_to_embeddings.mtod', 'task_embedding_controller.task_to_embeddings.mtop', 'encoder.block.0.layer.0.SelfAttention.q.linear.weight', 'encoder.block.0.layer.0.SelfAttention.v.linear.weight', 'encoder.block.1.layer.0.SelfAttention.q.linear.weight', 'encoder.block.1.layer.0.SelfAttention.v.linear.weight', 'encoder.block.2.layer.0.SelfAttention.q.linear.weight', 'encoder.block.2.layer.0.SelfAttention.v.linear.weight', 'encoder.block.3.layer.0.SelfAttention.q.linear.weight', 'encoder.block.3.layer.0.SelfAttention.v.linear.weight', 'encoder.block.4.layer.0.SelfAttention.q.linear.weight', 'encoder.block.4.layer.0.SelfAttention.v.linear.weight', 'encoder.block.5.layer.0.SelfAttention.q.linear.weight', 'encoder.block.5.layer.0.SelfAttention.v.linear.weight', 'encoder.block.6.layer.0.SelfAttention.q.linear.weight', 'encoder.block.6.layer.0.SelfAttention.v.linear.weight', 'encoder.block.7.layer.0.SelfAttention.q.linear.weight', 'encoder.block.7.layer.0.SelfAttention.v.linear.weight', 'encoder.block.8.layer.0.SelfAttention.q.linear.weight', 'encoder.block.8.layer.0.SelfAttention.v.linear.weight', 'encoder.block.9.layer.0.SelfAttention.q.linear.weight', 'encoder.block.9.layer.0.SelfAttention.v.linear.weight', 'encoder.block.10.layer.0.SelfAttention.q.linear.weight', 'encoder.block.10.layer.0.SelfAttention.v.linear.weight', 'encoder.block.11.layer.0.SelfAttention.q.linear.weight', 'encoder.block.11.layer.0.SelfAttention.v.linear.weight', 'encoder.adapter_layers_hyper_net.layer_id_embeddings.weight', 'encoder.adapter_layers_hyper_net.adapters_block_type.weight', 'encoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.0.weight', 'encoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.0.bias', 'encoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.2.weight', 'encoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.2.bias', 'encoder.adapter_layers_hyper_net.LayerNorm.weight', 'encoder.adapter_layers_hyper_net.LayerNorm.bias', 'encoder.adapter_layers_hyper_net.up_sampler_hyper_net.weight_generator.0.weight', 'encoder.adapter_layers_hyper_net.up_sampler_hyper_net.weight_generator.0.bias', 'encoder.adapter_layers_hyper_net.up_sampler_hyper_net.bias_generator.0.weight', 'encoder.adapter_layers_hyper_net.up_sampler_hyper_net.bias_generator.0.bias', 'encoder.adapter_layers_hyper_net.down_sampler_hyper_net.weight_generator.0.weight', 'encoder.adapter_layers_hyper_net.down_sampler_hyper_net.weight_generator.0.bias', 'encoder.adapter_layers_hyper_net.down_sampler_hyper_net.bias_generator.0.weight', 'encoder.adapter_layers_hyper_net.down_sampler_hyper_net.bias_generator.0.bias', 'encoder.adapter_layers_hyper_net.lora_query_a_hyper_net.weight_generator.0.weight', 'encoder.adapter_layers_hyper_net.lora_query_a_hyper_net.weight_generator.0.bias', 'encoder.adapter_layers_hyper_net.lora_query_b_hyper_net.weight_generator.0.weight', 'encoder.adapter_layers_hyper_net.lora_query_b_hyper_net.weight_generator.0.bias', 'encoder.adapter_layers_hyper_net.lora_value_a_hyper_net.weight_generator.0.weight', 'encoder.adapter_layers_hyper_net.lora_value_a_hyper_net.weight_generator.0.bias', 'encoder.adapter_layers_hyper_net.lora_value_b_hyper_net.weight_generator.0.weight', 'encoder.adapter_layers_hyper_net.lora_value_b_hyper_net.weight_generator.0.bias', 'encoder.adapter_layers_hyper_net.post_layernorm_hypernet.weight_generator.weight', 'encoder.adapter_layers_hyper_net.post_layernorm_hypernet.weight_generator.bias', 'encoder.adapter_layers_hyper_net.post_layernorm_hypernet.bias_generator.weight', 'encoder.adapter_layers_hyper_net.post_layernorm_hypernet.bias_generator.bias', 'decoder.block.0.layer.0.SelfAttention.q.linear.weight', 'decoder.block.0.layer.0.SelfAttention.v.linear.weight', 'decoder.block.1.layer.0.SelfAttention.q.linear.weight', 'decoder.block.1.layer.0.SelfAttention.v.linear.weight', 'decoder.block.2.layer.0.SelfAttention.q.linear.weight', 'decoder.block.2.layer.0.SelfAttention.v.linear.weight', 'decoder.block.3.layer.0.SelfAttention.q.linear.weight', 'decoder.block.3.layer.0.SelfAttention.v.linear.weight', 'decoder.block.4.layer.0.SelfAttention.q.linear.weight', 'decoder.block.4.layer.0.SelfAttention.v.linear.weight', 'decoder.block.5.layer.0.SelfAttention.q.linear.weight', 'decoder.block.5.layer.0.SelfAttention.v.linear.weight', 'decoder.block.6.layer.0.SelfAttention.q.linear.weight', 'decoder.block.6.layer.0.SelfAttention.v.linear.weight', 'decoder.block.7.layer.0.SelfAttention.q.linear.weight', 'decoder.block.7.layer.0.SelfAttention.v.linear.weight', 'decoder.block.8.layer.0.SelfAttention.q.linear.weight', 'decoder.block.8.layer.0.SelfAttention.v.linear.weight', 'decoder.block.9.layer.0.SelfAttention.q.linear.weight', 'decoder.block.9.layer.0.SelfAttention.v.linear.weight', 'decoder.block.10.layer.0.SelfAttention.q.linear.weight', 'decoder.block.10.layer.0.SelfAttention.v.linear.weight', 'decoder.block.11.layer.0.SelfAttention.q.linear.weight', 'decoder.block.11.layer.0.SelfAttention.v.linear.weight', 'decoder.adapter_layers_hyper_net.layer_id_embeddings.weight', 'decoder.adapter_layers_hyper_net.adapters_block_type.weight', 'decoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.0.weight', 'decoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.0.bias', 'decoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.2.weight', 'decoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.2.bias', 'decoder.adapter_layers_hyper_net.LayerNorm.weight', 'decoder.adapter_layers_hyper_net.LayerNorm.bias', 'decoder.adapter_layers_hyper_net.up_sampler_hyper_net.weight_generator.0.weight', 'decoder.adapter_layers_hyper_net.up_sampler_hyper_net.weight_generator.0.bias', 'decoder.adapter_layers_hyper_net.up_sampler_hyper_net.bias_generator.0.weight', 'decoder.adapter_layers_hyper_net.up_sampler_hyper_net.bias_generator.0.bias', 'decoder.adapter_layers_hyper_net.down_sampler_hyper_net.weight_generator.0.weight', 'decoder.adapter_layers_hyper_net.down_sampler_hyper_net.weight_generator.0.bias', 'decoder.adapter_layers_hyper_net.down_sampler_hyper_net.bias_generator.0.weight', 'decoder.adapter_layers_hyper_net.down_sampler_hyper_net.bias_generator.0.bias', 'decoder.adapter_layers_hyper_net.lora_query_a_hyper_net.weight_generator.0.weight', 'decoder.adapter_layers_hyper_net.lora_query_a_hyper_net.weight_generator.0.bias', 'decoder.adapter_layers_hyper_net.lora_query_b_hyper_net.weight_generator.0.weight', 'decoder.adapter_layers_hyper_net.lora_query_b_hyper_net.weight_generator.0.bias', 'decoder.adapter_layers_hyper_net.lora_value_a_hyper_net.weight_generator.0.weight', 'decoder.adapter_layers_hyper_net.lora_value_a_hyper_net.weight_generator.0.bias', 'decoder.adapter_layers_hyper_net.lora_value_b_hyper_net.weight_generator.0.weight', 'decoder.adapter_layers_hyper_net.lora_value_b_hyper_net.weight_generator.0.bias', 'decoder.adapter_layers_hyper_net.post_layernorm_hypernet.weight_generator.weight', 'decoder.adapter_layers_hyper_net.post_layernorm_hypernet.weight_generator.bias', 'decoder.adapter_layers_hyper_net.post_layernorm_hypernet.bias_generator.weight', 'decoder.adapter_layers_hyper_net.post_layernorm_hypernet.bias_generator.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Trainable param: layer_id_embeddings.weight
Trainable param: adapters_block_type.weight
Trainable param: task_hypernet.task_embeding_generator.0.weight
Trainable param: task_hypernet.task_embeding_generator.0.bias
Trainable param: task_hypernet.task_embeding_generator.2.weight
Trainable param: task_hypernet.task_embeding_generator.2.bias
Trainable param: LayerNorm.weight
Trainable param: LayerNorm.bias
Trainable param: up_sampler_hyper_net.weight_generator.0.weight
Trainable param: up_sampler_hyper_net.weight_generator.0.bias
Trainable param: up_sampler_hyper_net.bias_generator.0.weight
Trainable param: up_sampler_hyper_net.bias_generator.0.bias
Trainable param: down_sampler_hyper_net.weight_generator.0.weight
Trainable param: down_sampler_hyper_net.weight_generator.0.bias
Trainable param: down_sampler_hyper_net.bias_generator.0.weight
Trainable param: down_sampler_hyper_net.bias_generator.0.bias
Trainable param: lora_query_a_hyper_net.weight_generator.0.weight
Trainable param: lora_query_a_hyper_net.weight_generator.0.bias
Trainable param: lora_query_b_hyper_net.weight_generator.0.weight
Trainable param: lora_query_b_hyper_net.weight_generator.0.bias
Trainable param: lora_value_a_hyper_net.weight_generator.0.weight
Trainable param: lora_value_a_hyper_net.weight_generator.0.bias
Trainable param: lora_value_b_hyper_net.weight_generator.0.weight
Trainable param: lora_value_b_hyper_net.weight_generator.0.bias
Trainable param: post_layernorm_hypernet.weight_generator.weight
Trainable param: post_layernorm_hypernet.weight_generator.bias
Trainable param: post_layernorm_hypernet.bias_generator.weight
Trainable param: post_layernorm_hypernet.bias_generator.bias
Trainable param: layer_id_embeddings.weight
Trainable param: adapters_block_type.weight
Trainable param: task_hypernet.task_embeding_generator.0.weight
Trainable param: task_hypernet.task_embeding_generator.0.bias
Trainable param: task_hypernet.task_embeding_generator.2.weight
Trainable param: task_hypernet.task_embeding_generator.2.bias
Trainable param: LayerNorm.weight
Trainable param: LayerNorm.bias
Trainable param: up_sampler_hyper_net.weight_generator.0.weight
Trainable param: up_sampler_hyper_net.weight_generator.0.bias
Trainable param: up_sampler_hyper_net.bias_generator.0.weight
Trainable param: up_sampler_hyper_net.bias_generator.0.bias
Trainable param: down_sampler_hyper_net.weight_generator.0.weight
Trainable param: down_sampler_hyper_net.weight_generator.0.bias
Trainable param: down_sampler_hyper_net.bias_generator.0.weight
Trainable param: down_sampler_hyper_net.bias_generator.0.bias
Trainable param: lora_query_a_hyper_net.weight_generator.0.weight
Trainable param: lora_query_a_hyper_net.weight_generator.0.bias
Trainable param: lora_query_b_hyper_net.weight_generator.0.weight
Trainable param: lora_query_b_hyper_net.weight_generator.0.bias
Trainable param: lora_value_a_hyper_net.weight_generator.0.weight
Trainable param: lora_value_a_hyper_net.weight_generator.0.bias
Trainable param: lora_value_b_hyper_net.weight_generator.0.weight
Trainable param: lora_value_b_hyper_net.weight_generator.0.bias
Trainable param: post_layernorm_hypernet.weight_generator.weight
Trainable param: post_layernorm_hypernet.weight_generator.bias
Trainable param: post_layernorm_hypernet.bias_generator.weight
Trainable param: post_layernorm_hypernet.bias_generator.bias
Some weights of the model checkpoint at t5-base were not used when initializing T5ForConditionalGeneration: ['encoder.block.0.layer.0.SelfAttention.q.weight', 'encoder.block.0.layer.0.SelfAttention.v.weight', 'encoder.block.1.layer.0.SelfAttention.q.weight', 'encoder.block.1.layer.0.SelfAttention.v.weight', 'encoder.block.2.layer.0.SelfAttention.q.weight', 'encoder.block.2.layer.0.SelfAttention.v.weight', 'encoder.block.3.layer.0.SelfAttention.q.weight', 'encoder.block.3.layer.0.SelfAttention.v.weight', 'encoder.block.4.layer.0.SelfAttention.q.weight', 'encoder.block.4.layer.0.SelfAttention.v.weight', 'encoder.block.5.layer.0.SelfAttention.q.weight', 'encoder.block.5.layer.0.SelfAttention.v.weight', 'encoder.block.6.layer.0.SelfAttention.q.weight', 'encoder.block.6.layer.0.SelfAttention.v.weight', 'encoder.block.7.layer.0.SelfAttention.q.weight', 'encoder.block.7.layer.0.SelfAttention.v.weight', 'encoder.block.8.layer.0.SelfAttention.q.weight', 'encoder.block.8.layer.0.SelfAttention.v.weight', 'encoder.block.9.layer.0.SelfAttention.q.weight', 'encoder.block.9.layer.0.SelfAttention.v.weight', 'encoder.block.10.layer.0.SelfAttention.q.weight', 'encoder.block.10.layer.0.SelfAttention.v.weight', 'encoder.block.11.layer.0.SelfAttention.q.weight', 'encoder.block.11.layer.0.SelfAttention.v.weight', 'decoder.block.0.layer.0.SelfAttention.q.weight', 'decoder.block.0.layer.0.SelfAttention.v.weight', 'decoder.block.1.layer.0.SelfAttention.q.weight', 'decoder.block.1.layer.0.SelfAttention.v.weight', 'decoder.block.2.layer.0.SelfAttention.q.weight', 'decoder.block.2.layer.0.SelfAttention.v.weight', 'decoder.block.3.layer.0.SelfAttention.q.weight', 'decoder.block.3.layer.0.SelfAttention.v.weight', 'decoder.block.4.layer.0.SelfAttention.q.weight', 'decoder.block.4.layer.0.SelfAttention.v.weight', 'decoder.block.5.layer.0.SelfAttention.q.weight', 'decoder.block.5.layer.0.SelfAttention.v.weight', 'decoder.block.6.layer.0.SelfAttention.q.weight', 'decoder.block.6.layer.0.SelfAttention.v.weight', 'decoder.block.7.layer.0.SelfAttention.q.weight', 'decoder.block.7.layer.0.SelfAttention.v.weight', 'decoder.block.8.layer.0.SelfAttention.q.weight', 'decoder.block.8.layer.0.SelfAttention.v.weight', 'decoder.block.9.layer.0.SelfAttention.q.weight', 'decoder.block.9.layer.0.SelfAttention.v.weight', 'decoder.block.10.layer.0.SelfAttention.q.weight', 'decoder.block.10.layer.0.SelfAttention.v.weight', 'decoder.block.11.layer.0.SelfAttention.q.weight', 'decoder.block.11.layer.0.SelfAttention.v.weight']
- This IS expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of T5ForConditionalGeneration were not initialized from the model checkpoint at t5-base and are newly initialized: ['task_embedding_controller.task_to_embeddings.movieTrivia', 'task_embedding_controller.task_to_embeddings.movie', 'task_embedding_controller.task_to_embeddings.restaurant', 'task_embedding_controller.task_to_embeddings.atis', 'task_embedding_controller.task_to_embeddings.snips', 'task_embedding_controller.task_to_embeddings.mtod', 'task_embedding_controller.task_to_embeddings.mtop', 'encoder.block.0.layer.0.SelfAttention.q.linear.weight', 'encoder.block.0.layer.0.SelfAttention.v.linear.weight', 'encoder.block.1.layer.0.SelfAttention.q.linear.weight', 'encoder.block.1.layer.0.SelfAttention.v.linear.weight', 'encoder.block.2.layer.0.SelfAttention.q.linear.weight', 'encoder.block.2.layer.0.SelfAttention.v.linear.weight', 'encoder.block.3.layer.0.SelfAttention.q.linear.weight', 'encoder.block.3.layer.0.SelfAttention.v.linear.weight', 'encoder.block.4.layer.0.SelfAttention.q.linear.weight', 'encoder.block.4.layer.0.SelfAttention.v.linear.weight', 'encoder.block.5.layer.0.SelfAttention.q.linear.weight', 'encoder.block.5.layer.0.SelfAttention.v.linear.weight', 'encoder.block.6.layer.0.SelfAttention.q.linear.weight', 'encoder.block.6.layer.0.SelfAttention.v.linear.weight', 'encoder.block.7.layer.0.SelfAttention.q.linear.weight', 'encoder.block.7.layer.0.SelfAttention.v.linear.weight', 'encoder.block.8.layer.0.SelfAttention.q.linear.weight', 'encoder.block.8.layer.0.SelfAttention.v.linear.weight', 'encoder.block.9.layer.0.SelfAttention.q.linear.weight', 'encoder.block.9.layer.0.SelfAttention.v.linear.weight', 'encoder.block.10.layer.0.SelfAttention.q.linear.weight', 'encoder.block.10.layer.0.SelfAttention.v.linear.weight', 'encoder.block.11.layer.0.SelfAttention.q.linear.weight', 'encoder.block.11.layer.0.SelfAttention.v.linear.weight', 'encoder.adapter_layers_hyper_net.layer_id_embeddings.weight', 'encoder.adapter_layers_hyper_net.adapters_block_type.weight', 'encoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.0.weight', 'encoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.0.bias', 'encoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.2.weight', 'encoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.2.bias', 'encoder.adapter_layers_hyper_net.LayerNorm.weight', 'encoder.adapter_layers_hyper_net.LayerNorm.bias', 'encoder.adapter_layers_hyper_net.up_sampler_hyper_net.weight_generator.0.weight', 'encoder.adapter_layers_hyper_net.up_sampler_hyper_net.weight_generator.0.bias', 'encoder.adapter_layers_hyper_net.up_sampler_hyper_net.bias_generator.0.weight', 'encoder.adapter_layers_hyper_net.up_sampler_hyper_net.bias_generator.0.bias', 'encoder.adapter_layers_hyper_net.down_sampler_hyper_net.weight_generator.0.weight', 'encoder.adapter_layers_hyper_net.down_sampler_hyper_net.weight_generator.0.bias', 'encoder.adapter_layers_hyper_net.down_sampler_hyper_net.bias_generator.0.weight', 'encoder.adapter_layers_hyper_net.down_sampler_hyper_net.bias_generator.0.bias', 'encoder.adapter_layers_hyper_net.lora_query_a_hyper_net.weight_generator.0.weight', 'encoder.adapter_layers_hyper_net.lora_query_a_hyper_net.weight_generator.0.bias', 'encoder.adapter_layers_hyper_net.lora_query_b_hyper_net.weight_generator.0.weight', 'encoder.adapter_layers_hyper_net.lora_query_b_hyper_net.weight_generator.0.bias', 'encoder.adapter_layers_hyper_net.lora_value_a_hyper_net.weight_generator.0.weight', 'encoder.adapter_layers_hyper_net.lora_value_a_hyper_net.weight_generator.0.bias', 'encoder.adapter_layers_hyper_net.lora_value_b_hyper_net.weight_generator.0.weight', 'encoder.adapter_layers_hyper_net.lora_value_b_hyper_net.weight_generator.0.bias', 'encoder.adapter_layers_hyper_net.post_layernorm_hypernet.weight_generator.weight', 'encoder.adapter_layers_hyper_net.post_layernorm_hypernet.weight_generator.bias', 'encoder.adapter_layers_hyper_net.post_layernorm_hypernet.bias_generator.weight', 'encoder.adapter_layers_hyper_net.post_layernorm_hypernet.bias_generator.bias', 'decoder.block.0.layer.0.SelfAttention.q.linear.weight', 'decoder.block.0.layer.0.SelfAttention.v.linear.weight', 'decoder.block.1.layer.0.SelfAttention.q.linear.weight', 'decoder.block.1.layer.0.SelfAttention.v.linear.weight', 'decoder.block.2.layer.0.SelfAttention.q.linear.weight', 'decoder.block.2.layer.0.SelfAttention.v.linear.weight', 'decoder.block.3.layer.0.SelfAttention.q.linear.weight', 'decoder.block.3.layer.0.SelfAttention.v.linear.weight', 'decoder.block.4.layer.0.SelfAttention.q.linear.weight', 'decoder.block.4.layer.0.SelfAttention.v.linear.weight', 'decoder.block.5.layer.0.SelfAttention.q.linear.weight', 'decoder.block.5.layer.0.SelfAttention.v.linear.weight', 'decoder.block.6.layer.0.SelfAttention.q.linear.weight', 'decoder.block.6.layer.0.SelfAttention.v.linear.weight', 'decoder.block.7.layer.0.SelfAttention.q.linear.weight', 'decoder.block.7.layer.0.SelfAttention.v.linear.weight', 'decoder.block.8.layer.0.SelfAttention.q.linear.weight', 'decoder.block.8.layer.0.SelfAttention.v.linear.weight', 'decoder.block.9.layer.0.SelfAttention.q.linear.weight', 'decoder.block.9.layer.0.SelfAttention.v.linear.weight', 'decoder.block.10.layer.0.SelfAttention.q.linear.weight', 'decoder.block.10.layer.0.SelfAttention.v.linear.weight', 'decoder.block.11.layer.0.SelfAttention.q.linear.weight', 'decoder.block.11.layer.0.SelfAttention.v.linear.weight', 'decoder.adapter_layers_hyper_net.layer_id_embeddings.weight', 'decoder.adapter_layers_hyper_net.adapters_block_type.weight', 'decoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.0.weight', 'decoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.0.bias', 'decoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.2.weight', 'decoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.2.bias', 'decoder.adapter_layers_hyper_net.LayerNorm.weight', 'decoder.adapter_layers_hyper_net.LayerNorm.bias', 'decoder.adapter_layers_hyper_net.up_sampler_hyper_net.weight_generator.0.weight', 'decoder.adapter_layers_hyper_net.up_sampler_hyper_net.weight_generator.0.bias', 'decoder.adapter_layers_hyper_net.up_sampler_hyper_net.bias_generator.0.weight', 'decoder.adapter_layers_hyper_net.up_sampler_hyper_net.bias_generator.0.bias', 'decoder.adapter_layers_hyper_net.down_sampler_hyper_net.weight_generator.0.weight', 'decoder.adapter_layers_hyper_net.down_sampler_hyper_net.weight_generator.0.bias', 'decoder.adapter_layers_hyper_net.down_sampler_hyper_net.bias_generator.0.weight', 'decoder.adapter_layers_hyper_net.down_sampler_hyper_net.bias_generator.0.bias', 'decoder.adapter_layers_hyper_net.lora_query_a_hyper_net.weight_generator.0.weight', 'decoder.adapter_layers_hyper_net.lora_query_a_hyper_net.weight_generator.0.bias', 'decoder.adapter_layers_hyper_net.lora_query_b_hyper_net.weight_generator.0.weight', 'decoder.adapter_layers_hyper_net.lora_query_b_hyper_net.weight_generator.0.bias', 'decoder.adapter_layers_hyper_net.lora_value_a_hyper_net.weight_generator.0.weight', 'decoder.adapter_layers_hyper_net.lora_value_a_hyper_net.weight_generator.0.bias', 'decoder.adapter_layers_hyper_net.lora_value_b_hyper_net.weight_generator.0.weight', 'decoder.adapter_layers_hyper_net.lora_value_b_hyper_net.weight_generator.0.bias', 'decoder.adapter_layers_hyper_net.post_layernorm_hypernet.weight_generator.weight', 'decoder.adapter_layers_hyper_net.post_layernorm_hypernet.weight_generator.bias', 'decoder.adapter_layers_hyper_net.post_layernorm_hypernet.bias_generator.weight', 'decoder.adapter_layers_hyper_net.post_layernorm_hypernet.bias_generator.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of the model checkpoint at t5-base were not used when initializing T5ForConditionalGeneration: ['encoder.block.0.layer.0.SelfAttention.q.weight', 'encoder.block.0.layer.0.SelfAttention.v.weight', 'encoder.block.1.layer.0.SelfAttention.q.weight', 'encoder.block.1.layer.0.SelfAttention.v.weight', 'encoder.block.2.layer.0.SelfAttention.q.weight', 'encoder.block.2.layer.0.SelfAttention.v.weight', 'encoder.block.3.layer.0.SelfAttention.q.weight', 'encoder.block.3.layer.0.SelfAttention.v.weight', 'encoder.block.4.layer.0.SelfAttention.q.weight', 'encoder.block.4.layer.0.SelfAttention.v.weight', 'encoder.block.5.layer.0.SelfAttention.q.weight', 'encoder.block.5.layer.0.SelfAttention.v.weight', 'encoder.block.6.layer.0.SelfAttention.q.weight', 'encoder.block.6.layer.0.SelfAttention.v.weight', 'encoder.block.7.layer.0.SelfAttention.q.weight', 'encoder.block.7.layer.0.SelfAttention.v.weight', 'encoder.block.8.layer.0.SelfAttention.q.weight', 'encoder.block.8.layer.0.SelfAttention.v.weight', 'encoder.block.9.layer.0.SelfAttention.q.weight', 'encoder.block.9.layer.0.SelfAttention.v.weight', 'encoder.block.10.layer.0.SelfAttention.q.weight', 'encoder.block.10.layer.0.SelfAttention.v.weight', 'encoder.block.11.layer.0.SelfAttention.q.weight', 'encoder.block.11.layer.0.SelfAttention.v.weight', 'decoder.block.0.layer.0.SelfAttention.q.weight', 'decoder.block.0.layer.0.SelfAttention.v.weight', 'decoder.block.1.layer.0.SelfAttention.q.weight', 'decoder.block.1.layer.0.SelfAttention.v.weight', 'decoder.block.2.layer.0.SelfAttention.q.weight', 'decoder.block.2.layer.0.SelfAttention.v.weight', 'decoder.block.3.layer.0.SelfAttention.q.weight', 'decoder.block.3.layer.0.SelfAttention.v.weight', 'decoder.block.4.layer.0.SelfAttention.q.weight', 'decoder.block.4.layer.0.SelfAttention.v.weight', 'decoder.block.5.layer.0.SelfAttention.q.weight', 'decoder.block.5.layer.0.SelfAttention.v.weight', 'decoder.block.6.layer.0.SelfAttention.q.weight', 'decoder.block.6.layer.0.SelfAttention.v.weight', 'decoder.block.7.layer.0.SelfAttention.q.weight', 'decoder.block.7.layer.0.SelfAttention.v.weight', 'decoder.block.8.layer.0.SelfAttention.q.weight', 'decoder.block.8.layer.0.SelfAttention.v.weight', 'decoder.block.9.layer.0.SelfAttention.q.weight', 'decoder.block.9.layer.0.SelfAttention.v.weight', 'decoder.block.10.layer.0.SelfAttention.q.weight', 'decoder.block.10.layer.0.SelfAttention.v.weight', 'decoder.block.11.layer.0.SelfAttention.q.weight', 'decoder.block.11.layer.0.SelfAttention.v.weight']
- This IS expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of T5ForConditionalGeneration were not initialized from the model checkpoint at t5-base and are newly initialized: ['task_embedding_controller.task_to_embeddings.movieTrivia', 'task_embedding_controller.task_to_embeddings.movie', 'task_embedding_controller.task_to_embeddings.restaurant', 'task_embedding_controller.task_to_embeddings.atis', 'task_embedding_controller.task_to_embeddings.snips', 'task_embedding_controller.task_to_embeddings.mtod', 'task_embedding_controller.task_to_embeddings.mtop', 'encoder.block.0.layer.0.SelfAttention.q.linear.weight', 'encoder.block.0.layer.0.SelfAttention.v.linear.weight', 'encoder.block.1.layer.0.SelfAttention.q.linear.weight', 'encoder.block.1.layer.0.SelfAttention.v.linear.weight', 'encoder.block.2.layer.0.SelfAttention.q.linear.weight', 'encoder.block.2.layer.0.SelfAttention.v.linear.weight', 'encoder.block.3.layer.0.SelfAttention.q.linear.weight', 'encoder.block.3.layer.0.SelfAttention.v.linear.weight', 'encoder.block.4.layer.0.SelfAttention.q.linear.weight', 'encoder.block.4.layer.0.SelfAttention.v.linear.weight', 'encoder.block.5.layer.0.SelfAttention.q.linear.weight', 'encoder.block.5.layer.0.SelfAttention.v.linear.weight', 'encoder.block.6.layer.0.SelfAttention.q.linear.weight', 'encoder.block.6.layer.0.SelfAttention.v.linear.weight', 'encoder.block.7.layer.0.SelfAttention.q.linear.weight', 'encoder.block.7.layer.0.SelfAttention.v.linear.weight', 'encoder.block.8.layer.0.SelfAttention.q.linear.weight', 'encoder.block.8.layer.0.SelfAttention.v.linear.weight', 'encoder.block.9.layer.0.SelfAttention.q.linear.weight', 'encoder.block.9.layer.0.SelfAttention.v.linear.weight', 'encoder.block.10.layer.0.SelfAttention.q.linear.weight', 'encoder.block.10.layer.0.SelfAttention.v.linear.weight', 'encoder.block.11.layer.0.SelfAttention.q.linear.weight', 'encoder.block.11.layer.0.SelfAttention.v.linear.weight', 'encoder.adapter_layers_hyper_net.layer_id_embeddings.weight', 'encoder.adapter_layers_hyper_net.adapters_block_type.weight', 'encoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.0.weight', 'encoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.0.bias', 'encoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.2.weight', 'encoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.2.bias', 'encoder.adapter_layers_hyper_net.LayerNorm.weight', 'encoder.adapter_layers_hyper_net.LayerNorm.bias', 'encoder.adapter_layers_hyper_net.up_sampler_hyper_net.weight_generator.0.weight', 'encoder.adapter_layers_hyper_net.up_sampler_hyper_net.weight_generator.0.bias', 'encoder.adapter_layers_hyper_net.up_sampler_hyper_net.bias_generator.0.weight', 'encoder.adapter_layers_hyper_net.up_sampler_hyper_net.bias_generator.0.bias', 'encoder.adapter_layers_hyper_net.down_sampler_hyper_net.weight_generator.0.weight', 'encoder.adapter_layers_hyper_net.down_sampler_hyper_net.weight_generator.0.bias', 'encoder.adapter_layers_hyper_net.down_sampler_hyper_net.bias_generator.0.weight', 'encoder.adapter_layers_hyper_net.down_sampler_hyper_net.bias_generator.0.bias', 'encoder.adapter_layers_hyper_net.lora_query_a_hyper_net.weight_generator.0.weight', 'encoder.adapter_layers_hyper_net.lora_query_a_hyper_net.weight_generator.0.bias', 'encoder.adapter_layers_hyper_net.lora_query_b_hyper_net.weight_generator.0.weight', 'encoder.adapter_layers_hyper_net.lora_query_b_hyper_net.weight_generator.0.bias', 'encoder.adapter_layers_hyper_net.lora_value_a_hyper_net.weight_generator.0.weight', 'encoder.adapter_layers_hyper_net.lora_value_a_hyper_net.weight_generator.0.bias', 'encoder.adapter_layers_hyper_net.lora_value_b_hyper_net.weight_generator.0.weight', 'encoder.adapter_layers_hyper_net.lora_value_b_hyper_net.weight_generator.0.bias', 'encoder.adapter_layers_hyper_net.post_layernorm_hypernet.weight_generator.weight', 'encoder.adapter_layers_hyper_net.post_layernorm_hypernet.weight_generator.bias', 'encoder.adapter_layers_hyper_net.post_layernorm_hypernet.bias_generator.weight', 'encoder.adapter_layers_hyper_net.post_layernorm_hypernet.bias_generator.bias', 'decoder.block.0.layer.0.SelfAttention.q.linear.weight', 'decoder.block.0.layer.0.SelfAttention.v.linear.weight', 'decoder.block.1.layer.0.SelfAttention.q.linear.weight', 'decoder.block.1.layer.0.SelfAttention.v.linear.weight', 'decoder.block.2.layer.0.SelfAttention.q.linear.weight', 'decoder.block.2.layer.0.SelfAttention.v.linear.weight', 'decoder.block.3.layer.0.SelfAttention.q.linear.weight', 'decoder.block.3.layer.0.SelfAttention.v.linear.weight', 'decoder.block.4.layer.0.SelfAttention.q.linear.weight', 'decoder.block.4.layer.0.SelfAttention.v.linear.weight', 'decoder.block.5.layer.0.SelfAttention.q.linear.weight', 'decoder.block.5.layer.0.SelfAttention.v.linear.weight', 'decoder.block.6.layer.0.SelfAttention.q.linear.weight', 'decoder.block.6.layer.0.SelfAttention.v.linear.weight', 'decoder.block.7.layer.0.SelfAttention.q.linear.weight', 'decoder.block.7.layer.0.SelfAttention.v.linear.weight', 'decoder.block.8.layer.0.SelfAttention.q.linear.weight', 'decoder.block.8.layer.0.SelfAttention.v.linear.weight', 'decoder.block.9.layer.0.SelfAttention.q.linear.weight', 'decoder.block.9.layer.0.SelfAttention.v.linear.weight', 'decoder.block.10.layer.0.SelfAttention.q.linear.weight', 'decoder.block.10.layer.0.SelfAttention.v.linear.weight', 'decoder.block.11.layer.0.SelfAttention.q.linear.weight', 'decoder.block.11.layer.0.SelfAttention.v.linear.weight', 'decoder.adapter_layers_hyper_net.layer_id_embeddings.weight', 'decoder.adapter_layers_hyper_net.adapters_block_type.weight', 'decoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.0.weight', 'decoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.0.bias', 'decoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.2.weight', 'decoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.2.bias', 'decoder.adapter_layers_hyper_net.LayerNorm.weight', 'decoder.adapter_layers_hyper_net.LayerNorm.bias', 'decoder.adapter_layers_hyper_net.up_sampler_hyper_net.weight_generator.0.weight', 'decoder.adapter_layers_hyper_net.up_sampler_hyper_net.weight_generator.0.bias', 'decoder.adapter_layers_hyper_net.up_sampler_hyper_net.bias_generator.0.weight', 'decoder.adapter_layers_hyper_net.up_sampler_hyper_net.bias_generator.0.bias', 'decoder.adapter_layers_hyper_net.down_sampler_hyper_net.weight_generator.0.weight', 'decoder.adapter_layers_hyper_net.down_sampler_hyper_net.weight_generator.0.bias', 'decoder.adapter_layers_hyper_net.down_sampler_hyper_net.bias_generator.0.weight', 'decoder.adapter_layers_hyper_net.down_sampler_hyper_net.bias_generator.0.bias', 'decoder.adapter_layers_hyper_net.lora_query_a_hyper_net.weight_generator.0.weight', 'decoder.adapter_layers_hyper_net.lora_query_a_hyper_net.weight_generator.0.bias', 'decoder.adapter_layers_hyper_net.lora_query_b_hyper_net.weight_generator.0.weight', 'decoder.adapter_layers_hyper_net.lora_query_b_hyper_net.weight_generator.0.bias', 'decoder.adapter_layers_hyper_net.lora_value_a_hyper_net.weight_generator.0.weight', 'decoder.adapter_layers_hyper_net.lora_value_a_hyper_net.weight_generator.0.bias', 'decoder.adapter_layers_hyper_net.lora_value_b_hyper_net.weight_generator.0.weight', 'decoder.adapter_layers_hyper_net.lora_value_b_hyper_net.weight_generator.0.bias', 'decoder.adapter_layers_hyper_net.post_layernorm_hypernet.weight_generator.weight', 'decoder.adapter_layers_hyper_net.post_layernorm_hypernet.weight_generator.bias', 'decoder.adapter_layers_hyper_net.post_layernorm_hypernet.bias_generator.weight', 'decoder.adapter_layers_hyper_net.post_layernorm_hypernet.bias_generator.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Trainable param: layer_id_embeddings.weight
Trainable param: adapters_block_type.weight
Trainable param: task_hypernet.task_embeding_generator.0.weight
Trainable param: task_hypernet.task_embeding_generator.0.bias
Trainable param: task_hypernet.task_embeding_generator.2.weight
Trainable param: task_hypernet.task_embeding_generator.2.bias
Trainable param: LayerNorm.weight
Trainable param: LayerNorm.bias
Trainable param: up_sampler_hyper_net.weight_generator.0.weight
Trainable param: up_sampler_hyper_net.weight_generator.0.bias
Trainable param: up_sampler_hyper_net.bias_generator.0.weight
Trainable param: up_sampler_hyper_net.bias_generator.0.bias
Trainable param: down_sampler_hyper_net.weight_generator.0.weight
Trainable param: down_sampler_hyper_net.weight_generator.0.bias
Trainable param: down_sampler_hyper_net.bias_generator.0.weight
Trainable param: down_sampler_hyper_net.bias_generator.0.bias
Trainable param: lora_query_a_hyper_net.weight_generator.0.weight
Trainable param: lora_query_a_hyper_net.weight_generator.0.bias
Trainable param: lora_query_b_hyper_net.weight_generator.0.weight
Trainable param: lora_query_b_hyper_net.weight_generator.0.bias
Trainable param: lora_value_a_hyper_net.weight_generator.0.weight
Trainable param: lora_value_a_hyper_net.weight_generator.0.bias
Trainable param: lora_value_b_hyper_net.weight_generator.0.weight
Trainable param: lora_value_b_hyper_net.weight_generator.0.bias
Trainable param: post_layernorm_hypernet.weight_generator.weighttrain

Trainable param: post_layernorm_hypernet.weight_generator.bias
Trainable param: post_layernorm_hypernet.bias_generator.weight
Trainable param: post_layernorm_hypernet.bias_generator.bias
Trainable param: layer_id_embeddings.weight
Trainable param: adapters_block_type.weight
Trainable param: task_hypernet.task_embeding_generator.0.weight
Trainable param: task_hypernet.task_embeding_generator.0.bias
Trainable param: task_hypernet.task_embeding_generator.2.weight
Trainable param: task_hypernet.task_embeding_generator.2.bias
Trainable param: LayerNorm.weight
Trainable param: LayerNorm.bias
Trainable param: up_sampler_hyper_net.weight_generator.0.weight
Trainable param: up_sampler_hyper_net.weight_generator.0.bias
Trainable param: up_sampler_hyper_net.bias_generator.0.weight
Trainable param: up_sampler_hyper_net.bias_generator.0.bias
Trainable param: down_sampler_hyper_net.weight_generator.0.weight
Trainable param: down_sampler_hyper_net.weight_generator.0.bias
Trainable param: down_sampler_hyper_net.bias_generator.0.weight
Trainable param: down_sampler_hyper_net.bias_generator.0.bias
Trainable param: lora_query_a_hyper_net.weight_generator.0.weight
Trainable param: lora_query_a_hyper_net.weight_generator.0.bias
Trainable param: lora_query_b_hyper_net.weight_generator.0.weight
Trainable param: lora_query_b_hyper_net.weight_generator.0.bias
Trainable param: lora_value_a_hyper_net.weight_generator.0.weight
Trainable param: lora_value_a_hyper_net.weight_generator.0.bias
Trainable param: lora_value_b_hyper_net.weight_generator.0.weight
Trainable param: lora_value_b_hyper_net.weight_generator.0.bias
Trainable param: post_layernorm_hypernet.weight_generator.weight
Trainable param: post_layernorm_hypernet.weight_generator.bias
Trainable param: post_layernorm_hypernet.bias_generator.weight
Trainable param: post_layernorm_hypernet.bias_generator.bias
Some weights of the model checkpoint at t5-base were not used when initializing T5ForConditionalGeneration: ['encoder.block.0.layer.0.SelfAttention.q.weight', 'encoder.block.0.layer.0.SelfAttention.v.weight', 'encoder.block.1.layer.0.SelfAttention.q.weight', 'encoder.block.1.layer.0.SelfAttention.v.weight', 'encoder.block.2.layer.0.SelfAttention.q.weight', 'encoder.block.2.layer.0.SelfAttention.v.weight', 'encoder.block.3.layer.0.SelfAttention.q.weight', 'encoder.block.3.layer.0.SelfAttention.v.weight', 'encoder.block.4.layer.0.SelfAttention.q.weight', 'encoder.block.4.layer.0.SelfAttention.v.weight', 'encoder.block.5.layer.0.SelfAttention.q.weight', 'encoder.block.5.layer.0.SelfAttention.v.weight', 'encoder.block.6.layer.0.SelfAttention.q.weight', 'encoder.block.6.layer.0.SelfAttention.v.weight', 'encoder.block.7.layer.0.SelfAttention.q.weight', 'encoder.block.7.layer.0.SelfAttention.v.weight', 'encoder.block.8.layer.0.SelfAttention.q.weight', 'encoder.block.8.layer.0.SelfAttention.v.weight', 'encoder.block.9.layer.0.SelfAttention.q.weight', 'encoder.block.9.layer.0.SelfAttention.v.weight', 'encoder.block.10.layer.0.SelfAttention.q.weight', 'encoder.block.10.layer.0.SelfAttention.v.weight', 'encoder.block.11.layer.0.SelfAttention.q.weight', 'encoder.block.11.layer.0.SelfAttention.v.weight', 'decoder.block.0.layer.0.SelfAttention.q.weight', 'decoder.block.0.layer.0.SelfAttention.v.weight', 'decoder.block.1.layer.0.SelfAttention.q.weight', 'decoder.block.1.layer.0.SelfAttention.v.weight', 'decoder.block.2.layer.0.SelfAttention.q.weight', 'decoder.block.2.layer.0.SelfAttention.v.weight', 'decoder.block.3.layer.0.SelfAttention.q.weight', 'decoder.block.3.layer.0.SelfAttention.v.weight', 'decoder.block.4.layer.0.SelfAttention.q.weight', 'decoder.block.4.layer.0.SelfAttention.v.weight', 'decoder.block.5.layer.0.SelfAttention.q.weight', 'decoder.block.5.layer.0.SelfAttention.v.weight', 'decoder.block.6.layer.0.SelfAttention.q.weight', 'decoder.block.6.layer.0.SelfAttention.v.weight', 'decoder.block.7.layer.0.SelfAttention.q.weight', 'decoder.block.7.layer.0.SelfAttention.v.weight', 'decoder.block.8.layer.0.SelfAttention.q.weight', 'decoder.block.8.layer.0.SelfAttention.v.weight', 'decoder.block.9.layer.0.SelfAttention.q.weight', 'decoder.block.9.layer.0.SelfAttention.v.weight', 'decoder.block.10.layer.0.SelfAttention.q.weight', 'decoder.block.10.layer.0.SelfAttention.v.weight', 'decoder.block.11.layer.0.SelfAttention.q.weight', 'decoder.block.11.layer.0.SelfAttention.v.weight']
- This IS expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of T5ForConditionalGeneration were not initialized from the model checkpoint at t5-base and are newly initialized: ['task_embedding_controller.task_to_embeddings.movieTrivia', 'task_embedding_controller.task_to_embeddings.movie', 'task_embedding_controller.task_to_embeddings.restaurant', 'task_embedding_controller.task_to_embeddings.atis', 'task_embedding_controller.task_to_embeddings.snips', 'task_embedding_controller.task_to_embeddings.mtod', 'task_embedding_controller.task_to_embeddings.mtop', 'encoder.block.0.layer.0.SelfAttention.q.linear.weight', 'encoder.block.0.layer.0.SelfAttention.v.linear.weight', 'encoder.block.1.layer.0.SelfAttention.q.linear.weight', 'encoder.block.1.layer.0.SelfAttention.v.linear.weight', 'encoder.block.2.layer.0.SelfAttention.q.linear.weight', 'encoder.block.2.layer.0.SelfAttention.v.linear.weight', 'encoder.block.3.layer.0.SelfAttention.q.linear.weight', 'encoder.block.3.layer.0.SelfAttention.v.linear.weight', 'encoder.block.4.layer.0.SelfAttention.q.linear.weight', 'encoder.block.4.layer.0.SelfAttention.v.linear.weight', 'encoder.block.5.layer.0.SelfAttention.q.linear.weight', 'encoder.block.5.layer.0.SelfAttention.v.linear.weight', 'encoder.block.6.layer.0.SelfAttention.q.linear.weight', 'encoder.block.6.layer.0.SelfAttention.v.linear.weight', 'encoder.block.7.layer.0.SelfAttention.q.linear.weight', 'encoder.block.7.layer.0.SelfAttention.v.linear.weight', 'encoder.block.8.layer.0.SelfAttention.q.linear.weight', 'encoder.block.8.layer.0.SelfAttention.v.linear.weight', 'encoder.block.9.layer.0.SelfAttention.q.linear.weight', 'encoder.block.9.layer.0.SelfAttention.v.linear.weight', 'encoder.block.10.layer.0.SelfAttention.q.linear.weight', 'encoder.block.10.layer.0.SelfAttention.v.linear.weight', 'encoder.block.11.layer.0.SelfAttention.q.linear.weight', 'encoder.block.11.layer.0.SelfAttention.v.linear.weight', 'encoder.adapter_layers_hyper_net.layer_id_embeddings.weight', 'encoder.adapter_layers_hyper_net.adapters_block_type.weight', 'encoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.0.weight', 'encoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.0.bias', 'encoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.2.weight', 'encoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.2.bias', 'encoder.adapter_layers_hyper_net.LayerNorm.weight', 'encoder.adapter_layers_hyper_net.LayerNorm.bias', 'encoder.adapter_layers_hyper_net.up_sampler_hyper_net.weight_generator.0.weight', 'encoder.adapter_layers_hyper_net.up_sampler_hyper_net.weight_generator.0.bias', 'encoder.adapter_layers_hyper_net.up_sampler_hyper_net.bias_generator.0.weight', 'encoder.adapter_layers_hyper_net.up_sampler_hyper_net.bias_generator.0.bias', 'encoder.adapter_layers_hyper_net.down_sampler_hyper_net.weight_generator.0.weight', 'encoder.adapter_layers_hyper_net.down_sampler_hyper_net.weight_generator.0.bias', 'encoder.adapter_layers_hyper_net.down_sampler_hyper_net.bias_generator.0.weight', 'encoder.adapter_layers_hyper_net.down_sampler_hyper_net.bias_generator.0.bias', 'encoder.adapter_layers_hyper_net.lora_query_a_hyper_net.weight_generator.0.weight', 'encoder.adapter_layers_hyper_net.lora_query_a_hyper_net.weight_generator.0.bias', 'encoder.adapter_layers_hyper_net.lora_query_b_hyper_net.weight_generator.0.weight', 'encoder.adapter_layers_hyper_net.lora_query_b_hyper_net.weight_generator.0.bias', 'encoder.adapter_layers_hyper_net.lora_value_a_hyper_net.weight_generator.0.weight', 'encoder.adapter_layers_hyper_net.lora_value_a_hyper_net.weight_generator.0.bias', 'encoder.adapter_layers_hyper_net.lora_value_b_hyper_net.weight_generator.0.weight', 'encoder.adapter_layers_hyper_net.lora_value_b_hyper_net.weight_generator.0.bias', 'encoder.adapter_layers_hyper_net.post_layernorm_hypernet.weight_generator.weight', 'encoder.adapter_layers_hyper_net.post_layernorm_hypernet.weight_generator.bias', 'encoder.adapter_layers_hyper_net.post_layernorm_hypernet.bias_generator.weight', 'encoder.adapter_layers_hyper_net.post_layernorm_hypernet.bias_generator.bias', 'decoder.block.0.layer.0.SelfAttention.q.linear.weight', 'decoder.block.0.layer.0.SelfAttention.v.linear.weight', 'decoder.block.1.layer.0.SelfAttention.q.linear.weight', 'decoder.block.1.layer.0.SelfAttention.v.linear.weight', 'decoder.block.2.layer.0.SelfAttention.q.linear.weight', 'decoder.block.2.layer.0.SelfAttention.v.linear.weight', 'decoder.block.3.layer.0.SelfAttention.q.linear.weight', 'decoder.block.3.layer.0.SelfAttention.v.linear.weight', 'decoder.block.4.layer.0.SelfAttention.q.linear.weight', 'decoder.block.4.layer.0.SelfAttention.v.linear.weight', 'decoder.block.5.layer.0.SelfAttention.q.linear.weight', 'decoder.block.5.layer.0.SelfAttention.v.linear.weight', 'decoder.block.6.layer.0.SelfAttention.q.linear.weight', 'decoder.block.6.layer.0.SelfAttention.v.linear.weight', 'decoder.block.7.layer.0.SelfAttention.q.linear.weight', 'decoder.block.7.layer.0.SelfAttention.v.linear.weight', 'decoder.block.8.layer.0.SelfAttention.q.linear.weight', 'decoder.block.8.layer.0.SelfAttention.v.linear.weight', 'decoder.block.9.layer.0.SelfAttention.q.linear.weight', 'decoder.block.9.layer.0.SelfAttention.v.linear.weight', 'decoder.block.10.layer.0.SelfAttention.q.linear.weight', 'decoder.block.10.layer.0.SelfAttention.v.linear.weight', 'decoder.block.11.layer.0.SelfAttention.q.linear.weight', 'decoder.block.11.layer.0.SelfAttention.v.linear.weight', 'decoder.adapter_layers_hyper_net.layer_id_embeddings.weight', 'decoder.adapter_layers_hyper_net.adapters_block_type.weight', 'decoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.0.weight', 'decoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.0.bias', 'decoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.2.weight', 'decoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.2.bias', 'decoder.adapter_layers_hyper_net.LayerNorm.weight', 'decoder.adapter_layers_hyper_net.LayerNorm.bias', 'decoder.adapter_layers_hyper_net.up_sampler_hyper_net.weight_generator.0.weight', 'decoder.adapter_layers_hyper_net.up_sampler_hyper_net.weight_generator.0.bias', 'decoder.adapter_layers_hyper_net.up_sampler_hyper_net.bias_generator.0.weight', 'decoder.adapter_layers_hyper_net.up_sampler_hyper_net.bias_generator.0.bias', 'decoder.adapter_layers_hyper_net.down_sampler_hyper_net.weight_generator.0.weight', 'decoder.adapter_layers_hyper_net.down_sampler_hyper_net.weight_generator.0.bias', 'decoder.adapter_layers_hyper_net.down_sampler_hyper_net.bias_generator.0.weight', 'decoder.adapter_layers_hyper_net.down_sampler_hyper_net.bias_generator.0.bias', 'decoder.adapter_layers_hyper_net.lora_query_a_hyper_net.weight_generator.0.weight', 'decoder.adapter_layers_hyper_net.lora_query_a_hyper_net.weight_generator.0.bias', 'decoder.adapter_layers_hyper_net.lora_query_b_hyper_net.weight_generator.0.weight', 'decoder.adapter_layers_hyper_net.lora_query_b_hyper_net.weight_generator.0.bias', 'decoder.adapter_layers_hyper_net.lora_value_a_hyper_net.weight_generator.0.weight', 'decoder.adapter_layers_hyper_net.lora_value_a_hyper_net.weight_generator.0.bias', 'decoder.adapter_layers_hyper_net.lora_value_b_hyper_net.weight_generator.0.weight', 'decoder.adapter_layers_hyper_net.lora_value_b_hyper_net.weight_generator.0.bias', 'decoder.adapter_layers_hyper_net.post_layernorm_hypernet.weight_generator.weight', 'decoder.adapter_layers_hyper_net.post_layernorm_hypernet.weight_generator.bias', 'decoder.adapter_layers_hyper_net.post_layernorm_hypernet.bias_generator.weight', 'decoder.adapter_layers_hyper_net.post_layernorm_hypernet.bias_generator.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
05/24/2024 22:14:25 - INFO - __main__ -   T5ForConditionalGeneration(
  (task_embedding_controller): TaskEmbeddingController(
    (task_to_embeddings): ParameterDict(
        (movieTrivia): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]
        (movie): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]
        (restaurant): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]
        (atis): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]
        (snips): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]
        (mtod): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]
        (mtop): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]
    )
  )
  (shared): Embedding(32128, 768)
  (encoder): T5Stack(
    (embed_tokens): Embedding(32128, 768)
    (block): ModuleList(
      (0): T5Block(
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            (SelfAttention): T5Attention(
              (q): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (k): Linear(in_features=768, out_features=768, bias=False)
              (v): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (o): Linear(in_features=768, out_features=768, bias=False)
              (relative_attention_bias): Embedding(32, 12)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (1): T5LayerFF(
            (DenseReluDense): T5DenseReluDense(
              (wi): Linear(in_features=768, out_features=3072, bias=False)
              (wo): Linear(in_features=3072, out_features=768, bias=False)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (1): T5Block(
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            (SelfAttention): T5Attention(
              (q): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (k): Linear(in_features=768, out_features=768, bias=False)
              (v): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (o): Linear(in_features=768, out_features=768, bias=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (1): T5LayerFF(
            (DenseReluDense): T5DenseReluDense(
              (wi): Linear(in_features=768, out_features=3072, bias=False)
              (wo): Linear(in_features=3072, out_features=768, bias=False)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (2): T5Block(
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            (SelfAttention): T5Attention(
              (q): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (k): Linear(in_features=768, out_features=768, bias=False)
              (v): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (o): Linear(in_features=768, out_features=768, bias=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (1): T5LayerFF(
            (DenseReluDense): T5DenseReluDense(
              (wi): Linear(in_features=768, out_features=3072, bias=False)
              (wo): Linear(in_features=3072, out_features=768, bias=False)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (3): T5Block(
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            (SelfAttention): T5Attention(
              (q): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (k): Linear(in_features=768, out_features=768, bias=False)
              (v): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (o): Linear(in_features=768, out_features=768, bias=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (1): T5LayerFF(
            (DenseReluDense): T5DenseReluDense(
              (wi): Linear(in_features=768, out_features=3072, bias=False)
              (wo): Linear(in_features=3072, out_features=768, bias=False)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (4): T5Block(
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            (SelfAttention): T5Attention(
              (q): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (k): Linear(in_features=768, out_features=768, bias=False)
              (v): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (o): Linear(in_features=768, out_features=768, bias=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (1): T5LayerFF(
            (DenseReluDense): T5DenseReluDense(
              (wi): Linear(in_features=768, out_features=3072, bias=False)
              (wo): Linear(in_features=3072, out_features=768, bias=False)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (5): T5Block(
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            (SelfAttention): T5Attention(
              (q): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (k): Linear(in_features=768, out_features=768, bias=False)
              (v): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (o): Linear(in_features=768, out_features=768, bias=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (1): T5LayerFF(
            (DenseReluDense): T5DenseReluDense(
              (wi): Linear(in_features=768, out_features=3072, bias=False)
              (wo): Linear(in_features=3072, out_features=768, bias=False)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (6): T5Block(
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            (SelfAttention): T5Attention(
              (q): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (k): Linear(in_features=768, out_features=768, bias=False)
              (v): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (o): Linear(in_features=768, out_features=768, bias=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (1): T5LayerFF(
            (DenseReluDense): T5DenseReluDense(
              (wi): Linear(in_features=768, out_features=3072, bias=False)
              (wo): Linear(in_features=3072, out_features=768, bias=False)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (7): T5Block(
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            (SelfAttention): T5Attention(
              (q): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (k): Linear(in_features=768, out_features=768, bias=False)
              (v): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (o): Linear(in_features=768, out_features=768, bias=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (1): T5LayerFF(
            (DenseReluDense): T5DenseReluDense(
              (wi): Linear(in_features=768, out_features=3072, bias=False)
              (wo): Linear(in_features=3072, out_features=768, bias=False)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (8): T5Block(
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            (SelfAttention): T5Attention(
              (q): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (k): Linear(in_features=768, out_features=768, bias=False)
              (v): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (o): Linear(in_features=768, out_features=768, bias=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (1): T5LayerFF(
            (DenseReluDense): T5DenseReluDense(
              (wi): Linear(in_features=768, out_features=3072, bias=False)
              (wo): Linear(in_features=3072, out_features=768, bias=False)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (9): T5Block(
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            (SelfAttention): T5Attention(
              (q): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (k): Linear(in_features=768, out_features=768, bias=False)
              (v): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (o): Linear(in_features=768, out_features=768, bias=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (1): T5LayerFF(
            (DenseReluDense): T5DenseReluDense(
              (wi): Linear(in_features=768, out_features=3072, bias=False)
              (wo): Linear(in_features=3072, out_features=768, bias=False)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (10): T5Block(
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            (SelfAttention): T5Attention(
              (q): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (k): Linear(in_features=768, out_features=768, bias=False)
              (v): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (o): Linear(in_features=768, out_features=768, bias=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (1): T5LayerFF(
            (DenseReluDense): T5DenseReluDense(
              (wi): Linear(in_features=768, out_features=3072, bias=False)
              (wo): Linear(in_features=3072, out_features=768, bias=False)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (11): T5Block(
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            (SelfAttention): T5Attention(
              (q): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (k): Linear(in_features=768, out_features=768, bias=False)
              (v): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (o): Linear(in_features=768, out_features=768, bias=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (1): T5LayerFF(
            (DenseReluDense): T5DenseReluDense(
              (wi): Linear(in_features=768, out_features=3072, bias=False)
              (wo): Linear(in_features=3072, out_features=768, bias=False)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (adapter_layers_hyper_net): AdapterLayersOneHyperNetController(
      (layer_id_embeddings): Embedding(12, 64)
      (adapters_block_type): Embedding(3, 64)
      (task_hypernet): TaskHyperNet(
        (task_embeding_generator): Sequential(
          (0): Linear(in_features=192, out_features=128, bias=True)
          (1): ReLU()
          (2): Linear(in_features=128, out_features=64, bias=True)
        )
      )
      (LayerNorm): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
      (up_sampler_hyper_net): AdapterLayersHyperNet(
        (weight_generator): Sequential(
          (0): Linear(in_features=64, out_features=18432, bias=True)
        )
        (bias_generator): Sequential(
          (0): Linear(in_features=64, out_features=768, bias=True)
        )
      )
      (down_sampler_hyper_net): AdapterLayersHyperNet(
        (weight_generator): Sequential(
          (0): Linear(in_features=64, out_features=18432, bias=True)
        )
        (bias_generator): Sequential(
          (0): Linear(in_features=64, out_features=24, bias=True)
        )
      )
      (lora_query_a_hyper_net): LoRALayersHyperNet(
        (weight_generator): Sequential(
          (0): Linear(in_features=64, out_features=6144, bias=True)
        )
      )
      (lora_query_b_hyper_net): LoRALayersHyperNet(
        (weight_generator): Sequential(
          (0): Linear(in_features=64, out_features=6144, bias=True)
        )
      )
      (lora_value_a_hyper_net): LoRALayersHyperNet(
        (weight_generator): Sequential(
          (0): Linear(in_features=64, out_features=6144, bias=True)
        )
      )
      (lora_value_b_hyper_net): LoRALayersHyperNet(
        (weight_generator): Sequential(
          (0): Linear(in_features=64, out_features=6144, bias=True)
        )
      )
      (post_layernorm_hypernet): LayerNormHyperNet(
        (weight_generator): Linear(in_features=64, out_features=768, bias=True)
        (bias_generator): Linear(in_features=64, out_features=768, bias=True)
      )
    )
    (final_layer_norm): T5LayerNorm()
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (decoder): T5Stack(
    (embed_tokens): Embedding(32128, 768)
    (block): ModuleList(
      (0): T5Block(
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            (SelfAttention): T5Attention(
              (q): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (k): Linear(in_features=768, out_features=768, bias=False)
              (v): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (o): Linear(in_features=768, out_features=768, bias=False)
              (relative_attention_bias): Embedding(32, 12)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (1): T5LayerCrossAttention(
            (EncDecAttention): T5Attention(
              (q): Linear(in_features=768, out_features=768, bias=False)
              (k): Linear(in_features=768, out_features=768, bias=False)
              (v): Linear(in_features=768, out_features=768, bias=False)
              (o): Linear(in_features=768, out_features=768, bias=False)
              (relative_attention_bias): Embedding(32, 12)
            )
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (2): T5LayerFF(
            (DenseReluDense): T5DenseReluDense(
              (wi): Linear(in_features=768, out_features=3072, bias=False)
              (wo): Linear(in_features=3072, out_features=768, bias=False)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (1): T5Block(
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            (SelfAttention): T5Attention(
              (q): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (k): Linear(in_features=768, out_features=768, bias=False)
              (v): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (o): Linear(in_features=768, out_features=768, bias=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (1): T5LayerCrossAttention(
            (EncDecAttention): T5Attention(
              (q): Linear(in_features=768, out_features=768, bias=False)
              (k): Linear(in_features=768, out_features=768, bias=False)
              (v): Linear(in_features=768, out_features=768, bias=False)
              (o): Linear(in_features=768, out_features=768, bias=False)
            )
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (2): T5LayerFF(
            (DenseReluDense): T5DenseReluDense(
              (wi): Linear(in_features=768, out_features=3072, bias=False)
              (wo): Linear(in_features=3072, out_features=768, bias=False)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (2): T5Block(
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            (SelfAttention): T5Attention(
              (q): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (k): Linear(in_features=768, out_features=768, bias=False)
              (v): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (o): Linear(in_features=768, out_features=768, bias=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (1): T5LayerCrossAttention(
            (EncDecAttention): T5Attention(
              (q): Linear(in_features=768, out_features=768, bias=False)
              (k): Linear(in_features=768, out_features=768, bias=False)
              (v): Linear(in_features=768, out_features=768, bias=False)
              (o): Linear(in_features=768, out_features=768, bias=False)
            )
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (2): T5LayerFF(
            (DenseReluDense): T5DenseReluDense(
              (wi): Linear(in_features=768, out_features=3072, bias=False)
              (wo): Linear(in_features=3072, out_features=768, bias=False)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (3): T5Block(
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            (SelfAttention): T5Attention(
              (q): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (k): Linear(in_features=768, out_features=768, bias=False)
              (v): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (o): Linear(in_features=768, out_features=768, bias=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (1): T5LayerCrossAttention(
            (EncDecAttention): T5Attention(
              (q): Linear(in_features=768, out_features=768, bias=False)
              (k): Linear(in_features=768, out_features=768, bias=False)
              (v): Linear(in_features=768, out_features=768, bias=False)
              (o): Linear(in_features=768, out_features=768, bias=False)
            )
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (2): T5LayerFF(
            (DenseReluDense): T5DenseReluDense(
              (wi): Linear(in_features=768, out_features=3072, bias=False)
              (wo): Linear(in_features=3072, out_features=768, bias=False)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (4): T5Block(
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            (SelfAttention): T5Attention(
              (q): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (k): Linear(in_features=768, out_features=768, bias=False)
              (v): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (o): Linear(in_features=768, out_features=768, bias=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (1): T5LayerCrossAttention(
            (EncDecAttention): T5Attention(
              (q): Linear(in_features=768, out_features=768, bias=False)
              (k): Linear(in_features=768, out_features=768, bias=False)
              (v): Linear(in_features=768, out_features=768, bias=False)
              (o): Linear(in_features=768, out_features=768, bias=False)
            )
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (2): T5LayerFF(
            (DenseReluDense): T5DenseReluDense(
              (wi): Linear(in_features=768, out_features=3072, bias=False)
              (wo): Linear(in_features=3072, out_features=768, bias=False)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (5): T5Block(
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            (SelfAttention): T5Attention(
              (q): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (k): Linear(in_features=768, out_features=768, bias=False)
              (v): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (o): Linear(in_features=768, out_features=768, bias=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (1): T5LayerCrossAttention(
            (EncDecAttention): T5Attention(
              (q): Linear(in_features=768, out_features=768, bias=False)
              (k): Linear(in_features=768, out_features=768, bias=False)
              (v): Linear(in_features=768, out_features=768, bias=False)
              (o): Linear(in_features=768, out_features=768, bias=False)
            )
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (2): T5LayerFF(
            (DenseReluDense): T5DenseReluDense(
              (wi): Linear(in_features=768, out_features=3072, bias=False)
              (wo): Linear(in_features=3072, out_features=768, bias=False)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (6): T5Block(
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            (SelfAttention): T5Attention(
              (q): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (k): Linear(in_features=768, out_features=768, bias=False)
              (v): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (o): Linear(in_features=768, out_features=768, bias=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (1): T5LayerCrossAttention(
            (EncDecAttention): T5Attention(
              (q): Linear(in_features=768, out_features=768, bias=False)
              (k): Linear(in_features=768, out_features=768, bias=False)
              (v): Linear(in_features=768, out_features=768, bias=False)
              (o): Linear(in_features=768, out_features=768, bias=False)
            )
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (2): T5LayerFF(
            (DenseReluDense): T5DenseReluDense(
              (wi): Linear(in_features=768, out_features=3072, bias=False)
              (wo): Linear(in_features=3072, out_features=768, bias=False)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (7): T5Block(
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            (SelfAttention): T5Attention(
              (q): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (k): Linear(in_features=768, out_features=768, bias=False)
              (v): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (o): Linear(in_features=768, out_features=768, bias=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (1): T5LayerCrossAttention(
            (EncDecAttention): T5Attention(
              (q): Linear(in_features=768, out_features=768, bias=False)
              (k): Linear(in_features=768, out_features=768, bias=False)
              (v): Linear(in_features=768, out_features=768, bias=False)
              (o): Linear(in_features=768, out_features=768, bias=False)
            )
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (2): T5LayerFF(
            (DenseReluDense): T5DenseReluDense(
              (wi): Linear(in_features=768, out_features=3072, bias=False)
              (wo): Linear(in_features=3072, out_features=768, bias=False)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (8): T5Block(
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            (SelfAttention): T5Attention(
              (q): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (k): Linear(in_features=768, out_features=768, bias=False)
              (v): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (o): Linear(in_features=768, out_features=768, bias=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (1): T5LayerCrossAttention(
            (EncDecAttention): T5Attention(
              (q): Linear(in_features=768, out_features=768, bias=False)
              (k): Linear(in_features=768, out_features=768, bias=False)
              (v): Linear(in_features=768, out_features=768, bias=False)
              (o): Linear(in_features=768, out_features=768, bias=False)
            )
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (2): T5LayerFF(
            (DenseReluDense): T5DenseReluDense(
              (wi): Linear(in_features=768, out_features=3072, bias=False)
              (wo): Linear(in_features=3072, out_features=768, bias=False)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (9): T5Block(
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            (SelfAttention): T5Attention(
              (q): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (k): Linear(in_features=768, out_features=768, bias=False)
              (v): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (o): Linear(in_features=768, out_features=768, bias=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (1): T5LayerCrossAttention(
            (EncDecAttention): T5Attention(
              (q): Linear(in_features=768, out_features=768, bias=False)
              (k): Linear(in_features=768, out_features=768, bias=False)
              (v): Linear(in_features=768, out_features=768, bias=False)
              (o): Linear(in_features=768, out_features=768, bias=False)
            )
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (2): T5LayerFF(
            (DenseReluDense): T5DenseReluDense(
              (wi): Linear(in_features=768, out_features=3072, bias=False)
              (wo): Linear(in_features=3072, out_features=768, bias=False)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (10): T5Block(
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            (SelfAttention): T5Attention(
              (q): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (k): Linear(in_features=768, out_features=768, bias=False)
              (v): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (o): Linear(in_features=768, out_features=768, bias=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (1): T5LayerCrossAttention(
            (EncDecAttention): T5Attention(
              (q): Linear(in_features=768, out_features=768, bias=False)
              (k): Linear(in_features=768, out_features=768, bias=False)
              (v): Linear(in_features=768, out_features=768, bias=False)
              (o): Linear(in_features=768, out_features=768, bias=False)
            )
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (2): T5LayerFF(
            (DenseReluDense): T5DenseReluDense(
              (wi): Linear(in_features=768, out_features=3072, bias=False)
              (wo): Linear(in_features=3072, out_features=768, bias=False)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (11): T5Block(
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            (SelfAttention): T5Attention(
              (q): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (k): Linear(in_features=768, out_features=768, bias=False)
              (v): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (o): Linear(in_features=768, out_features=768, bias=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (1): T5LayerCrossAttention(
            (EncDecAttention): T5Attention(
              (q): Linear(in_features=768, out_features=768, bias=False)
              (k): Linear(in_features=768, out_features=768, bias=False)
              (v): Linear(in_features=768, out_features=768, bias=False)
              (o): Linear(in_features=768, out_features=768, bias=False)
            )
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (2): T5LayerFF(
            (DenseReluDense): T5DenseReluDense(
              (wi): Linear(in_features=768, out_features=3072, bias=False)
              (wo): Linear(in_features=3072, out_features=768, bias=False)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (adapter_layers_hyper_net): AdapterLayersOneHyperNetController(
      (layer_id_embeddings): Embedding(12, 64)
      (adapters_block_type): Embedding(3, 64)
      (task_hypernet): TaskHyperNet(
        (task_embeding_generator): Sequential(
          (0): Linear(in_features=192, out_features=128, bias=True)
          (1): ReLU()
          (2): Linear(in_features=128, out_features=64, bias=True)
        )
      )
      (LayerNorm): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
      (up_sampler_hyper_net): AdapterLayersHyperNet(
        (weight_generator): Sequential(
          (0): Linear(in_features=64, out_features=18432, bias=True)
        )
        (bias_generator): Sequential(
          (0): Linear(in_features=64, out_features=768, bias=True)
        )
      )
      (down_sampler_hyper_net): AdapterLayersHyperNet(
        (weight_generator): Sequential(
          (0): Linear(in_features=64, out_features=18432, bias=True)
        )
        (bias_generator): Sequential(
          (0): Linear(in_features=64, out_features=24, bias=True)
        )
      )
      (lora_query_a_hyper_net): LoRALayersHyperNet(
        (weight_generator): Sequential(
          (0): Linear(in_features=64, out_features=6144, bias=True)
        )
      )
      (lora_query_b_hyper_net): LoRALayersHyperNet(
        (weight_generator): Sequential(
          (0): Linear(in_features=64, out_features=6144, bias=True)
        )
      )
      (lora_value_a_hyper_net): LoRALayersHyperNet(
        (weight_generator): Sequential(
          (0): Linear(in_features=64, out_features=6144, bias=True)
        )
      )
      (lora_value_b_hyper_net): LoRALayersHyperNet(
        (weight_generator): Sequential(
          (0): Linear(in_features=64, out_features=6144, bias=True)
        )
      )
      (post_layernorm_hypernet): LayerNormHyperNet(
        (weight_generator): Linear(in_features=64, out_features=768, bias=True)
        (bias_generator): Linear(in_features=64, out_features=768, bias=True)
      )
    )
    (final_layer_norm): T5LayerNorm()
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (lm_head): Linear(in_features=768, out_features=32128, bias=False)
)
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name task_embedding_controller.task_to_embeddings.movieTrivia
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name task_embedding_controller.task_to_embeddings.movie
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name task_embedding_controller.task_to_embeddings.restaurant
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name task_embedding_controller.task_to_embeddings.atis
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name task_embedding_controller.task_to_embeddings.snips
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name task_embedding_controller.task_to_embeddings.mtod
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name task_embedding_controller.task_to_embeddings.mtop
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name encoder.block.0.layer.0.layer_norm.weight
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name encoder.block.0.layer.1.layer_norm.weight
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name encoder.block.1.layer.0.layer_norm.weight
Trainable param: layer_id_embeddings.weight
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name encoder.block.1.layer.1.layer_norm.weight
Trainable param: adapters_block_type.weight
Trainable param: task_hypernet.task_embeding_generator.0.weight
Trainable param: task_hypernet.task_embeding_generator.0.bias
Trainable param: task_hypernet.task_embeding_generator.2.weight
Trainable param: task_hypernet.task_embeding_generator.2.bias
Trainable param: LayerNorm.weight
Trainable param: LayerNorm.bias
Trainable param: up_sampler_hyper_net.weight_generator.0.weight
Trainable param: up_sampler_hyper_net.weight_generator.0.bias
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name encoder.block.2.layer.0.layer_norm.weight
Trainable param: up_sampler_hyper_net.bias_generator.0.weight
Trainable param: up_sampler_hyper_net.bias_generator.0.bias
Trainable param: down_sampler_hyper_net.weight_generator.0.weight
Trainable param: down_sampler_hyper_net.weight_generator.0.bias
Trainable param: down_sampler_hyper_net.bias_generator.0.weight
Trainable param: down_sampler_hyper_net.bias_generator.0.bias
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name encoder.block.2.layer.1.layer_norm.weight
Trainable param: lora_query_a_hyper_net.weight_generator.0.weight
Trainable param: lora_query_a_hyper_net.weight_generator.0.bias
Trainable param: lora_query_b_hyper_net.weight_generator.0.weight
Trainable param: lora_query_b_hyper_net.weight_generator.0.bias
Trainable param: lora_value_a_hyper_net.weight_generator.0.weight
Trainable param: lora_value_a_hyper_net.weight_generator.0.bias
Trainable param: lora_value_b_hyper_net.weight_generator.0.weight
Trainable param: lora_value_b_hyper_net.weight_generator.0.bias
Trainable param: post_layernorm_hypernet.weight_generator.weight
Trainable param: post_layernorm_hypernet.weight_generator.bias
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name encoder.block.3.layer.0.layer_norm.weight
Trainable param: post_layernorm_hypernet.bias_generator.weight
Trainable param: post_layernorm_hypernet.bias_generator.bias
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name encoder.block.3.layer.1.layer_norm.weight
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name encoder.block.4.layer.0.layer_norm.weight
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name encoder.block.4.layer.1.layer_norm.weight
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name encoder.block.5.layer.0.layer_norm.weight
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name encoder.block.5.layer.1.layer_norm.weight
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name encoder.block.6.layer.0.layer_norm.weight
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name encoder.block.6.layer.1.layer_norm.weight
Trainable param: layer_id_embeddings.weight
Trainable param: adapters_block_type.weight
Trainable param: task_hypernet.task_embeding_generator.0.weight
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name encoder.block.7.layer.0.layer_norm.weight
Trainable param: task_hypernet.task_embeding_generator.0.bias
Trainable param: task_hypernet.task_embeding_generator.2.weight
Trainable param: task_hypernet.task_embeding_generator.2.bias
Trainable param: LayerNorm.weight
Trainable param: LayerNorm.bias
Trainable param: up_sampler_hyper_net.weight_generator.0.weight
Trainable param: up_sampler_hyper_net.weight_generator.0.bias
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name encoder.block.7.layer.1.layer_norm.weight
Trainable param: up_sampler_hyper_net.bias_generator.0.weight
Trainable param: up_sampler_hyper_net.bias_generator.0.bias
Trainable param: down_sampler_hyper_net.weight_generator.0.weight
Trainable param: down_sampler_hyper_net.weight_generator.0.bias
Trainable param: down_sampler_hyper_net.bias_generator.0.weight
Trainable param: down_sampler_hyper_net.bias_generator.0.bias
Trainable param: lora_query_a_hyper_net.weight_generator.0.weight
Trainable param: lora_query_a_hyper_net.weight_generator.0.bias
Trainable param: lora_query_b_hyper_net.weight_generator.0.weight
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name encoder.block.8.layer.0.layer_norm.weight
Trainable param: lora_query_b_hyper_net.weight_generator.0.bias
Trainable param: lora_value_a_hyper_net.weight_generator.0.weight
Trainable param: lora_value_a_hyper_net.weight_generator.0.bias
Trainable param: lora_value_b_hyper_net.weight_generator.0.weight
Trainable param: lora_value_b_hyper_net.weight_generator.0.bias
Trainable param: post_layernorm_hypernet.weight_generator.weight
Trainable param: post_layernorm_hypernet.weight_generator.bias05/24/2024 22:14:25 - INFO - __main__ -   Parameter name encoder.block.8.layer.1.layer_norm.weight

Trainable param: post_layernorm_hypernet.bias_generator.weight
Trainable param: post_layernorm_hypernet.bias_generator.bias
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name encoder.block.9.layer.0.layer_norm.weight
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name encoder.block.9.layer.1.layer_norm.weight
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name encoder.block.10.layer.0.layer_norm.weight
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name encoder.block.10.layer.1.layer_norm.weight
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name encoder.block.11.layer.0.layer_norm.weight
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name encoder.block.11.layer.1.layer_norm.weight
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name encoder.adapter_layers_hyper_net.layer_id_embeddings.weight
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name encoder.adapter_layers_hyper_net.adapters_block_type.weight
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name encoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.0.weight
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name encoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.0.bias
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name encoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.2.weight
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name encoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.2.bias
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name encoder.adapter_layers_hyper_net.LayerNorm.weight
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name encoder.adapter_layers_hyper_net.LayerNorm.bias
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name encoder.adapter_layers_hyper_net.up_sampler_hyper_net.weight_generator.0.weight
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name encoder.adapter_layers_hyper_net.up_sampler_hyper_net.weight_generator.0.bias
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name encoder.adapter_layers_hyper_net.up_sampler_hyper_net.bias_generator.0.weight
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name encoder.adapter_layers_hyper_net.up_sampler_hyper_net.bias_generator.0.bias
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name encoder.adapter_layers_hyper_net.down_sampler_hyper_net.weight_generator.0.weight
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name encoder.adapter_layers_hyper_net.down_sampler_hyper_net.weight_generator.0.bias
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name encoder.adapter_layers_hyper_net.down_sampler_hyper_net.bias_generator.0.weight
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name encoder.adapter_layers_hyper_net.down_sampler_hyper_net.bias_generator.0.bias
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name encoder.adapter_layers_hyper_net.lora_query_a_hyper_net.weight_generator.0.weight
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name encoder.adapter_layers_hyper_net.lora_query_a_hyper_net.weight_generator.0.bias
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name encoder.adapter_layers_hyper_net.lora_query_b_hyper_net.weight_generator.0.weight
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name encoder.adapter_layers_hyper_net.lora_query_b_hyper_net.weight_generator.0.bias
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name encoder.adapter_layers_hyper_net.lora_value_a_hyper_net.weight_generator.0.weight
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name encoder.adapter_layers_hyper_net.lora_value_a_hyper_net.weight_generator.0.bias
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name encoder.adapter_layers_hyper_net.lora_value_b_hyper_net.weight_generator.0.weight
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name encoder.adapter_layers_hyper_net.lora_value_b_hyper_net.weight_generator.0.bias
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name encoder.adapter_layers_hyper_net.post_layernorm_hypernet.weight_generator.weight
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name encoder.adapter_layers_hyper_net.post_layernorm_hypernet.weight_generator.bias
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name encoder.adapter_layers_hyper_net.post_layernorm_hypernet.bias_generator.weight
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name encoder.adapter_layers_hyper_net.post_layernorm_hypernet.bias_generator.bias
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name encoder.final_layer_norm.weight
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name decoder.block.0.layer.0.layer_norm.weight
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name decoder.block.0.layer.1.layer_norm.weight
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name decoder.block.0.layer.2.layer_norm.weight
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name decoder.block.1.layer.0.layer_norm.weight
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name decoder.block.1.layer.1.layer_norm.weight
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name decoder.block.1.layer.2.layer_norm.weight
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name decoder.block.2.layer.0.layer_norm.weight
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name decoder.block.2.layer.1.layer_norm.weight
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name decoder.block.2.layer.2.layer_norm.weight
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name decoder.block.3.layer.0.layer_norm.weight
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name decoder.block.3.layer.1.layer_norm.weight
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name decoder.block.3.layer.2.layer_norm.weight
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name decoder.block.4.layer.0.layer_norm.weight
Trainable param: layer_id_embeddings.weight
Trainable param: adapters_block_type.weight
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name decoder.block.4.layer.1.layer_norm.weight
Trainable param: task_hypernet.task_embeding_generator.0.weight
Trainable param: task_hypernet.task_embeding_generator.0.bias
Trainable param: task_hypernet.task_embeding_generator.2.weight
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name decoder.block.4.layer.2.layer_norm.weight
Trainable param: task_hypernet.task_embeding_generator.2.bias
Trainable param: LayerNorm.weight
Trainable param: LayerNorm.bias
Trainable param: up_sampler_hyper_net.weight_generator.0.weight
Trainable param: up_sampler_hyper_net.weight_generator.0.bias
Trainable param: up_sampler_hyper_net.bias_generator.0.weight
Trainable param: up_sampler_hyper_net.bias_generator.0.bias
Trainable param: down_sampler_hyper_net.weight_generator.0.weight
Trainable param: down_sampler_hyper_net.weight_generator.0.bias
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name decoder.block.5.layer.0.layer_norm.weight
Trainable param: down_sampler_hyper_net.bias_generator.0.weight
Trainable param: down_sampler_hyper_net.bias_generator.0.bias
Trainable param: lora_query_a_hyper_net.weight_generator.0.weight
Trainable param: lora_query_a_hyper_net.weight_generator.0.bias
Trainable param: lora_query_b_hyper_net.weight_generator.0.weight
Trainable param: lora_query_b_hyper_net.weight_generator.0.bias
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name decoder.block.5.layer.1.layer_norm.weight
Trainable param: lora_value_a_hyper_net.weight_generator.0.weight
Trainable param: lora_value_a_hyper_net.weight_generator.0.bias
Trainable param: lora_value_b_hyper_net.weight_generator.0.weight
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name decoder.block.5.layer.2.layer_norm.weight
Trainable param: lora_value_b_hyper_net.weight_generator.0.bias
Trainable param: post_layernorm_hypernet.weight_generator.weight
Trainable param: post_layernorm_hypernet.weight_generator.bias
Trainable param: post_layernorm_hypernet.bias_generator.weight
Trainable param: post_layernorm_hypernet.bias_generator.bias
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name decoder.block.6.layer.0.layer_norm.weight
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name decoder.block.6.layer.1.layer_norm.weight
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name decoder.block.6.layer.2.layer_norm.weight
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name decoder.block.7.layer.0.layer_norm.weight
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name decoder.block.7.layer.1.layer_norm.weight
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name decoder.block.7.layer.2.layer_norm.weight
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name decoder.block.8.layer.0.layer_norm.weight
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name decoder.block.8.layer.1.layer_norm.weight
Trainable param: layer_id_embeddings.weight
Trainable param: adapters_block_type.weight
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name decoder.block.8.layer.2.layer_norm.weight
Trainable param: task_hypernet.task_embeding_generator.0.weight
Trainable param: task_hypernet.task_embeding_generator.0.bias
Trainable param: task_hypernet.task_embeding_generator.2.weight
Trainable param: task_hypernet.task_embeding_generator.2.bias
Trainable param: LayerNorm.weight
Trainable param: LayerNorm.bias
Trainable param: up_sampler_hyper_net.weight_generator.0.weight
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name decoder.block.9.layer.0.layer_norm.weight
Trainable param: up_sampler_hyper_net.weight_generator.0.bias
Trainable param: up_sampler_hyper_net.bias_generator.0.weight
Trainable param: up_sampler_hyper_net.bias_generator.0.bias
Trainable param: down_sampler_hyper_net.weight_generator.0.weight
Trainable param: down_sampler_hyper_net.weight_generator.0.bias
Trainable param: down_sampler_hyper_net.bias_generator.0.weight
Trainable param: down_sampler_hyper_net.bias_generator.0.bias
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name decoder.block.9.layer.1.layer_norm.weight
Trainable param: lora_query_a_hyper_net.weight_generator.0.weight
Trainable param: lora_query_a_hyper_net.weight_generator.0.bias
Trainable param: lora_query_b_hyper_net.weight_generator.0.weight
Trainable param: lora_query_b_hyper_net.weight_generator.0.bias
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name decoder.block.9.layer.2.layer_norm.weight
Trainable param: lora_value_a_hyper_net.weight_generator.0.weight
Trainable param: lora_value_a_hyper_net.weight_generator.0.bias
Trainable param: lora_value_b_hyper_net.weight_generator.0.weight
Trainable param: lora_value_b_hyper_net.weight_generator.0.bias
Trainable param: post_layernorm_hypernet.weight_generator.weight
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name decoder.block.10.layer.0.layer_norm.weight
Trainable param: post_layernorm_hypernet.weight_generator.bias
Trainable param: post_layernorm_hypernet.bias_generator.weight
Trainable param: post_layernorm_hypernet.bias_generator.bias
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name decoder.block.10.layer.1.layer_norm.weight
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name decoder.block.10.layer.2.layer_norm.weight
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name decoder.block.11.layer.0.layer_norm.weight
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name decoder.block.11.layer.1.layer_norm.weight
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name decoder.block.11.layer.2.layer_norm.weight
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name decoder.adapter_layers_hyper_net.layer_id_embeddings.weight
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name decoder.adapter_layers_hyper_net.adapters_block_type.weight
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name decoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.0.weight
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name decoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.0.bias
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name decoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.2.weight
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name decoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.2.bias
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name decoder.adapter_layers_hyper_net.LayerNorm.weight
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name decoder.adapter_layers_hyper_net.LayerNorm.bias
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name decoder.adapter_layers_hyper_net.up_sampler_hyper_net.weight_generator.0.weight
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name decoder.adapter_layers_hyper_net.up_sampler_hyper_net.weight_generator.0.bias
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name decoder.adapter_layers_hyper_net.up_sampler_hyper_net.bias_generator.0.weight
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name decoder.adapter_layers_hyper_net.up_sampler_hyper_net.bias_generator.0.bias
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name decoder.adapter_layers_hyper_net.down_sampler_hyper_net.weight_generator.0.weight
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name decoder.adapter_layers_hyper_net.down_sampler_hyper_net.weight_generator.0.bias
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name decoder.adapter_layers_hyper_net.down_sampler_hyper_net.bias_generator.0.weight
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name decoder.adapter_layers_hyper_net.down_sampler_hyper_net.bias_generator.0.bias
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name decoder.adapter_layers_hyper_net.lora_query_a_hyper_net.weight_generator.0.weight
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name decoder.adapter_layers_hyper_net.lora_query_a_hyper_net.weight_generator.0.bias
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name decoder.adapter_layers_hyper_net.lora_query_b_hyper_net.weight_generator.0.weight
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name decoder.adapter_layers_hyper_net.lora_query_b_hyper_net.weight_generator.0.bias
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name decoder.adapter_layers_hyper_net.lora_value_a_hyper_net.weight_generator.0.weight
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name decoder.adapter_layers_hyper_net.lora_value_a_hyper_net.weight_generator.0.bias
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name decoder.adapter_layers_hyper_net.lora_value_b_hyper_net.weight_generator.0.weight
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name decoder.adapter_layers_hyper_net.lora_value_b_hyper_net.weight_generator.0.bias
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name decoder.adapter_layers_hyper_net.post_layernorm_hypernet.weight_generator.weight
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name decoder.adapter_layers_hyper_net.post_layernorm_hypernet.weight_generator.bias
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name decoder.adapter_layers_hyper_net.post_layernorm_hypernet.bias_generator.weight
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name decoder.adapter_layers_hyper_net.post_layernorm_hypernet.bias_generator.bias
05/24/2024 22:14:25 - INFO - __main__ -   Parameter name decoder.final_layer_norm.weight
train
05/24/2024 22:14:25 - INFO - __main__ -   Total trainable parameters 8406000
05/24/2024 22:14:25 - INFO - __main__ -   Total parameters 231262320
train
train

  0%|          | 0/7034 [00:00<?, ?ex/s]
  0%|          | 0/7034 [00:00<?, ?ex/s]
  0%|          | 0/7034 [00:00<?, ?ex/s]
  0%|          | 0/7034 [00:00<?, ?ex/s]
 38%|      | 2700/7034 [00:00<00:00, 26999.45ex/s]
 34%|      | 2413/7034 [00:00<00:00, 24122.83ex/s]
 39%|      | 2753/7034 [00:00<00:00, 27528.32ex/s]
 36%|      | 2565/7034 [00:00<00:00, 25646.72ex/s]
 82%| | 5746/7034 [00:00<00:00, 27952.02ex/s]
 78%|  | 5467/7034 [00:00<00:00, 25745.68ex/s]
 83%| | 5873/7034 [00:00<00:00, 28535.06ex/s]
 79%|  | 5588/7034 [00:00<00:00, 26866.78ex/s]
100%|| 7034/7034 [00:00<00:00, 29432.27ex/s]

100%|| 7034/7034 [00:00<00:00, 28843.37ex/s]

100%|| 7034/7034 [00:00<00:00, 28246.31ex/s]

100%|| 7034/7034 [00:00<00:00, 27898.80ex/s]

  0%|          | 0/8797 [00:00<?, ?ex/s]
  0%|          | 0/8797 [00:00<?, ?ex/s]
  0%|          | 0/8797 [00:00<?, ?ex/s]
  0%|          | 0/8797 [00:00<?, ?ex/s]
 35%|      | 3035/8797 [00:00<00:00, 30340.77ex/s]
 32%|      | 2813/8797 [00:00<00:00, 28122.65ex/s]
 35%|      | 3035/8797 [00:00<00:00, 30346.63ex/s]
 34%|      | 2981/8797 [00:00<00:00, 29808.75ex/s]
 69%|   | 6079/8797 [00:00<00:00, 30369.66ex/s]
 67%|   | 5923/8797 [00:00<00:00, 28953.12ex/s]
 67%|   | 5929/8797 [00:00<00:00, 29909.41ex/s]
 68%|   | 5980/8797 [00:00<00:00, 29860.61ex/s]
 99%|| 8696/8797 [00:00<00:00, 24364.61ex/s]
100%|| 8797/8797 [00:00<00:00, 24393.00ex/s]

 99%|| 8696/8797 [00:00<00:00, 23993.59ex/s]
100%|| 8797/8797 [00:00<00:00, 24068.84ex/s]

 99%|| 8696/8797 [00:00<00:00, 24333.70ex/s]
100%|| 8797/8797 [00:00<00:00, 23978.88ex/s]

 99%|| 8696/8797 [00:00<00:00, 24196.27ex/s]
100%|| 8797/8797 [00:00<00:00, 24060.48ex/s]

  0%|          | 0/6894 [00:00<?, ?ex/s]
  0%|          | 0/6894 [00:00<?, ?ex/s]
  0%|          | 0/6894 [00:00<?, ?ex/s]
  0%|          | 0/6894 [00:00<?, ?ex/s]
 45%|     | 3093/6894 [00:00<00:00, 30929.29ex/s]
 44%|     | 3053/6894 [00:00<00:00, 30522.68ex/s]
 45%|     | 3092/6894 [00:00<00:00, 30912.95ex/s]
 44%|     | 3067/6894 [00:00<00:00, 30665.57ex/s]
 90%| | 6175/6894 [00:00<00:00, 30896.01ex/s]
 86%| | 5954/6894 [00:00<00:00, 30052.13ex/s]
 87%| | 5992/6894 [00:00<00:00, 30312.32ex/s]
 88%| | 6091/6894 [00:00<00:00, 30536.39ex/s]
100%|| 6894/6894 [00:00<00:00, 30944.73ex/s]

100%|| 6894/6894 [00:00<00:00, 29791.55ex/s]

100%|| 6894/6894 [00:00<00:00, 30573.83ex/s]

100%|| 6894/6894 [00:00<00:00, 30016.16ex/s]

  0%|          | 0/4478 [00:00<?, ?ex/s]
  0%|          | 0/4478 [00:00<?, ?ex/s]
  0%|          | 0/4478 [00:00<?, ?ex/s]
  0%|          | 0/4478 [00:00<?, ?ex/s]
 69%|   | 3069/4478 [00:00<00:00, 30686.96ex/s]
 68%|   | 3066/4478 [00:00<00:00, 30655.57ex/s]
 69%|   | 3107/4478 [00:00<00:00, 31064.47ex/s]
 70%|   | 3123/4478 [00:00<00:00, 31220.28ex/s]
100%|| 4478/4478 [00:00<00:00, 30633.58ex/s]

100%|| 4478/4478 [00:00<00:00, 31043.09ex/s]

100%|| 4478/4478 [00:00<00:00, 29616.30ex/s]

100%|| 4478/4478 [00:00<00:00, 31275.60ex/s]

  0%|          | 0/13084 [00:00<?, ?ex/s]
  0%|          | 0/13084 [00:00<?, ?ex/s]
  0%|          | 0/13084 [00:00<?, ?ex/s]
  0%|          | 0/13084 [00:00<?, ?ex/s]
 23%|       | 3073/13084 [00:00<00:00, 30725.12ex/s]
 23%|       | 3023/13084 [00:00<00:00, 30222.53ex/s]
 23%|       | 3023/13084 [00:00<00:00, 30227.65ex/s]
 23%|       | 3029/13084 [00:00<00:00, 30282.88ex/s]
 47%|     | 6154/13084 [00:00<00:00, 30748.99ex/s]
 46%|     | 6017/13084 [00:00<00:00, 30136.55ex/s]
 46%|     | 6064/13084 [00:00<00:00, 30281.12ex/s]
 47%|     | 6106/13084 [00:00<00:00, 30425.85ex/s]
 70%|   | 9224/13084 [00:00<00:00, 30733.25ex/s]
 69%|   | 9058/13084 [00:00<00:00, 30216.60ex/s]
 70%|   | 9124/13084 [00:00<00:00, 30374.67ex/s]
 70%|   | 9201/13084 [00:00<00:00, 30578.57ex/s]
 93%|| 12139/13084 [00:00<00:00, 30238.56ex/s]
 92%|| 12080/13084 [00:00<00:00, 30214.99ex/s]
 93%|| 12194/13084 [00:00<00:00, 30469.15ex/s]
 94%|| 12321/13084 [00:00<00:00, 30761.20ex/s]
100%|| 13084/13084 [00:00<00:00, 30772.52ex/s]

100%|| 13084/13084 [00:00<00:00, 30503.76ex/s]

100%|| 13084/13084 [00:00<00:00, 30342.66ex/s]

100%|| 13084/13084 [00:00<00:00, 30189.62ex/s]

  0%|          | 0/30521 [00:00<?, ?ex/s]
  0%|          | 0/30521 [00:00<?, ?ex/s]
  0%|          | 0/30521 [00:00<?, ?ex/s]
  0%|          | 0/30521 [00:00<?, ?ex/s]
 10%|         | 3079/30521 [00:00<00:00, 30786.95ex/s]
 10%|         | 3058/30521 [00:00<00:00, 30571.65ex/s]
 10%|         | 3112/30521 [00:00<00:00, 31117.28ex/s]
 10%|         | 3120/30521 [00:00<00:00, 31190.96ex/s]
 20%|        | 6124/30521 [00:00<00:00, 30683.81ex/s]
 20%|        | 6163/30521 [00:00<00:00, 30712.87ex/s]
 20%|        | 6250/30521 [00:00<00:00, 31194.76ex/s]
 20%|        | 6242/30521 [00:00<00:00, 31197.33ex/s]
 30%|       | 9223/30521 [00:00<00:00, 30772.85ex/s]
 30%|       | 9288/30521 [00:00<00:00, 30871.13ex/s]
 31%|       | 9436/30521 [00:00<00:00, 31391.18ex/s]
 30%|       | 9222/30521 [00:00<00:00, 30762.03ex/s]
 40%|      | 12327/30521 [00:00<00:00, 30851.71ex/s]
 40%|      | 12254/30521 [00:00<00:00, 30497.14ex/s]
 41%|     | 12615/30521 [00:00<00:00, 31509.07ex/s]
 41%|      | 12401/30521 [00:00<00:00, 31062.29ex/s]
 50%|     | 15389/30521 [00:00<00:00, 30779.38ex/s]
 50%|     | 15341/30521 [00:00<00:00, 30607.32ex/s]
 52%|    | 15737/30521 [00:00<00:00, 31420.14ex/s]
 50%|     | 15349/30521 [00:00<00:00, 30567.34ex/s]
 61%|    | 18497/30521 [00:00<00:00, 30868.11ex/s]
 61%|    | 18477/30521 [00:00<00:00, 30827.66ex/s]
 62%|   | 18914/30521 [00:00<00:00, 31522.51ex/s]
 61%|    | 18528/30521 [00:00<00:00, 30923.36ex/s]
 71%|   | 21605/30521 [00:00<00:00, 30929.64ex/s]
 70%|   | 21464/30521 [00:00<00:00, 30533.23ex/s]
 72%|  | 22067/30521 [00:00<00:00, 31524.34ex/s]
 71%|   | 21710/30521 [00:00<00:00, 31185.66ex/s]
 81%|  | 24714/30521 [00:00<00:00, 30974.98ex/s]
 81%|  | 24601/30521 [00:00<00:00, 30777.23ex/s]
 83%| | 25238/30521 [00:00<00:00, 31577.88ex/s]
 82%| | 24885/30521 [00:00<00:00, 31351.32ex/s]
 91%| | 27775/30521 [00:00<00:00, 30863.58ex/s]
 91%| | 27696/30521 [00:00<00:00, 30826.85ex/s]
 93%|| 28364/30521 [00:00<00:00, 31480.26ex/s]
 91%|| 27874/30521 [00:00<00:00, 30896.69ex/s]
100%|| 30521/30521 [00:00<00:00, 31511.07ex/s]

100%|| 30521/30521 [00:00<00:00, 30863.85ex/s]

100%|| 30521/30521 [00:00<00:00, 31012.79ex/s]

100%|| 30521/30521 [00:00<00:00, 30655.14ex/s]

  0%|          | 0/15667 [00:00<?, ?ex/s]
  0%|          | 0/15667 [00:00<?, ?ex/s]
  0%|          | 0/15667 [00:00<?, ?ex/s]
  0%|          | 0/15667 [00:00<?, ?ex/s]
 20%|        | 3075/15667 [00:00<00:00, 30746.80ex/s]
 19%|        | 3020/15667 [00:00<00:00, 30196.65ex/s]
 20%|        | 3121/15667 [00:00<00:00, 31204.45ex/s]
 19%|        | 2931/15667 [00:00<00:00, 29305.14ex/s]
 39%|      | 6145/15667 [00:00<00:00, 30732.01ex/s]
 39%|      | 6135/15667 [00:00<00:00, 30476.01ex/s]
 40%|      | 6231/15667 [00:00<00:00, 31170.55ex/s]
 38%|      | 5929/15667 [00:00<00:00, 29503.19ex/s]
 58%|    | 9042/15667 [00:00<00:00, 30179.04ex/s]
 59%|    | 9258/15667 [00:00<00:00, 30696.23ex/s]
 59%|    | 9240/15667 [00:00<00:00, 30837.79ex/s]
 58%|    | 9023/15667 [00:00<00:00, 29919.18ex/s]
 78%|  | 12149/15667 [00:00<00:00, 30439.67ex/s]
 79%|  | 12379/15667 [00:00<00:00, 30846.66ex/s]
 78%|  | 12251/15667 [00:00<00:00, 30613.70ex/s]
 78%|  | 12155/15667 [00:00<00:00, 30324.36ex/s]
 97%|| 15203/15667 [00:00<00:00, 30467.03ex/s]
 99%|| 15443/15667 [00:00<00:00, 30781.93ex/s]
 98%|| 15375/15667 [00:00<00:00, 30796.30ex/s]
 97%|| 15249/15667 [00:00<00:00, 30504.49ex/s]
100%|| 15667/15667 [00:00<00:00, 30885.41ex/s]

100%|| 15667/15667 [00:00<00:00, 30425.90ex/s]
validation
validation

100%|| 15667/15667 [00:00<00:00, 30759.09ex/s]
validation

100%|| 15667/15667 [00:00<00:00, 30483.59ex/s]
validation

  0%|          | 0/782 [00:00<?, ?ex/s]
  0%|          | 0/782 [00:00<?, ?ex/s]
  0%|          | 0/782 [00:00<?, ?ex/s]
  0%|          | 0/782 [00:00<?, ?ex/s]
100%|| 782/782 [00:00<00:00, 32026.34ex/s]

100%|| 782/782 [00:00<00:00, 31608.15ex/s]

100%|| 782/782 [00:00<00:00, 25602.97ex/s]

100%|| 782/782 [00:00<00:00, 31126.41ex/s]

  0%|          | 0/978 [00:00<?, ?ex/s]
  0%|          | 0/978 [00:00<?, ?ex/s]
100%|| 978/978 [00:00<00:00, 32094.74ex/s]

  0%|          | 0/978 [00:00<?, ?ex/s]
  0%|          | 0/766 [00:00<?, ?ex/s]
  0%|          | 0/978 [00:00<?, ?ex/s]
100%|| 978/978 [00:00<00:00, 32257.53ex/s]

100%|| 766/766 [00:00<00:00, 31707.30ex/s]

  0%|          | 0/766 [00:00<?, ?ex/s]
100%|| 978/978 [00:00<00:00, 31075.04ex/s]

100%|| 978/978 [00:00<00:00, 31252.84ex/s]

  0%|          | 0/500 [00:00<?, ?ex/s]
  0%|          | 0/766 [00:00<?, ?ex/s]
  0%|          | 0/766 [00:00<?, ?ex/s]
100%|| 766/766 [00:00<00:00, 31852.53ex/s]

100%|| 500/500 [00:00<00:00, 31792.37ex/s]

  0%|          | 0/500 [00:00<?, ?ex/s]
  0%|          | 0/700 [00:00<?, ?ex/s]
100%|| 766/766 [00:00<00:00, 31128.22ex/s]

100%|| 766/766 [00:00<00:00, 31182.60ex/s]

  0%|          | 0/500 [00:00<?, ?ex/s]
  0%|          | 0/500 [00:00<?, ?ex/s]
100%|| 500/500 [00:00<00:00, 31981.46ex/s]

  0%|          | 0/700 [00:00<?, ?ex/s]
100%|| 500/500 [00:00<00:00, 31334.45ex/s]

100%|| 700/700 [00:00<00:00, 25313.29ex/s]

100%|| 500/500 [00:00<00:00, 30879.52ex/s]

  0%|          | 0/700 [00:00<?, ?ex/s]
  0%|          | 0/700 [00:00<?, ?ex/s]
100%|| 700/700 [00:00<00:00, 31600.27ex/s]

100%|| 700/700 [00:00<00:00, 31128.54ex/s]

100%|| 700/700 [00:00<00:00, 31281.43ex/s]

  0%|          | 0/4181 [00:00<?, ?ex/s]
  0%|          | 0/4181 [00:00<?, ?ex/s]
  0%|          | 0/4181 [00:00<?, ?ex/s]
  0%|          | 0/4181 [00:00<?, ?ex/s]
 74%|  | 3087/4181 [00:00<00:00, 30863.77ex/s]
 74%|  | 3077/4181 [00:00<00:00, 30768.78ex/s]
 75%|  | 3143/4181 [00:00<00:00, 31422.09ex/s]
 74%|  | 3110/4181 [00:00<00:00, 31095.95ex/s]
100%|| 4181/4181 [00:00<00:00, 30806.72ex/s]

100%|| 4181/4181 [00:00<00:00, 31500.60ex/s]

100%|| 4181/4181 [00:00<00:00, 30913.54ex/s]

100%|| 4181/4181 [00:00<00:00, 31097.13ex/s]

  0%|          | 0/2235 [00:00<?, ?ex/s]
  0%|          | 0/2235 [00:00<?, ?ex/s]
  0%|          | 0/2235 [00:00<?, ?ex/s]
  0%|          | 0/2235 [00:00<?, ?ex/s]
100%|| 2235/2235 [00:00<00:00, 31493.64ex/s]
test

100%|| 2235/2235 [00:00<00:00, 31080.76ex/s]
test

100%|| 2235/2235 [00:00<00:00, 31130.41ex/s]
test

100%|| 2235/2235 [00:00<00:00, 31234.76ex/s]
test

  0%|          | 0/1953 [00:00<?, ?ex/s]
  0%|          | 0/1953 [00:00<?, ?ex/s]
  0%|          | 0/1953 [00:00<?, ?ex/s]
  0%|          | 0/1953 [00:00<?, ?ex/s]
100%|| 1953/1953 [00:00<00:00, 31023.62ex/s]

100%|| 1953/1953 [00:00<00:00, 30950.82ex/s]

100%|| 1953/1953 [00:00<00:00, 30698.89ex/s]

100%|| 1953/1953 [00:00<00:00, 30670.95ex/s]

  0%|          | 0/2443 [00:00<?, ?ex/s]
  0%|          | 0/2443 [00:00<?, ?ex/s]
  0%|          | 0/2443 [00:00<?, ?ex/s]
  0%|          | 0/2443 [00:00<?, ?ex/s]
100%|| 2443/2443 [00:00<00:00, 31491.73ex/s]

100%|| 2443/2443 [00:00<00:00, 31037.67ex/s]

100%|| 2443/2443 [00:00<00:00, 31063.27ex/s]

100%|| 2443/2443 [00:00<00:00, 30618.93ex/s]

  0%|          | 0/1521 [00:00<?, ?ex/s]
  0%|          | 0/1521 [00:00<?, ?ex/s]
  0%|          | 0/1521 [00:00<?, ?ex/s]
  0%|          | 0/1521 [00:00<?, ?ex/s]
100%|| 1521/1521 [00:00<00:00, 31485.85ex/s]

100%|| 1521/1521 [00:00<00:00, 31304.62ex/s]

100%|| 1521/1521 [00:00<00:00, 30861.51ex/s]

100%|| 1521/1521 [00:00<00:00, 30628.88ex/s]

  0%|          | 0/893 [00:00<?, ?ex/s]
  0%|          | 0/893 [00:00<?, ?ex/s]
  0%|          | 0/893 [00:00<?, ?ex/s]
  0%|          | 0/893 [00:00<?, ?ex/s]
100%|| 893/893 [00:00<00:00, 31593.58ex/s]

100%|| 893/893 [00:00<00:00, 30981.54ex/s]

100%|| 893/893 [00:00<00:00, 31711.54ex/s]

100%|| 893/893 [00:00<00:00, 32033.74ex/s]

  0%|          | 0/700 [00:00<?, ?ex/s]
  0%|          | 0/700 [00:00<?, ?ex/s]
  0%|          | 0/700 [00:00<?, ?ex/s]
  0%|          | 0/700 [00:00<?, ?ex/s]
100%|| 700/700 [00:00<00:00, 25720.20ex/s]

100%|| 700/700 [00:00<00:00, 26010.73ex/s]

100%|| 700/700 [00:00<00:00, 22420.53ex/s]

100%|| 700/700 [00:00<00:00, 22397.10ex/s]

  0%|          | 0/8621 [00:00<?, ?ex/s]
  0%|          | 0/8621 [00:00<?, ?ex/s]
  0%|          | 0/8621 [00:00<?, ?ex/s]
  0%|          | 0/8621 [00:00<?, ?ex/s]
 35%|      | 2993/8621 [00:00<00:00, 29924.04ex/s]
 36%|      | 3077/8621 [00:00<00:00, 30764.16ex/s]
 35%|      | 2983/8621 [00:00<00:00, 29825.83ex/s]
 36%|      | 3101/8621 [00:00<00:00, 31001.16ex/s]
 69%|   | 5983/8621 [00:00<00:00, 29915.14ex/s]
 72%|  | 6181/8621 [00:00<00:00, 30844.43ex/s]
 69%|   | 5920/8621 [00:00<00:00, 29686.95ex/s]
 72%|  | 6223/8621 [00:00<00:00, 31066.32ex/s]
100%|| 8621/8621 [00:00<00:00, 30902.12ex/s]

100%|| 8621/8621 [00:00<00:00, 31167.47ex/s]

100%|| 8621/8621 [00:00<00:00, 30057.04ex/s]

100%|| 8621/8621 [00:00<00:00, 29450.39ex/s]

  0%|          | 0/4386 [00:00<?, ?ex/s]
  0%|          | 0/4386 [00:00<?, ?ex/s]
  0%|          | 0/4386 [00:00<?, ?ex/s]
  0%|          | 0/4386 [00:00<?, ?ex/s]
 71%|  | 3127/4386 [00:00<00:00, 31268.32ex/s]
 66%|   | 2881/4386 [00:00<00:00, 28806.73ex/s]
 70%|   | 3068/4386 [00:00<00:00, 30671.91ex/s]
 69%|   | 3037/4386 [00:00<00:00, 30364.38ex/s]
100%|| 4386/4386 [00:00<00:00, 31119.74ex/s]

100%|| 4386/4386 [00:00<00:00, 30699.20ex/s]

100%|| 4386/4386 [00:00<00:00, 29340.43ex/s]

100%|| 4386/4386 [00:00<00:00, 30640.80ex/s]
05/24/2024 22:14:29 - INFO - utils.utils -   ***** arguments metrics *****
05/24/2024 22:14:29 - INFO - utils.utils -     adafactor = False
05/24/2024 22:14:29 - INFO - utils.utils -     adam_beta1 = 0.9
05/24/2024 22:14:29 - INFO - utils.utils -     adam_beta2 = 0.999
05/24/2024 22:14:29 - INFO - utils.utils -     adam_epsilon = 1e-08
05/24/2024 22:14:29 - INFO - utils.utils -     adapter_config_name = meta-adapter
05/24/2024 22:14:29 - INFO - utils.utils -     adapters = None
05/24/2024 22:14:29 - INFO - utils.utils -     add_layer_norm_after_adapter = True
05/24/2024 22:14:29 - INFO - utils.utils -     add_layer_norm_before_adapter = False
05/24/2024 22:14:29 - INFO - utils.utils -     attention_dropout = None
05/24/2024 22:14:29 - INFO - utils.utils -     cache_dir = None
05/24/2024 22:14:29 - INFO - utils.utils -     compute_memory = False
05/24/2024 22:14:29 - INFO - utils.utils -     compute_time = False
05/24/2024 22:14:29 - INFO - utils.utils -     conditional_layer_norm = True
05/24/2024 22:14:29 - INFO - utils.utils -     config_name = None
05/24/2024 22:14:29 - INFO - utils.utils -     data_seed = 42
05/24/2024 22:14:29 - INFO - utils.utils -     dataloader_drop_last = False
05/24/2024 22:14:29 - INFO - utils.utils -     dataloader_num_workers = 0
05/24/2024 22:14:29 - INFO - utils.utils -     debug = False
05/24/2024 22:14:29 - INFO - utils.utils -     decoder_layerdrop = None
05/24/2024 22:14:29 - INFO - utils.utils -     disable_tqdm = True
05/24/2024 22:14:29 - INFO - utils.utils -     do_eval = True
05/24/2024 22:14:29 - INFO - utils.utils -     do_predict = False
05/24/2024 22:14:29 - INFO - utils.utils -     do_test = True
05/24/2024 22:14:29 - INFO - utils.utils -     do_train = True
05/24/2024 22:14:29 - INFO - utils.utils -     dropout = None
05/24/2024 22:14:29 - INFO - utils.utils -     efficient_unique_hyper_net = True
05/24/2024 22:14:29 - INFO - utils.utils -     encoder_layerdrop = None
05/24/2024 22:14:29 - INFO - utils.utils -     eval_accumulation_steps = None
05/24/2024 22:14:29 - INFO - utils.utils -     eval_beams = 1
05/24/2024 22:14:29 - INFO - utils.utils -     eval_output_dir = None
05/24/2024 22:14:29 - INFO - utils.utils -     eval_steps = 1000
05/24/2024 22:14:29 - INFO - utils.utils -     eval_tasks = ['movieTrivia', 'movie', 'restaurant', 'atis', 'snips', 'mtod', 'mtop']
05/24/2024 22:14:29 - INFO - utils.utils -     evaluate_during_training = False
05/24/2024 22:14:29 - INFO - utils.utils -     fp16 = False
05/24/2024 22:14:29 - INFO - utils.utils -     fp16_opt_level = O1
05/24/2024 22:14:29 - INFO - utils.utils -     freeze_embeds = False
05/24/2024 22:14:29 - INFO - utils.utils -     freeze_encoder = False
05/24/2024 22:14:29 - INFO - utils.utils -     freeze_model = False
05/24/2024 22:14:29 - INFO - utils.utils -     freeze_model_but_lm_head = False
05/24/2024 22:14:29 - INFO - utils.utils -     freeze_model_but_task_embeddings = False
05/24/2024 22:14:29 - INFO - utils.utils -     generate_classifier_weights = False
05/24/2024 22:14:29 - INFO - utils.utils -     gradient_accumulation_steps = 1
05/24/2024 22:14:29 - INFO - utils.utils -     greater_is_better = True
05/24/2024 22:14:29 - INFO - utils.utils -     hidden_dim = 128
05/24/2024 22:14:29 - INFO - utils.utils -     ignore_pad_token_for_loss = True
05/24/2024 22:14:29 - INFO - utils.utils -     label_names = None
05/24/2024 22:14:29 - INFO - utils.utils -     label_smoothing = 0.1
05/24/2024 22:14:29 - INFO - utils.utils -     learning_rate = 0.0003
05/24/2024 22:14:29 - INFO - utils.utils -     load_best_model_at_end = True
05/24/2024 22:14:29 - INFO - utils.utils -     local_rank = 0
05/24/2024 22:14:29 - INFO - utils.utils -     logging_dir = runs/May24_22-14-10_gpu-16
05/24/2024 22:14:29 - INFO - utils.utils -     logging_first_step = True
05/24/2024 22:14:29 - INFO - utils.utils -     logging_steps = 200
05/24/2024 22:14:29 - INFO - utils.utils -     lr_scheduler = linear
05/24/2024 22:14:29 - INFO - utils.utils -     max_grad_norm = 1.0
05/24/2024 22:14:29 - INFO - utils.utils -     max_source_length = 128
05/24/2024 22:14:29 - INFO - utils.utils -     max_steps = 65536
05/24/2024 22:14:29 - INFO - utils.utils -     max_target_length = 128
05/24/2024 22:14:29 - INFO - utils.utils -     metric_for_best_model = average_metrics
05/24/2024 22:14:29 - INFO - utils.utils -     model_name_or_path = t5-base
05/24/2024 22:14:29 - INFO - utils.utils -     n_test = -1
05/24/2024 22:14:29 - INFO - utils.utils -     n_train = -1
05/24/2024 22:14:29 - INFO - utils.utils -     n_val = -1
05/24/2024 22:14:29 - INFO - utils.utils -     no_cuda = False
05/24/2024 22:14:29 - INFO - utils.utils -     non_linearity = gelu_new
05/24/2024 22:14:29 - INFO - utils.utils -     not_load_t5_checkpoint = False
05/24/2024 22:14:29 - INFO - utils.utils -     num_train_epochs = 100
05/24/2024 22:14:29 - INFO - utils.utils -     optimize_from_scratch = False
05/24/2024 22:14:29 - INFO - utils.utils -     optimize_from_scratch_with_loading_model = False
05/24/2024 22:14:29 - INFO - utils.utils -     output_dir = outputs/hyperformer_al++/
05/24/2024 22:14:29 - INFO - utils.utils -     overwrite_output_dir = True
05/24/2024 22:14:29 - INFO - utils.utils -     past_index = -1
05/24/2024 22:14:29 - INFO - utils.utils -     per_device_eval_batch_size = 32
05/24/2024 22:14:29 - INFO - utils.utils -     per_device_train_batch_size = 32
05/24/2024 22:14:29 - INFO - utils.utils -     per_gpu_eval_batch_size = None
05/24/2024 22:14:29 - INFO - utils.utils -     per_gpu_train_batch_size = None
05/24/2024 22:14:29 - INFO - utils.utils -     predict_with_generate = True
05/24/2024 22:14:29 - INFO - utils.utils -     prediction_loss_only = False
05/24/2024 22:14:29 - INFO - utils.utils -     print_num_parameters = True
05/24/2024 22:14:29 - INFO - utils.utils -     projected_task_embedding_dim = 64
05/24/2024 22:14:29 - INFO - utils.utils -     reduction_factor = 32
05/24/2024 22:14:29 - INFO - utils.utils -     remove_unused_columns = False
05/24/2024 22:14:29 - INFO - utils.utils -     run_name = outputs/hyperformer_al++/
05/24/2024 22:14:29 - INFO - utils.utils -     save_steps = 1000
05/24/2024 22:14:29 - INFO - utils.utils -     save_total_limit = 1
05/24/2024 22:14:29 - INFO - utils.utils -     seed = 42
05/24/2024 22:14:29 - INFO - utils.utils -     split_validation_test = True
05/24/2024 22:14:29 - INFO - utils.utils -     task_embedding_dim = 64
05/24/2024 22:14:29 - INFO - utils.utils -     task_embeddings = None
05/24/2024 22:14:29 - INFO - utils.utils -     task_hidden_dim = 128
05/24/2024 22:14:29 - INFO - utils.utils -     tasks = ['movieTrivia', 'movie', 'restaurant', 'atis', 'snips', 'mtod', 'mtop']
05/24/2024 22:14:29 - INFO - utils.utils -     temperature = 10
05/24/2024 22:14:29 - INFO - utils.utils -     test_max_target_length = 128
05/24/2024 22:14:29 - INFO - utils.utils -     tokenizer_name = t5-base
05/24/2024 22:14:29 - INFO - utils.utils -     tpu_metrics_debug = False
05/24/2024 22:14:29 - INFO - utils.utils -     tpu_num_cores = None
05/24/2024 22:14:29 - INFO - utils.utils -     train_adapters = True
05/24/2024 22:14:29 - INFO - utils.utils -     train_adapters_blocks = True
05/24/2024 22:14:29 - INFO - utils.utils -     train_task_embeddings = False
05/24/2024 22:14:29 - INFO - utils.utils -     unfreeze_layer_norms = True
05/24/2024 22:14:29 - INFO - utils.utils -     unfreeze_lm_head = False
05/24/2024 22:14:29 - INFO - utils.utils -     unfreeze_model = False
05/24/2024 22:14:29 - INFO - utils.utils -     unique_hyper_net = False
05/24/2024 22:14:29 - INFO - utils.utils -     unique_hyper_net_layer_norm = True
05/24/2024 22:14:29 - INFO - utils.utils -     val_max_target_length = 128
05/24/2024 22:14:29 - INFO - utils.utils -     warmup_steps = 500
05/24/2024 22:14:29 - INFO - utils.utils -     weight_decay = 0.0
05/24/2024 22:14:30 - INFO - third_party.trainers.t5_trainer -   ***** Running training *****
05/24/2024 22:14:30 - INFO - third_party.trainers.t5_trainer -     Num examples = 86475
05/24/2024 22:14:30 - INFO - third_party.trainers.t5_trainer -     Num Epochs = 98
05/24/2024 22:14:30 - INFO - third_party.trainers.t5_trainer -     Instantaneous batch size per device = 32
05/24/2024 22:14:30 - INFO - third_party.trainers.t5_trainer -     Total train batch size (w. parallel, distributed & accumulation) = 128
05/24/2024 22:14:30 - INFO - third_party.trainers.t5_trainer -     Gradient Accumulation steps = 1
05/24/2024 22:14:30 - INFO - third_party.trainers.t5_trainer -     Total optimization steps = 65536
{'loss': 7207.42333984375, 'learning_rate': 6e-07, 'epoch': 0.0014814814814814814}
{'loss': 4552.155850051036, 'learning_rate': 0.00011999999999999999, 'epoch': 0.2962962962962963}
{'loss': 2113.2084375, 'learning_rate': 0.00023999999999999998, 'epoch': 0.5925925925925926}
{'loss': 1911.28, 'learning_rate': 0.00029953871701826677, 'epoch': 0.8888888888888888}
{'loss': 1726.7875, 'learning_rate': 0.0002986161510548004, 'epoch': 1.1851851851851851}
{'loss': 1554.806875, 'learning_rate': 0.000297693585091334, 'epoch': 1.4814814814814814}
05/24/2024 22:20:48 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/24/2024 22:22:04 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 2102.087158203125
05/24/2024 22:22:04 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.4795865633074935
05/24/2024 22:22:04 - INFO - utils.utils -   config is reset to the initial values.
05/24/2024 22:22:04 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/24/2024 22:23:14 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1292.88037109375
05/24/2024 22:23:14 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.6650909950366344
05/24/2024 22:23:14 - INFO - utils.utils -   config is reset to the initial values.
05/24/2024 22:23:14 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/24/2024 22:24:04 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1092.6051025390625
05/24/2024 22:24:04 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.6159280667951189
05/24/2024 22:24:04 - INFO - utils.utils -   config is reset to the initial values.
05/24/2024 22:24:04 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/24/2024 22:24:48 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 2088.778564453125
05/24/2024 22:24:48 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.6827545615067687
05/24/2024 22:24:48 - INFO - utils.utils -   config is reset to the initial values.
05/24/2024 22:24:48 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/24/2024 22:25:36 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1253.42333984375
05/24/2024 22:25:36 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.5200222469410456
05/24/2024 22:25:36 - INFO - utils.utils -   config is reset to the initial values.
05/24/2024 22:25:36 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/24/2024 22:29:40 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 826.7274169921875
05/24/2024 22:29:40 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.7003688799463447
05/24/2024 22:29:40 - INFO - utils.utils -   config is reset to the initial values.
05/24/2024 22:29:40 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/24/2024 22:32:16 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1317.2745361328125
05/24/2024 22:32:16 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.41765517241379313
05/24/2024 22:32:16 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1464.5875, 'learning_rate': 0.0002967710191278676, 'epoch': 1.7777777777777777}
{'loss': 1422.835, 'learning_rate': 0.0002958484531644012, 'epoch': 2.074074074074074}
{'loss': 1475.17, 'learning_rate': 0.00029492588720093487, 'epoch': 2.3703703703703702}
{'loss': 1441.17125, 'learning_rate': 0.00029400332123746847, 'epoch': 2.6666666666666665}
{'loss': 1405.52, 'learning_rate': 0.00029308075527400206, 'epoch': 2.962962962962963}
05/24/2024 22:38:35 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/24/2024 22:39:51 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1986.656005859375
05/24/2024 22:39:51 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.6059594755661503
05/24/2024 22:39:51 - INFO - utils.utils -   config is reset to the initial values.
05/24/2024 22:39:51 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/24/2024 22:41:01 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1229.772705078125
05/24/2024 22:41:01 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.8131504257332072
05/24/2024 22:41:01 - INFO - utils.utils -   config is reset to the initial values.
05/24/2024 22:41:01 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/24/2024 22:41:52 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1051.7022705078125
05/24/2024 22:41:52 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.7335526315789473
05/24/2024 22:41:52 - INFO - utils.utils -   config is reset to the initial values.
05/24/2024 22:41:52 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/24/2024 22:42:37 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1932.2572021484375
05/24/2024 22:42:37 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.8573928258967629
05/24/2024 22:42:37 - INFO - utils.utils -   config is reset to the initial values.
05/24/2024 22:42:37 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/24/2024 22:43:24 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1115.7623291015625
05/24/2024 22:43:24 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.8008936051382296
05/24/2024 22:43:24 - INFO - utils.utils -   config is reset to the initial values.
05/24/2024 22:43:24 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/24/2024 22:47:28 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 779.839599609375
05/24/2024 22:47:28 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.937575800813298
05/24/2024 22:47:28 - INFO - utils.utils -   config is reset to the initial values.
05/24/2024 22:47:28 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/24/2024 22:50:06 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1200.086669921875
05/24/2024 22:50:06 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.5753850501624983
05/24/2024 22:50:06 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1445.135, 'learning_rate': 0.00029215818931053566, 'epoch': 3.259259259259259}
{'loss': 1387.60875, 'learning_rate': 0.0002912356233470693, 'epoch': 3.5555555555555554}
{'loss': 1398.6125, 'learning_rate': 0.0002903130573836029, 'epoch': 3.851851851851852}
{'loss': 1411.7925, 'learning_rate': 0.0002893904914201365, 'epoch': 4.148148148148148}
{'loss': 1417.745, 'learning_rate': 0.0002884679254566701, 'epoch': 4.444444444444445}
05/24/2024 22:56:26 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/24/2024 22:57:44 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1968.2738037109375
05/24/2024 22:57:44 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.6330457863304578
05/24/2024 22:57:44 - INFO - utils.utils -   config is reset to the initial values.
05/24/2024 22:57:44 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/24/2024 22:58:54 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1206.89208984375
05/24/2024 22:58:54 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.8429791271347249
05/24/2024 22:58:54 - INFO - utils.utils -   config is reset to the initial values.
05/24/2024 22:58:54 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/24/2024 22:59:45 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1046.6771240234375
05/24/2024 22:59:45 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.7375478927203066
05/24/2024 22:59:45 - INFO - utils.utils -   config is reset to the initial values.
05/24/2024 22:59:45 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/24/2024 23:00:30 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1896.908447265625
05/24/2024 23:00:30 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.9155711364300321
05/24/2024 23:00:30 - INFO - utils.utils -   config is reset to the initial values.
05/24/2024 23:00:30 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/24/2024 23:01:17 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1096.95361328125
05/24/2024 23:01:17 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.8520055325034579
05/24/2024 23:01:17 - INFO - utils.utils -   config is reset to the initial values.
05/24/2024 23:01:17 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/24/2024 23:05:20 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 776.688720703125
05/24/2024 23:05:20 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.9433345183078563
05/24/2024 23:05:20 - INFO - utils.utils -   config is reset to the initial values.
05/24/2024 23:05:20 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/24/2024 23:07:50 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1172.86376953125
05/24/2024 23:07:50 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.6711700229416264
05/24/2024 23:07:50 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1354.2425, 'learning_rate': 0.00028754535949320376, 'epoch': 4.7407407407407405}
{'loss': 1342.8175, 'learning_rate': 0.00028662279352973736, 'epoch': 5.037037037037037}
{'loss': 1396.1475, 'learning_rate': 0.00028570022756627095, 'epoch': 5.333333333333333}
{'loss': 1357.5575, 'learning_rate': 0.00028477766160280455, 'epoch': 5.62962962962963}
{'loss': 1420.5975, 'learning_rate': 0.0002838550956393382, 'epoch': 5.925925925925926}
05/24/2024 23:14:08 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/24/2024 23:15:27 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1972.9515380859375
05/24/2024 23:15:27 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.6264555193292967
05/24/2024 23:15:27 - INFO - utils.utils -   config is reset to the initial values.
05/24/2024 23:15:27 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/24/2024 23:16:39 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1202.411865234375
05/24/2024 23:16:39 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.8547049063759184
05/24/2024 23:16:39 - INFO - utils.utils -   config is reset to the initial values.
05/24/2024 23:16:39 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/24/2024 23:17:30 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1036.3330078125
05/24/2024 23:17:30 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.7542706964520367
05/24/2024 23:17:30 - INFO - utils.utils -   config is reset to the initial values.
05/24/2024 23:17:30 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/24/2024 23:18:16 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1881.9132080078125
05/24/2024 23:18:16 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.9473991817650497
05/24/2024 23:18:16 - INFO - utils.utils -   config is reset to the initial values.
05/24/2024 23:18:16 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/24/2024 23:19:03 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1080.8829345703125
05/24/2024 23:19:03 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.8786031042128604
05/24/2024 23:19:03 - INFO - utils.utils -   config is reset to the initial values.
05/24/2024 23:19:03 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/24/2024 23:23:09 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 774.3021850585938
05/24/2024 23:23:09 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.9481576692373607
05/24/2024 23:23:09 - INFO - utils.utils -   config is reset to the initial values.
05/24/2024 23:23:09 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/24/2024 23:25:45 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1159.1002197265625
05/24/2024 23:25:45 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.7107049608355092
05/24/2024 23:25:45 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1314.56, 'learning_rate': 0.0002829325296758718, 'epoch': 6.222222222222222}
{'loss': 1314.06, 'learning_rate': 0.0002820099637124054, 'epoch': 6.518518518518518}
{'loss': 1426.455, 'learning_rate': 0.00028108739774893905, 'epoch': 6.814814814814815}
{'loss': 1308.3075, 'learning_rate': 0.0002801648317854726, 'epoch': 7.111111111111111}
{'loss': 1325.55, 'learning_rate': 0.00027924226582200625, 'epoch': 7.407407407407407}
05/24/2024 23:32:05 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/24/2024 23:33:19 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1948.4652099609375
05/24/2024 23:33:19 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.6455667789001123
05/24/2024 23:33:19 - INFO - utils.utils -   config is reset to the initial values.
05/24/2024 23:33:19 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/24/2024 23:34:28 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1192.79443359375
05/24/2024 23:34:28 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.8507109004739336
05/24/2024 23:34:28 - INFO - utils.utils -   config is reset to the initial values.
05/24/2024 23:34:28 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/24/2024 23:35:17 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1034.2772216796875
05/24/2024 23:35:17 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.763951250801796
05/24/2024 23:35:17 - INFO - utils.utils -   config is reset to the initial values.
05/24/2024 23:35:17 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/24/2024 23:36:02 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1861.691650390625
05/24/2024 23:36:02 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.9608187134502923
05/24/2024 23:36:02 - INFO - utils.utils -   config is reset to the initial values.
05/24/2024 23:36:02 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/24/2024 23:36:49 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1076.956298828125
05/24/2024 23:36:49 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.8793817278498482
05/24/2024 23:36:49 - INFO - utils.utils -   config is reset to the initial values.
05/24/2024 23:36:49 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/24/2024 23:40:51 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 771.723388671875
05/24/2024 23:40:51 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.9472331310246341
05/24/2024 23:40:51 - INFO - utils.utils -   config is reset to the initial values.
05/24/2024 23:40:51 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/24/2024 23:43:21 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1149.3638916015625
05/24/2024 23:43:21 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.723784494086728
05/24/2024 23:43:21 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1315.5725, 'learning_rate': 0.00027831969985853984, 'epoch': 7.703703703703704}
{'loss': 1303.92, 'learning_rate': 0.0002773971338950735, 'epoch': 8.0}
{'loss': 1316.465, 'learning_rate': 0.0002764745679316071, 'epoch': 8.296296296296296}
{'loss': 1352.225, 'learning_rate': 0.0002755520019681407, 'epoch': 8.592592592592592}
{'loss': 1333.425, 'learning_rate': 0.0002746294360046743, 'epoch': 8.88888888888889}
05/24/2024 23:49:36 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/24/2024 23:50:50 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1950.8304443359375
05/24/2024 23:50:50 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.6606553771717616
05/24/2024 23:50:50 - INFO - utils.utils -   config is reset to the initial values.
05/24/2024 23:50:50 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/24/2024 23:51:59 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1197.9713134765625
05/24/2024 23:51:59 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.8546214584300975
05/24/2024 23:51:59 - INFO - utils.utils -   config is reset to the initial values.
05/24/2024 23:51:59 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/24/2024 23:52:49 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1036.5313720703125
05/24/2024 23:52:49 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.7545952918413416
05/24/2024 23:52:49 - INFO - utils.utils -   config is reset to the initial values.
05/24/2024 23:52:49 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/24/2024 23:53:34 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1865.0609130859375
05/24/2024 23:53:34 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.9625730994152047
05/24/2024 23:53:34 - INFO - utils.utils -   config is reset to the initial values.
05/24/2024 23:53:34 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/24/2024 23:54:22 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1074.73193359375
05/24/2024 23:54:22 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.8968011126564673
05/24/2024 23:54:22 - INFO - utils.utils -   config is reset to the initial values.
05/24/2024 23:54:22 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/24/2024 23:58:28 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 773.4996337890625
05/24/2024 23:58:28 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.9447957371225577
05/24/2024 23:58:28 - INFO - utils.utils -   config is reset to the initial values.
05/24/2024 23:58:28 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/25/2024 00:01:04 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1137.7474365234375
05/25/2024 00:01:04 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.7499034624790835
05/25/2024 00:01:04 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1293.535, 'learning_rate': 0.00027370687004120794, 'epoch': 9.185185185185185}
{'loss': 1300.475, 'learning_rate': 0.00027278430407774154, 'epoch': 9.481481481481481}
{'loss': 1307.19, 'learning_rate': 0.00027186173811427514, 'epoch': 9.777777777777779}
{'loss': 1343.045, 'learning_rate': 0.00027093917215080873, 'epoch': 10.074074074074074}
{'loss': 1320.16, 'learning_rate': 0.0002700166061873424, 'epoch': 10.37037037037037}
05/25/2024 00:07:20 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/25/2024 00:08:33 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1940.1297607421875
05/25/2024 00:08:33 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.6448782627769248
05/25/2024 00:08:33 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 00:08:33 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/25/2024 00:09:43 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1190.2376708984375
05/25/2024 00:09:43 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.8549870313605282
05/25/2024 00:09:43 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 00:09:43 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/25/2024 00:10:35 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1028.6925048828125
05/25/2024 00:10:35 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.7524177949709864
05/25/2024 00:10:35 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 00:10:35 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/25/2024 00:11:21 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1858.8927001953125
05/25/2024 00:11:21 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.9564454837766735
05/25/2024 00:11:21 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 00:11:21 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/25/2024 00:12:08 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1063.6126708984375
05/25/2024 00:12:08 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.9018836097835254
05/25/2024 00:12:08 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 00:12:08 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/25/2024 00:16:11 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 772.9686889648438
05/25/2024 00:16:11 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.9453312614776099
05/25/2024 00:16:11 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 00:16:11 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/25/2024 00:18:41 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1130.288330078125
05/25/2024 00:18:41 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.7526336844912656
05/25/2024 00:18:41 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1324.535, 'learning_rate': 0.000269094040223876, 'epoch': 10.666666666666666}
{'loss': 1361.55, 'learning_rate': 0.0002681714742604096, 'epoch': 10.962962962962964}
{'loss': 1352.58, 'learning_rate': 0.0002672489082969432, 'epoch': 11.25925925925926}
{'loss': 1302.28, 'learning_rate': 0.00026632634233347683, 'epoch': 11.555555555555555}
{'loss': 1273.19, 'learning_rate': 0.00026540377637001043, 'epoch': 11.851851851851851}
05/25/2024 00:24:57 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/25/2024 00:26:09 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1931.298583984375
05/25/2024 00:26:09 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.6714574444194925
05/25/2024 00:26:09 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 00:26:09 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/25/2024 00:27:20 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1188.9957275390625
05/25/2024 00:27:20 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.8624587847385774
05/25/2024 00:27:20 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 00:27:20 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/25/2024 00:28:09 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1028.8551025390625
05/25/2024 00:28:09 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.7680461982675649
05/25/2024 00:28:09 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 00:28:09 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/25/2024 00:28:54 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1862.33447265625
05/25/2024 00:28:54 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.9671939074399531
05/25/2024 00:28:54 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 00:28:54 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/25/2024 00:29:40 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1065.63671875
05/25/2024 00:29:40 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.9019826864004468
05/25/2024 00:29:40 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 00:29:40 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/25/2024 00:33:44 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 767.2271728515625
05/25/2024 00:33:44 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.9548506929561366
05/25/2024 00:33:44 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 00:33:44 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/25/2024 00:36:17 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1130.917236328125
05/25/2024 00:36:17 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.7278876170655567
05/25/2024 00:36:17 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1331.845, 'learning_rate': 0.000264481210406544, 'epoch': 12.148148148148149}
{'loss': 1318.47, 'learning_rate': 0.0002635586444430776, 'epoch': 12.444444444444445}
{'loss': 1323.11, 'learning_rate': 0.0002626360784796113, 'epoch': 12.74074074074074}
{'loss': 1282.13, 'learning_rate': 0.0002617135125161449, 'epoch': 13.037037037037036}
{'loss': 1266.05, 'learning_rate': 0.0002607909465526785, 'epoch': 13.333333333333334}
05/25/2024 00:42:30 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/25/2024 00:43:42 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1934.203125
05/25/2024 00:43:42 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.6649064906490648
05/25/2024 00:43:42 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 00:43:42 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/25/2024 00:44:51 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1185.2779541015625
05/25/2024 00:44:51 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.8586778790002336
05/25/2024 00:44:51 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 00:44:51 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/25/2024 00:45:40 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1031.5369873046875
05/25/2024 00:45:40 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.7720423212568132
05/25/2024 00:45:40 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 00:45:40 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/25/2024 00:46:25 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1852.704833984375
05/25/2024 00:46:25 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.9681193331383445
05/25/2024 00:46:25 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 00:46:25 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/25/2024 00:47:12 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1064.8724365234375
05/25/2024 00:47:12 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.9086364898639268
05/25/2024 00:47:12 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 00:47:12 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/25/2024 00:51:14 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 767.6959228515625
05/25/2024 00:51:14 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.9504725360619626
05/25/2024 00:51:14 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 00:51:14 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/25/2024 00:53:46 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1120.647216796875
05/25/2024 00:53:46 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.7920302122672221
05/25/2024 00:53:46 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1334.975, 'learning_rate': 0.0002598683805892121, 'epoch': 13.62962962962963}
{'loss': 1339.06, 'learning_rate': 0.0002589458146257457, 'epoch': 13.925925925925926}
{'loss': 1316.87, 'learning_rate': 0.0002580232486622793, 'epoch': 14.222222222222221}
{'loss': 1299.375, 'learning_rate': 0.00025710068269881297, 'epoch': 14.518518518518519}
{'loss': 1335.06, 'learning_rate': 0.00025617811673534657, 'epoch': 14.814814814814815}
05/25/2024 01:00:01 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/25/2024 01:01:13 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1928.7357177734375
05/25/2024 01:01:13 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.6715425531914895
05/25/2024 01:01:13 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 01:01:13 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/25/2024 01:02:22 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1183.9681396484375
05/25/2024 01:02:22 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.8648269410664172
05/25/2024 01:02:22 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 01:02:22 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/25/2024 01:03:11 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1035.50048828125
05/25/2024 01:03:11 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.7597298166613058
05/25/2024 01:03:11 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 01:03:11 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/25/2024 01:03:55 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1850.9327392578125
05/25/2024 01:03:55 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.9663840982168956
05/25/2024 01:03:55 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 01:03:55 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/25/2024 01:04:42 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1056.698974609375
05/25/2024 01:04:42 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.917823431426985
05/25/2024 01:04:42 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 01:04:42 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/25/2024 01:08:45 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 766.5250244140625
05/25/2024 01:08:45 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.9544197915928263
05/25/2024 01:08:45 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 01:08:45 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/25/2024 01:11:17 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1112.6461181640625
05/25/2024 01:11:17 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.79989725147701
05/25/2024 01:11:17 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1352.48, 'learning_rate': 0.00025525555077188017, 'epoch': 15.11111111111111}
{'loss': 1328.86, 'learning_rate': 0.00025433298480841376, 'epoch': 15.407407407407407}
{'loss': 1233.035, 'learning_rate': 0.0002534104188449474, 'epoch': 15.703703703703704}
{'loss': 1362.635, 'learning_rate': 0.000252487852881481, 'epoch': 16.0}
{'loss': 1303.25, 'learning_rate': 0.0002515652869180146, 'epoch': 16.296296296296298}
05/25/2024 01:17:32 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/25/2024 01:18:44 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1933.4190673828125
05/25/2024 01:18:44 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.6698481561822126
05/25/2024 01:18:44 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 01:18:44 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/25/2024 01:19:54 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1188.19580078125
05/25/2024 01:19:54 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.8603614175076273
05/25/2024 01:19:54 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 01:19:54 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/25/2024 01:20:45 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1036.6865234375
05/25/2024 01:20:45 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.7610677083333333
05/25/2024 01:20:45 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 01:20:45 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/25/2024 01:21:30 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1849.005126953125
05/25/2024 01:21:30 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.9608644859813082
05/25/2024 01:21:30 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 01:21:30 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/25/2024 01:22:18 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1058.616455078125
05/25/2024 01:22:18 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.9219227563212004
05/25/2024 01:22:18 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 01:22:18 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/25/2024 01:26:21 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 766.337646484375
05/25/2024 01:26:21 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.9571806419329474
05/25/2024 01:26:21 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 01:26:21 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/25/2024 01:28:55 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1110.389892578125
05/25/2024 01:28:55 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.8150058012118088
05/25/2024 01:28:55 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1308.18, 'learning_rate': 0.0002506427209545482, 'epoch': 16.59259259259259}
{'loss': 1321.295, 'learning_rate': 0.00024972015499108186, 'epoch': 16.88888888888889}
{'loss': 1339.545, 'learning_rate': 0.00024879758902761546, 'epoch': 17.185185185185187}
{'loss': 1325.5, 'learning_rate': 0.00024787502306414905, 'epoch': 17.48148148148148}
{'loss': 1348.19, 'learning_rate': 0.00024695245710068265, 'epoch': 17.77777777777778}
05/25/2024 01:35:18 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/25/2024 01:36:30 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1930.61669921875
05/25/2024 01:36:30 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.6783625730994153
05/25/2024 01:36:30 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 01:36:30 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/25/2024 01:37:39 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1188.587158203125
05/25/2024 01:37:39 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.8600234466588511
05/25/2024 01:37:39 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 01:37:39 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/25/2024 01:38:30 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1047.615478515625
05/25/2024 01:38:30 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.7559899117276166
05/25/2024 01:38:30 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 01:38:30 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/25/2024 01:39:15 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1852.6600341796875
05/25/2024 01:39:15 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.9719462302746932
05/25/2024 01:39:15 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 01:39:15 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/25/2024 01:40:01 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1056.9742431640625
05/25/2024 01:40:01 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.9223922114047288
05/25/2024 01:40:01 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 01:40:01 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/25/2024 01:44:04 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 767.1198120117188
05/25/2024 01:44:04 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.9561247057144895
05/25/2024 01:44:04 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 01:44:04 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/25/2024 01:46:35 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1106.8389892578125
05/25/2024 01:46:35 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.8231620039037085
05/25/2024 01:46:35 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1256.61, 'learning_rate': 0.00024602989113721625, 'epoch': 18.074074074074073}
{'loss': 1267.15, 'learning_rate': 0.0002451073251737499, 'epoch': 18.37037037037037}
{'loss': 1295.28, 'learning_rate': 0.0002441847592102835, 'epoch': 18.666666666666668}
{'loss': 1265.85, 'learning_rate': 0.00024326219324681712, 'epoch': 18.962962962962962}
{'loss': 1297.31, 'learning_rate': 0.00024233962728335072, 'epoch': 19.25925925925926}
05/25/2024 01:52:53 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/25/2024 01:54:05 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1928.122802734375
05/25/2024 01:54:05 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.6781557743957028
05/25/2024 01:54:05 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 01:54:05 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/25/2024 01:55:14 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1189.49853515625
05/25/2024 01:55:14 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.8620608347087951
05/25/2024 01:55:14 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 01:55:14 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/25/2024 01:56:04 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1035.87353515625
05/25/2024 01:56:04 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.7693303138142996
05/25/2024 01:56:04 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 01:56:04 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/25/2024 01:56:49 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1847.409912109375
05/25/2024 01:56:49 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.9701405152224825
05/25/2024 01:56:49 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 01:56:49 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/25/2024 01:57:35 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1060.500732421875
05/25/2024 01:57:35 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.9159500693481275
05/25/2024 01:57:35 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 01:57:35 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/25/2024 02:01:38 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 766.3685302734375
05/25/2024 02:01:38 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.955132320422284
05/25/2024 02:01:38 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 02:01:38 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/25/2024 02:04:11 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1109.1402587890625
05/25/2024 02:04:11 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.8326848249027237
05/25/2024 02:04:11 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1324.05, 'learning_rate': 0.00024141706131988435, 'epoch': 19.555555555555557}
{'loss': 1285.74, 'learning_rate': 0.00024049449535641794, 'epoch': 19.85185185185185}
{'loss': 1367.93, 'learning_rate': 0.00023957192939295157, 'epoch': 20.14814814814815}
{'loss': 1291.74, 'learning_rate': 0.00023864936342948517, 'epoch': 20.444444444444443}
{'loss': 1271.89, 'learning_rate': 0.0002377267974660188, 'epoch': 20.74074074074074}
05/25/2024 02:10:27 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/25/2024 02:11:38 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1928.2320556640625
05/25/2024 02:11:38 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.6805678793256433
05/25/2024 02:11:38 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 02:11:38 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/25/2024 02:12:47 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1186.798583984375
05/25/2024 02:12:47 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.8650421743205249
05/25/2024 02:12:47 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 02:12:47 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/25/2024 02:13:36 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1039.0880126953125
05/25/2024 02:13:36 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.7703225806451612
05/25/2024 02:13:36 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 02:13:36 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/25/2024 02:14:20 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1846.1978759765625
05/25/2024 02:14:20 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.976608187134503
05/25/2024 02:14:20 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 02:14:20 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/25/2024 02:15:07 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1054.9852294921875
05/25/2024 02:15:07 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.9199110122358175
05/25/2024 02:15:07 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 02:15:07 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/25/2024 02:19:10 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 767.5283203125
05/25/2024 02:19:10 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.9539927469245537
05/25/2024 02:19:10 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 02:19:10 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/25/2024 02:21:44 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1108.3682861328125
05/25/2024 02:21:44 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.8296103896103897
05/25/2024 02:21:44 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1291.45, 'learning_rate': 0.0002368042315025524, 'epoch': 21.037037037037038}
{'loss': 1296.12, 'learning_rate': 0.00023588166553908604, 'epoch': 21.333333333333332}
{'loss': 1273.99, 'learning_rate': 0.0002349590995756196, 'epoch': 21.62962962962963}
{'loss': 1314.15, 'learning_rate': 0.00023403653361215326, 'epoch': 21.925925925925927}
{'loss': 1278.41, 'learning_rate': 0.00023311396764868686, 'epoch': 22.22222222222222}
05/25/2024 02:27:58 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/25/2024 02:29:10 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1926.77880859375
05/25/2024 02:29:10 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.6751073931720551
05/25/2024 02:29:10 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 02:29:10 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/25/2024 02:30:19 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1188.0263671875
05/25/2024 02:30:19 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.8588290840415487
05/25/2024 02:30:19 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 02:30:19 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/25/2024 02:31:08 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1035.265625
05/25/2024 02:31:08 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.7591757887958791
05/25/2024 02:31:08 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 02:31:08 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/25/2024 02:31:52 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1849.1273193359375
05/25/2024 02:31:52 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.9739994157172072
05/25/2024 02:31:52 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 02:31:52 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/25/2024 02:32:39 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1056.57861328125
05/25/2024 02:32:39 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.916597395400388
05/25/2024 02:32:39 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 02:32:39 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/25/2024 02:36:45 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 765.646240234375
05/25/2024 02:36:45 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.9582502137361072
05/25/2024 02:36:45 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 02:36:45 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/25/2024 02:39:18 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1108.810791015625
05/25/2024 02:39:18 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.8354234001292824
05/25/2024 02:39:18 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1310.21, 'learning_rate': 0.00023219140168522049, 'epoch': 22.51851851851852}
{'loss': 1347.9, 'learning_rate': 0.00023126883572175408, 'epoch': 22.814814814814813}
{'loss': 1285.74, 'learning_rate': 0.0002303462697582877, 'epoch': 23.11111111111111}
{'loss': 1316.39, 'learning_rate': 0.0002294237037948213, 'epoch': 23.40740740740741}
{'loss': 1287.29, 'learning_rate': 0.00022850113783135493, 'epoch': 23.703703703703702}
05/25/2024 02:45:37 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/25/2024 02:46:49 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1929.5655517578125
05/25/2024 02:46:49 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.6738084827284653
05/25/2024 02:46:49 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 02:46:49 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/25/2024 02:47:58 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1189.7994384765625
05/25/2024 02:47:58 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.8626900584795322
05/25/2024 02:47:58 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 02:47:58 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/25/2024 02:48:46 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1040.55517578125
05/25/2024 02:48:46 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.7709137709137709
05/25/2024 02:48:46 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 02:48:46 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/25/2024 02:49:30 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1841.334228515625
05/25/2024 02:49:30 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.9730679156908665
05/25/2024 02:49:30 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 02:49:30 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/25/2024 02:50:17 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1054.90771484375
05/25/2024 02:50:17 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.9269647320188837
05/25/2024 02:50:17 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 02:50:17 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/25/2024 02:54:19 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 765.9788208007812
05/25/2024 02:54:19 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.9546362339514979
05/25/2024 02:54:19 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 02:54:19 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/25/2024 02:56:50 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1107.5235595703125
05/25/2024 02:56:50 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.8272998572726094
05/25/2024 02:56:50 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1333.85, 'learning_rate': 0.00022757857186788853, 'epoch': 24.0}
{'loss': 1273.57, 'learning_rate': 0.00022665600590442215, 'epoch': 24.296296296296298}
{'loss': 1251.43, 'learning_rate': 0.00022573343994095575, 'epoch': 24.59259259259259}
{'loss': 1308.03, 'learning_rate': 0.00022481087397748938, 'epoch': 24.88888888888889}
{'loss': 1248.88, 'learning_rate': 0.00022388830801402297, 'epoch': 25.185185185185187}
05/25/2024 03:03:03 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/25/2024 03:04:15 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1928.61328125
05/25/2024 03:04:15 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.6724928992790038
05/25/2024 03:04:15 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 03:04:15 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/25/2024 03:05:25 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1190.72412109375
05/25/2024 03:05:25 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.8624970719137971
05/25/2024 03:05:25 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 03:05:25 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/25/2024 03:06:14 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1044.8863525390625
05/25/2024 03:06:14 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.7734450531743475
05/25/2024 03:06:14 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 03:06:14 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/25/2024 03:06:58 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1838.9324951171875
05/25/2024 03:06:58 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.9768667642752562
05/25/2024 03:06:58 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 03:06:58 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/25/2024 03:07:44 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1054.03857421875
05/25/2024 03:07:44 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.923632324354346
05/25/2024 03:07:44 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 03:07:44 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/25/2024 03:11:47 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 765.4959716796875
05/25/2024 03:11:47 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.9603530500391486
05/25/2024 03:11:47 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 03:11:47 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/25/2024 03:14:21 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1101.7232666015625
05/25/2024 03:14:21 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.8349185667752442
05/25/2024 03:14:21 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1314.12, 'learning_rate': 0.0002229657420505566, 'epoch': 25.48148148148148}
{'loss': 1278.3, 'learning_rate': 0.0002220431760870902, 'epoch': 25.77777777777778}
{'loss': 1266.35, 'learning_rate': 0.00022112061012362382, 'epoch': 26.074074074074073}
{'loss': 1305.64, 'learning_rate': 0.00022019804416015742, 'epoch': 26.37037037037037}
{'loss': 1324.82, 'learning_rate': 0.00021927547819669104, 'epoch': 26.666666666666668}
05/25/2024 03:20:36 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/25/2024 03:21:48 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1938.193359375
05/25/2024 03:21:48 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.6703272567537887
05/25/2024 03:21:48 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 03:21:48 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/25/2024 03:22:57 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1190.07958984375
05/25/2024 03:22:57 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.8626168224299066
05/25/2024 03:22:57 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 03:22:57 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/25/2024 03:23:46 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1044.60791015625
05/25/2024 03:23:46 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.7727272727272728
05/25/2024 03:23:46 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 03:23:46 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/25/2024 03:24:31 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1842.354736328125
05/25/2024 03:24:31 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.9768803043605502
05/25/2024 03:24:31 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 03:24:31 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/25/2024 03:25:17 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1057.1683349609375
05/25/2024 03:25:17 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.929663608562691
05/25/2024 03:25:17 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 03:25:17 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/25/2024 03:29:19 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 766.4441528320312
05/25/2024 03:29:19 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.9588515386255418
05/25/2024 03:29:19 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 03:29:19 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/25/2024 03:31:51 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1101.5198974609375
05/25/2024 03:31:51 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.8406954282034771
05/25/2024 03:31:51 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1310.75, 'learning_rate': 0.00021835291223322464, 'epoch': 26.962962962962962}
{'loss': 1293.26, 'learning_rate': 0.0002174303462697583, 'epoch': 27.25925925925926}
{'loss': 1396.52, 'learning_rate': 0.0002165077803062919, 'epoch': 27.555555555555557}
{'loss': 1261.28, 'learning_rate': 0.00021558521434282552, 'epoch': 27.85185185185185}
{'loss': 1240.74, 'learning_rate': 0.0002146626483793591, 'epoch': 28.14814814814815}
05/25/2024 03:38:05 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/25/2024 03:39:17 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1934.0223388671875
05/25/2024 03:39:17 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.6710182767624021
05/25/2024 03:39:17 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 03:39:17 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/25/2024 03:40:27 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1191.032958984375
05/25/2024 03:40:27 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.8625029684160532
05/25/2024 03:40:27 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 03:40:27 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/25/2024 03:41:16 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1054.38232421875
05/25/2024 03:41:16 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.7579415501905973
05/25/2024 03:41:16 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 03:41:16 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/25/2024 03:42:01 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1839.955810546875
05/25/2024 03:42:01 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.978050921861282
05/25/2024 03:42:01 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 03:42:01 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/25/2024 03:42:48 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1055.6392822265625
05/25/2024 03:42:48 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.9217101610216546
05/25/2024 03:42:48 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 03:42:48 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/25/2024 03:46:55 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 766.02392578125
05/25/2024 03:46:55 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.9552217555349896
05/25/2024 03:46:55 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 03:46:55 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/25/2024 03:49:28 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1100.646728515625
05/25/2024 03:49:28 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.8417359667359666
05/25/2024 03:49:28 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1269.46, 'learning_rate': 0.00021374008241589274, 'epoch': 28.444444444444443}
{'loss': 1276.65, 'learning_rate': 0.00021281751645242634, 'epoch': 28.74074074074074}
{'loss': 1291.18, 'learning_rate': 0.00021189495048895996, 'epoch': 29.037037037037038}
{'loss': 1292.93, 'learning_rate': 0.00021097238452549356, 'epoch': 29.333333333333332}
{'loss': 1362.34, 'learning_rate': 0.00021004981856202716, 'epoch': 29.62962962962963}
05/25/2024 03:55:45 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/25/2024 03:56:56 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1933.667724609375
05/25/2024 03:56:56 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.6805891404704331
05/25/2024 03:56:56 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 03:56:56 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/25/2024 03:58:04 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1195.2998046875
05/25/2024 03:58:04 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.8534322820037106
05/25/2024 03:58:04 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 03:58:04 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/25/2024 03:58:53 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1044.480224609375
05/25/2024 03:58:53 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.7732125525719832
05/25/2024 03:58:53 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 03:58:53 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/25/2024 03:59:37 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1838.01025390625
05/25/2024 03:59:37 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.977751756440281
05/25/2024 03:59:37 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 03:59:37 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/25/2024 04:00:24 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1052.471923828125
05/25/2024 04:00:24 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.9308141150319533
05/25/2024 04:00:24 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 04:00:24 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/25/2024 04:04:26 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 765.7449340820312
05/25/2024 04:04:26 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.9586565146232122
05/25/2024 04:04:26 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 04:04:26 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/25/2024 04:06:56 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1099.9268798828125
05/25/2024 04:06:56 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.8504079782411604
05/25/2024 04:06:56 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1321.7, 'learning_rate': 0.00020912725259856078, 'epoch': 29.925925925925927}
{'loss': 1300.64, 'learning_rate': 0.00020820468663509438, 'epoch': 30.22222222222222}
{'loss': 1333.83, 'learning_rate': 0.000207282120671628, 'epoch': 30.51851851851852}
{'loss': 1270.87, 'learning_rate': 0.0002063595547081616, 'epoch': 30.814814814814813}
{'loss': 1324.44, 'learning_rate': 0.00020543698874469523, 'epoch': 31.11111111111111}
05/25/2024 04:13:10 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/25/2024 04:14:21 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1957.237548828125
05/25/2024 04:14:21 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.6443388072601555
05/25/2024 04:14:21 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 04:14:21 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/25/2024 04:15:30 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1201.2474365234375
05/25/2024 04:15:30 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.8505586592178771
05/25/2024 04:15:30 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 04:15:30 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/25/2024 04:16:19 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1053.546875
05/25/2024 04:16:19 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.7608764687202287
05/25/2024 04:16:19 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 04:16:19 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/25/2024 04:17:03 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1838.889892578125
05/25/2024 04:17:03 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.9777777777777779
05/25/2024 04:17:03 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 04:17:03 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/25/2024 04:17:49 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1054.4111328125
05/25/2024 04:17:49 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.9274798555154209
05/25/2024 04:17:49 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 04:17:49 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/25/2024 04:21:52 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 767.0762939453125
05/25/2024 04:21:52 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.956348924693023
05/25/2024 04:21:52 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 04:21:52 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/25/2024 04:24:27 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1104.3289794921875
05/25/2024 04:24:27 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.8494387820926332
05/25/2024 04:24:27 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1207.47, 'learning_rate': 0.00020451442278122882, 'epoch': 31.40740740740741}
{'loss': 1231.47, 'learning_rate': 0.00020359185681776245, 'epoch': 31.703703703703702}
{'loss': 1306.21, 'learning_rate': 0.00020266929085429605, 'epoch': 32.0}
{'loss': 1327.47, 'learning_rate': 0.00020174672489082967, 'epoch': 32.2962962962963}
{'loss': 1277.45, 'learning_rate': 0.00020082415892736327, 'epoch': 32.592592592592595}
05/25/2024 04:30:41 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/25/2024 04:31:52 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1934.24853515625
05/25/2024 04:31:52 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.668302476020522
05/25/2024 04:31:52 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 04:31:52 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/25/2024 04:33:00 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1189.282470703125
05/25/2024 04:33:00 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.8681732580037665
05/25/2024 04:33:00 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 04:33:00 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/25/2024 04:33:50 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1048.33154296875
05/25/2024 04:33:50 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.7820224719101122
05/25/2024 04:33:50 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 04:33:50 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/25/2024 04:34:33 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1835.1005859375
05/25/2024 04:34:33 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.9792336940625914
05/25/2024 04:34:33 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 04:34:33 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/25/2024 04:35:19 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1052.003173828125
05/25/2024 04:35:19 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.9258127257571548
05/25/2024 04:35:19 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 04:35:19 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/25/2024 04:39:22 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 764.49462890625
05/25/2024 04:39:22 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.9596918028108725
05/25/2024 04:39:22 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 04:39:22 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/25/2024 04:41:58 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1098.5750732421875
05/25/2024 04:41:58 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.8456861984219376
05/25/2024 04:41:58 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1312.45, 'learning_rate': 0.00019990159296389692, 'epoch': 32.888888888888886}
{'loss': 1238.79, 'learning_rate': 0.0001989790270004305, 'epoch': 33.18518518518518}
{'loss': 1289.77, 'learning_rate': 0.00019805646103696414, 'epoch': 33.48148148148148}
{'loss': 1299.25, 'learning_rate': 0.00019713389507349774, 'epoch': 33.77777777777778}
{'loss': 1290.19, 'learning_rate': 0.00019621132911003136, 'epoch': 34.074074074074076}
05/25/2024 04:48:13 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/25/2024 04:49:23 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1934.8037109375
05/25/2024 04:49:23 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.6674077367718986
05/25/2024 04:49:23 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 04:49:23 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/25/2024 04:50:32 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1193.1663818359375
05/25/2024 04:50:32 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.865911237016053
05/25/2024 04:50:32 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 04:50:32 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/25/2024 04:51:21 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1046.9820556640625
05/25/2024 04:51:21 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.7692307692307692
05/25/2024 04:51:21 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 04:51:21 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/25/2024 04:52:05 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1844.1724853515625
05/25/2024 04:52:05 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.9751098096632503
05/25/2024 04:52:05 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 04:52:05 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/25/2024 04:52:52 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1049.5865478515625
05/25/2024 04:52:52 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.9353760445682452
05/25/2024 04:52:52 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 04:52:52 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/25/2024 04:56:53 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 765.428955078125
05/25/2024 04:56:53 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.9607423269093505
05/25/2024 04:56:53 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 04:56:53 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/25/2024 04:59:25 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1100.8548583984375
05/25/2024 04:59:25 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.8494904625032663
05/25/2024 04:59:25 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1229.51, 'learning_rate': 0.00019528876314656496, 'epoch': 34.370370370370374}
{'loss': 1306.55, 'learning_rate': 0.0001943661971830986, 'epoch': 34.666666666666664}
{'loss': 1279.29, 'learning_rate': 0.00019344363121963218, 'epoch': 34.96296296296296}
{'loss': 1255.05, 'learning_rate': 0.0001925210652561658, 'epoch': 35.25925925925926}
{'loss': 1282.7, 'learning_rate': 0.0001915984992926994, 'epoch': 35.55555555555556}
05/25/2024 05:05:39 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/25/2024 05:06:49 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1936.498779296875
05/25/2024 05:06:49 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.6666666666666666
05/25/2024 05:06:49 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 05:06:49 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/25/2024 05:07:58 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1192.570068359375
05/25/2024 05:07:58 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.8643667296786389
05/25/2024 05:07:58 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 05:07:58 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/25/2024 05:08:47 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1056.2569580078125
05/25/2024 05:08:47 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.7650834403080873
05/25/2024 05:08:47 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 05:08:47 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/25/2024 05:09:30 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1838.1358642578125
05/25/2024 05:09:30 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.974539069359087
05/25/2024 05:09:30 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 05:09:30 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/25/2024 05:10:17 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1053.5936279296875
05/25/2024 05:10:17 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.9323684942944616
05/25/2024 05:10:17 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 05:10:17 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/25/2024 05:14:19 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 766.3460083007812
05/25/2024 05:14:19 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.9590268886043534
05/25/2024 05:14:19 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 05:14:19 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/25/2024 05:16:52 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1101.23291015625
05/25/2024 05:16:52 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.8525607863424728
05/25/2024 05:16:52 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1281.58, 'learning_rate': 0.00019067593332923303, 'epoch': 35.851851851851855}
{'loss': 1292.22, 'learning_rate': 0.00018975336736576663, 'epoch': 36.148148148148145}
{'loss': 1289.0, 'learning_rate': 0.00018883080140230025, 'epoch': 36.44444444444444}
{'loss': 1265.49, 'learning_rate': 0.00018790823543883385, 'epoch': 36.74074074074074}
{'loss': 1272.38, 'learning_rate': 0.00018698566947536748, 'epoch': 37.03703703703704}
05/25/2024 05:23:07 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/25/2024 05:24:18 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1933.0340576171875
05/25/2024 05:24:18 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.6732068890342271
05/25/2024 05:24:18 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 05:24:18 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/25/2024 05:25:26 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1194.00146484375
05/25/2024 05:25:26 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.8580060422960725
05/25/2024 05:25:26 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 05:25:26 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/25/2024 05:26:15 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1054.1279296875
05/25/2024 05:26:15 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.7684413085311096
05/25/2024 05:26:15 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 05:26:15 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/25/2024 05:27:00 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1837.75439453125
05/25/2024 05:27:00 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.9786487276981574
05/25/2024 05:27:00 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 05:27:00 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/25/2024 05:27:47 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1050.7576904296875
05/25/2024 05:27:47 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.92789794786467
05/25/2024 05:27:47 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 05:27:47 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/25/2024 05:31:53 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 764.9581298828125
05/25/2024 05:31:53 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.9593507510500462
05/25/2024 05:31:53 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 05:31:53 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/25/2024 05:34:24 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1098.18212890625
05/25/2024 05:34:24 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.8500968366688186
05/25/2024 05:34:24 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1305.76, 'learning_rate': 0.00018606310351190107, 'epoch': 37.333333333333336}
{'loss': 1263.26, 'learning_rate': 0.0001851405375484347, 'epoch': 37.629629629629626}
{'loss': 1328.78, 'learning_rate': 0.0001842179715849683, 'epoch': 37.925925925925924}
{'loss': 1218.62, 'learning_rate': 0.00018329540562150192, 'epoch': 38.22222222222222}
{'loss': 1236.42, 'learning_rate': 0.00018237283965803552, 'epoch': 38.51851851851852}
05/25/2024 05:40:34 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/25/2024 05:41:43 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1941.734619140625
05/25/2024 05:41:43 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.6650474718480901
05/25/2024 05:41:43 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 05:41:43 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/25/2024 05:42:52 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1199.7969970703125
05/25/2024 05:42:52 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.8638497652582159
05/25/2024 05:42:52 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 05:42:52 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/25/2024 05:43:41 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1058.55859375
05/25/2024 05:43:41 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.7608418367346939
05/25/2024 05:43:41 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 05:43:41 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/25/2024 05:44:25 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1838.4923095703125
05/25/2024 05:44:25 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.977751756440281
05/25/2024 05:44:25 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 05:44:25 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/25/2024 05:45:12 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1051.9154052734375
05/25/2024 05:45:12 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.9324061196105702
05/25/2024 05:45:12 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 05:45:12 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/25/2024 05:49:14 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 766.9298706054688
05/25/2024 05:49:14 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.9583007743127085
05/25/2024 05:49:14 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 05:49:14 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/25/2024 05:51:46 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1098.2667236328125
05/25/2024 05:51:46 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.8524970963995354
05/25/2024 05:51:46 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1323.68, 'learning_rate': 0.00018145027369456917, 'epoch': 38.81481481481482}
{'loss': 1304.62, 'learning_rate': 0.00018052770773110277, 'epoch': 39.111111111111114}
{'loss': 1246.92, 'learning_rate': 0.0001796051417676364, 'epoch': 39.407407407407405}
{'loss': 1319.06, 'learning_rate': 0.00017868257580417, 'epoch': 39.7037037037037}
{'loss': 1259.18, 'learning_rate': 0.00017776000984070362, 'epoch': 40.0}
05/25/2024 05:57:59 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/25/2024 05:59:11 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1947.7205810546875
05/25/2024 05:59:11 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.6654724585759069
05/25/2024 05:59:11 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 05:59:11 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/25/2024 06:00:20 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1197.3240966796875
05/25/2024 06:00:20 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.8658967711524864
05/25/2024 06:00:20 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 06:00:20 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/25/2024 06:01:09 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1060.9332275390625
05/25/2024 06:01:09 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.7620599739243807
05/25/2024 06:01:09 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 06:01:09 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/25/2024 06:01:52 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1834.568115234375
05/25/2024 06:01:52 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.981275599765945
05/25/2024 06:01:52 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 06:01:52 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/25/2024 06:02:39 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1052.3529052734375
05/25/2024 06:02:39 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.9298050139275766
05/25/2024 06:02:39 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 06:02:39 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/25/2024 06:06:46 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 766.4194946289062
05/25/2024 06:06:46 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.9602341686299707
05/25/2024 06:06:46 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 06:06:46 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/25/2024 06:09:23 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1097.109130859375
05/25/2024 06:09:23 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.8564754736568907
05/25/2024 06:09:23 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1263.32, 'learning_rate': 0.0001768374438772372, 'epoch': 40.2962962962963}
{'loss': 1246.5, 'learning_rate': 0.00017591487791377084, 'epoch': 40.592592592592595}
{'loss': 1307.24, 'learning_rate': 0.00017499231195030444, 'epoch': 40.888888888888886}
{'loss': 1226.6, 'learning_rate': 0.00017406974598683803, 'epoch': 41.18518518518518}
{'loss': 1275.72, 'learning_rate': 0.00017314718002337166, 'epoch': 41.48148148148148}
05/25/2024 06:15:38 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/25/2024 06:16:48 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1938.10009765625
05/25/2024 06:16:48 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.6665201143108376
05/25/2024 06:16:48 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 06:16:48 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/25/2024 06:17:57 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1193.1912841796875
05/25/2024 06:17:57 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.8600234466588511
05/25/2024 06:17:57 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 06:17:57 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/25/2024 06:18:46 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1057.5504150390625
05/25/2024 06:18:46 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.7681483850335785
05/25/2024 06:18:46 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 06:18:46 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/25/2024 06:19:30 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1839.011474609375
05/25/2024 06:19:30 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.9789227166276346
05/25/2024 06:19:30 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 06:19:30 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/25/2024 06:20:17 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1052.6494140625
05/25/2024 06:20:17 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.927857935627081
05/25/2024 06:20:17 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 06:20:17 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/25/2024 06:24:25 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 766.2383422851562
05/25/2024 06:24:25 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.9584991472427515
05/25/2024 06:24:25 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 06:24:25 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/25/2024 06:26:55 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1096.9129638671875
05/25/2024 06:26:55 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.8537754176920088
05/25/2024 06:26:55 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1295.68, 'learning_rate': 0.00017222461405990526, 'epoch': 41.77777777777778}
{'loss': 1284.92, 'learning_rate': 0.00017130204809643888, 'epoch': 42.074074074074076}
{'loss': 1308.74, 'learning_rate': 0.00017037948213297248, 'epoch': 42.370370370370374}
{'loss': 1285.92, 'learning_rate': 0.0001694569161695061, 'epoch': 42.666666666666664}
{'loss': 1352.96, 'learning_rate': 0.0001685343502060397, 'epoch': 42.96296296296296}
05/25/2024 06:33:10 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/25/2024 06:34:18 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1944.5511474609375
05/25/2024 06:34:18 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.6564033913431504
05/25/2024 06:34:18 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 06:34:18 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/25/2024 06:35:27 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1198.9951171875
05/25/2024 06:35:27 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.8649532710280373
05/25/2024 06:35:27 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 06:35:27 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/25/2024 06:36:18 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1060.7457275390625
05/25/2024 06:36:18 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.7732819524727038
05/25/2024 06:36:18 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 06:36:18 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/25/2024 06:37:03 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1837.61181640625
05/25/2024 06:37:03 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.9736688121708601
05/25/2024 06:37:03 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 06:37:03 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/25/2024 06:37:50 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1054.617919921875
05/25/2024 06:37:50 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.9265850945494994
05/25/2024 06:37:50 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 06:37:50 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/25/2024 06:41:53 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 764.752197265625
05/25/2024 06:41:53 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.9605985037406484
05/25/2024 06:41:53 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 06:41:53 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/25/2024 06:44:24 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1097.4058837890625
05/25/2024 06:44:24 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.8528652555498192
05/25/2024 06:44:24 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1275.12, 'learning_rate': 0.00016761178424257333, 'epoch': 43.25925925925926}
{'loss': 1251.5, 'learning_rate': 0.00016668921827910692, 'epoch': 43.55555555555556}
{'loss': 1270.28, 'learning_rate': 0.00016576665231564055, 'epoch': 43.851851851851855}
{'loss': 1313.9, 'learning_rate': 0.00016484408635217415, 'epoch': 44.148148148148145}
{'loss': 1282.98, 'learning_rate': 0.00016392152038870777, 'epoch': 44.44444444444444}
05/25/2024 06:50:37 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/25/2024 06:51:44 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1942.4613037109375
05/25/2024 06:51:44 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.6649076517150396
05/25/2024 06:51:44 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 06:51:44 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/25/2024 06:52:53 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1193.9962158203125
05/25/2024 06:52:53 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.8630783758262511
05/25/2024 06:52:53 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 06:52:53 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/25/2024 06:53:42 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1064.109375
05/25/2024 06:53:42 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.7575953458306399
05/25/2024 06:53:42 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 06:53:42 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/25/2024 06:54:26 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1839.202392578125
05/25/2024 06:54:26 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.9759953161592506
05/25/2024 06:54:26 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 06:54:26 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/25/2024 06:55:13 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1050.71630859375
05/25/2024 06:55:13 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.9347826086956522
05/25/2024 06:55:13 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 06:55:13 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/25/2024 06:59:15 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 766.49658203125
05/25/2024 06:59:15 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.9604785302285836
05/25/2024 06:59:15 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 06:59:15 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/25/2024 07:01:45 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1098.2060546875
05/25/2024 07:01:45 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.8567353818228964
05/25/2024 07:01:45 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1250.92, 'learning_rate': 0.00016299895442524137, 'epoch': 44.74074074074074}
{'loss': 1194.3, 'learning_rate': 0.00016207638846177502, 'epoch': 45.03703703703704}
{'loss': 1311.88, 'learning_rate': 0.00016115382249830862, 'epoch': 45.333333333333336}
{'loss': 1318.76, 'learning_rate': 0.00016023125653484224, 'epoch': 45.629629629629626}
{'loss': 1308.52, 'learning_rate': 0.00015930869057137584, 'epoch': 45.925925925925924}
05/25/2024 07:07:57 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/25/2024 07:09:08 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1956.3187255859375
05/25/2024 07:09:08 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.6604429005644812
05/25/2024 07:09:08 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 07:09:08 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/25/2024 07:10:16 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1202.4832763671875
05/25/2024 07:10:16 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.8675263774912075
05/25/2024 07:10:16 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 07:10:16 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/25/2024 07:11:06 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1064.145263671875
05/25/2024 07:11:06 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.7724358974358972
05/25/2024 07:11:06 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 07:11:06 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/25/2024 07:11:50 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1844.4517822265625
05/25/2024 07:11:50 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.9748390871854886
05/25/2024 07:11:50 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 07:11:50 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/25/2024 07:12:37 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1052.5635986328125
05/25/2024 07:12:37 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.9300388672959468
05/25/2024 07:12:37 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 07:12:37 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/25/2024 07:16:41 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 767.471923828125
05/25/2024 07:16:41 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.954345668509854
05/25/2024 07:16:41 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 07:16:41 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/25/2024 07:19:14 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1097.78857421875
05/25/2024 07:19:14 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.8489764387794514
05/25/2024 07:19:14 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1230.44, 'learning_rate': 0.00015838612460790946, 'epoch': 46.22222222222222}
{'loss': 1252.96, 'learning_rate': 0.00015746355864444306, 'epoch': 46.51851851851852}
{'loss': 1268.34, 'learning_rate': 0.0001565409926809767, 'epoch': 46.81481481481482}
{'loss': 1245.78, 'learning_rate': 0.00015561842671751028, 'epoch': 47.111111111111114}
{'loss': 1227.12, 'learning_rate': 0.0001546958607540439, 'epoch': 47.407407407407405}
05/25/2024 07:25:26 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/25/2024 07:26:37 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1947.2938232421875
05/25/2024 07:26:37 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.6653465346534653
05/25/2024 07:26:37 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 07:26:37 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/25/2024 07:27:46 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1201.2021484375
05/25/2024 07:27:46 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.8590194698569082
05/25/2024 07:27:46 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 07:27:46 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/25/2024 07:28:35 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1064.446533203125
05/25/2024 07:28:35 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.7615062761506276
05/25/2024 07:28:35 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 07:28:35 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/25/2024 07:29:18 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1834.720458984375
05/25/2024 07:29:18 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.9771796372147454
05/25/2024 07:29:18 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 07:29:18 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/25/2024 07:30:05 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1052.145751953125
05/25/2024 07:30:05 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.930400890868597
05/25/2024 07:30:05 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 07:30:05 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/25/2024 07:34:07 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 765.7799072265625
05/25/2024 07:34:07 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.9614671043242472
05/25/2024 07:34:07 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 07:34:07 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/25/2024 07:36:40 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1098.0048828125
05/25/2024 07:36:40 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.8631989596879063
05/25/2024 07:36:40 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1240.8, 'learning_rate': 0.0001537732947905775, 'epoch': 47.7037037037037}
{'loss': 1316.68, 'learning_rate': 0.00015285072882711113, 'epoch': 48.0}
{'loss': 1290.66, 'learning_rate': 0.00015192816286364473, 'epoch': 48.2962962962963}
{'loss': 1256.28, 'learning_rate': 0.00015100559690017835, 'epoch': 48.592592592592595}
{'loss': 1270.94, 'learning_rate': 0.00015008303093671195, 'epoch': 48.888888888888886}
05/25/2024 07:42:53 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/25/2024 07:43:59 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1953.5692138671875
05/25/2024 07:43:59 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.6576300830782684
05/25/2024 07:43:59 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 07:43:59 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/25/2024 07:45:08 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1199.9493408203125
05/25/2024 07:45:08 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.8613721804511277
05/25/2024 07:45:08 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 07:45:08 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/25/2024 07:45:57 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1070.1644287109375
05/25/2024 07:45:57 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.7653452685421994
05/25/2024 07:45:57 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 07:45:57 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/25/2024 07:46:41 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1836.6011962890625
05/25/2024 07:46:41 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.976009362200117
05/25/2024 07:46:41 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 07:46:41 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/25/2024 07:47:27 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1052.0992431640625
05/25/2024 07:47:27 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.9264909847434118
05/25/2024 07:47:27 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 07:47:27 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/25/2024 07:51:29 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 766.9344482421875
05/25/2024 07:51:29 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.9593159957249734
05/25/2024 07:51:29 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 07:51:29 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/25/2024 07:54:01 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1098.572021484375
05/25/2024 07:54:01 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.8535705078628512
05/25/2024 07:54:01 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1289.9, 'learning_rate': 0.00014916046497324558, 'epoch': 49.18518518518518}
{'loss': 1250.94, 'learning_rate': 0.00014823789900977917, 'epoch': 49.48148148148148}
{'loss': 1278.56, 'learning_rate': 0.0001473153330463128, 'epoch': 49.77777777777778}
{'loss': 1348.38, 'learning_rate': 0.0001463927670828464, 'epoch': 50.074074074074076}
{'loss': 1258.94, 'learning_rate': 0.00014547020111938002, 'epoch': 50.370370370370374}
05/25/2024 08:00:14 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/25/2024 08:01:22 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1956.302734375
05/25/2024 08:01:22 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.6694395796847636
05/25/2024 08:01:22 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 08:01:22 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/25/2024 08:02:31 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1202.4600830078125
05/25/2024 08:02:31 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.8661157024793389
05/25/2024 08:02:31 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 08:02:31 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/25/2024 08:03:21 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1067.7525634765625
05/25/2024 08:03:21 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.7720990035358406
05/25/2024 08:03:21 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 08:03:21 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/25/2024 08:04:04 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1837.239501953125
05/25/2024 08:04:04 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.974824355971897
05/25/2024 08:04:04 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 08:04:04 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/25/2024 08:04:51 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1052.4849853515625
05/25/2024 08:04:51 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.9305169538632574
05/25/2024 08:04:51 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 08:04:51 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/25/2024 08:08:53 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 766.7368774414062
05/25/2024 08:08:53 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.963126738463733
05/25/2024 08:08:53 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 08:08:53 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/25/2024 08:11:25 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1099.2130126953125
05/25/2024 08:11:25 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.8564016085095344
05/25/2024 08:11:25 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1264.68, 'learning_rate': 0.00014454763515591362, 'epoch': 50.666666666666664}
{'loss': 1269.48, 'learning_rate': 0.00014362506919244724, 'epoch': 50.96296296296296}
{'loss': 1266.02, 'learning_rate': 0.00014270250322898087, 'epoch': 51.25925925925926}
{'loss': 1270.16, 'learning_rate': 0.00014177993726551447, 'epoch': 51.55555555555556}
{'loss': 1275.92, 'learning_rate': 0.0001408573713020481, 'epoch': 51.851851851851855}
05/25/2024 08:17:37 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/25/2024 08:18:49 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1966.3890380859375
05/25/2024 08:18:49 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.6642098417515717
05/25/2024 08:18:49 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 08:18:49 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/25/2024 08:19:58 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1201.3062744140625
05/25/2024 08:19:58 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.8649789029535866
05/25/2024 08:19:58 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 08:19:58 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/25/2024 08:20:48 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1072.1715087890625
05/25/2024 08:20:48 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.7670182166826461
05/25/2024 08:20:48 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 08:20:48 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/25/2024 08:21:32 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1836.1448974609375
05/25/2024 08:21:32 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.9803806734992679
05/25/2024 08:21:32 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 08:21:32 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/25/2024 08:22:18 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1052.744140625
05/25/2024 08:22:18 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.9324812447902195
05/25/2024 08:22:18 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 08:22:18 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/25/2024 08:26:21 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 766.6707153320312
05/25/2024 08:26:21 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.9608667759640743
05/25/2024 08:26:21 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 08:26:21 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/25/2024 08:28:50 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1097.4830322265625
05/25/2024 08:28:50 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.8566990291262135
05/25/2024 08:28:50 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1297.72, 'learning_rate': 0.0001399348053385817, 'epoch': 52.148148148148145}
{'loss': 1261.92, 'learning_rate': 0.00013901223937511531, 'epoch': 52.44444444444444}
{'loss': 1285.88, 'learning_rate': 0.0001380896734116489, 'epoch': 52.74074074074074}
{'loss': 1254.76, 'learning_rate': 0.00013716710744818254, 'epoch': 53.03703703703704}
{'loss': 1332.22, 'learning_rate': 0.00013624454148471613, 'epoch': 53.333333333333336}
05/25/2024 08:35:05 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/25/2024 08:36:11 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1960.707763671875
05/25/2024 08:36:11 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.6646140312293819
05/25/2024 08:36:11 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 08:36:11 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/25/2024 08:37:20 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1201.81396484375
05/25/2024 08:37:20 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.8609550561797752
05/25/2024 08:37:20 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 08:37:20 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/25/2024 08:38:10 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1072.1365966796875
05/25/2024 08:38:10 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.7567567567567568
05/25/2024 08:38:10 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 08:38:10 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/25/2024 08:38:54 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1839.2384033203125
05/25/2024 08:38:54 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.97196261682243
05/25/2024 08:38:54 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 08:38:54 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/25/2024 08:39:41 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1051.7333984375
05/25/2024 08:39:41 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.9293266555370061
05/25/2024 08:39:41 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 08:39:41 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/25/2024 08:43:43 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 765.721923828125
05/25/2024 08:43:43 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.9595556821418401
05/25/2024 08:43:43 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 08:43:43 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/25/2024 08:46:17 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1097.158447265625
05/25/2024 08:46:17 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.8595556710406652
05/25/2024 08:46:17 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1332.32, 'learning_rate': 0.00013532197552124976, 'epoch': 53.629629629629626}
{'loss': 1275.96, 'learning_rate': 0.00013439940955778338, 'epoch': 53.925925925925924}
{'loss': 1254.22, 'learning_rate': 0.00013347684359431698, 'epoch': 54.22222222222222}
{'loss': 1247.64, 'learning_rate': 0.0001325542776308506, 'epoch': 54.51851851851852}
{'loss': 1269.6, 'learning_rate': 0.0001316317116673842, 'epoch': 54.81481481481482}
05/25/2024 08:52:32 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/25/2024 08:53:37 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1954.6212158203125
05/25/2024 08:53:37 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.6694395796847636
05/25/2024 08:53:37 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 08:53:37 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/25/2024 08:54:46 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1201.4700927734375
05/25/2024 08:54:46 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.8633059788980071
05/25/2024 08:54:46 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 08:54:46 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/25/2024 08:55:35 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1073.406494140625
05/25/2024 08:55:35 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.7645553422904671
05/25/2024 08:55:35 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 08:55:35 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/25/2024 08:56:20 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1835.1806640625
05/25/2024 08:56:20 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.9818713450292399
05/25/2024 08:56:20 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 08:56:20 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/25/2024 08:57:06 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1051.5853271484375
05/25/2024 08:57:06 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.9340384080155859
05/25/2024 08:57:06 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 08:57:06 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/25/2024 09:01:08 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 766.039306640625
05/25/2024 09:01:08 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.9609797778410709
05/25/2024 09:01:08 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 09:01:08 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/25/2024 09:03:41 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1097.5159912109375
05/25/2024 09:03:41 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.8564056250806348
05/25/2024 09:03:41 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1306.48, 'learning_rate': 0.00013070914570391783, 'epoch': 55.111111111111114}
{'loss': 1286.04, 'learning_rate': 0.00012978657974045143, 'epoch': 55.407407407407405}
{'loss': 1264.58, 'learning_rate': 0.00012886401377698505, 'epoch': 55.7037037037037}
{'loss': 1248.46, 'learning_rate': 0.00012794144781351865, 'epoch': 56.0}
{'loss': 1242.64, 'learning_rate': 0.00012701888185005227, 'epoch': 56.2962962962963}
05/25/2024 09:09:54 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/25/2024 09:11:00 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1953.1873779296875
05/25/2024 09:11:00 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.6793442622950819
05/25/2024 09:11:00 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 09:11:00 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/25/2024 09:12:09 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1204.3289794921875
05/25/2024 09:12:09 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.8573426573426574
05/25/2024 09:12:09 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 09:12:09 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/25/2024 09:12:59 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1073.255859375
05/25/2024 09:12:59 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.7661082474226804
05/25/2024 09:12:59 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 09:12:59 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/25/2024 09:13:43 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1839.9461669921875
05/25/2024 09:13:43 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.976608187134503
05/25/2024 09:13:43 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 09:13:43 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/25/2024 09:14:29 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1052.6407470703125
05/25/2024 09:14:29 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.929068150208623
05/25/2024 09:14:29 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 09:14:29 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/25/2024 09:18:33 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 766.03662109375
05/25/2024 09:18:33 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.96058061761776
05/25/2024 09:18:33 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 09:18:33 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/25/2024 09:21:10 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1095.9833984375
05/25/2024 09:21:10 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.8611398963730569
05/25/2024 09:21:10 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1302.08, 'learning_rate': 0.0001260963158865859, 'epoch': 56.592592592592595}
{'loss': 1263.7, 'learning_rate': 0.0001251737499231195, 'epoch': 56.888888888888886}
{'loss': 1275.6, 'learning_rate': 0.00012425118395965312, 'epoch': 57.18518518518518}
{'loss': 1201.9, 'learning_rate': 0.00012332861799618672, 'epoch': 57.48148148148148}
{'loss': 1296.26, 'learning_rate': 0.00012240605203272034, 'epoch': 57.77777777777778}
05/25/2024 09:27:26 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/25/2024 09:28:33 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1962.1224365234375
05/25/2024 09:28:33 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.663155584814571
05/25/2024 09:28:33 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 09:28:33 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/25/2024 09:29:42 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1204.2359619140625
05/25/2024 09:29:42 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.8645735707591379
05/25/2024 09:29:42 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 09:29:42 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/25/2024 09:30:31 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1073.9693603515625
05/25/2024 09:30:31 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.7701703632272583
05/25/2024 09:30:31 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 09:30:31 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/25/2024 09:31:15 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1836.1082763671875
05/25/2024 09:31:15 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.9792336940625914
05/25/2024 09:31:15 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 09:31:15 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/25/2024 09:32:01 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1051.4136962890625
05/25/2024 09:32:01 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.9368215975507932
05/25/2024 09:32:01 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 09:32:01 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/25/2024 09:36:04 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 767.1234741210938
05/25/2024 09:36:04 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.9626041740864734
05/25/2024 09:36:04 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 09:36:04 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/25/2024 09:38:38 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1097.060546875
05/25/2024 09:38:38 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.8540192926045016
05/25/2024 09:38:38 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1248.44, 'learning_rate': 0.00012148348606925395, 'epoch': 58.074074074074076}
{'loss': 1282.44, 'learning_rate': 0.00012056092010578755, 'epoch': 58.370370370370374}
{'loss': 1257.06, 'learning_rate': 0.00011963835414232116, 'epoch': 58.666666666666664}
{'loss': 1256.02, 'learning_rate': 0.00011871578817885477, 'epoch': 58.96296296296296}
{'loss': 1310.3, 'learning_rate': 0.00011779322221538839, 'epoch': 59.25925925925926}
05/25/2024 09:44:54 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/25/2024 09:46:04 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1955.4010009765625
05/25/2024 09:46:04 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.6735911602209944
05/25/2024 09:46:04 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 09:46:04 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/25/2024 09:47:14 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1203.2642822265625
05/25/2024 09:47:14 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.8664310954063603
05/25/2024 09:47:14 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 09:47:14 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/25/2024 09:48:04 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1072.7418212890625
05/25/2024 09:48:04 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.7688311688311689
05/25/2024 09:48:04 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 09:48:04 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/25/2024 09:48:49 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1835.9581298828125
05/25/2024 09:48:49 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.980701754385965
05/25/2024 09:48:49 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 09:48:49 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/25/2024 09:49:37 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1050.6650390625
05/25/2024 09:49:37 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.938195991091314
05/25/2024 09:49:37 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 09:49:37 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/25/2024 09:53:43 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 765.2520751953125
05/25/2024 09:53:43 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.961218245214545
05/25/2024 09:53:43 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 09:53:43 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/25/2024 09:56:20 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1098.6571044921875
05/25/2024 09:56:20 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.8615184944841012
05/25/2024 09:56:20 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1312.04, 'learning_rate': 0.000116870656251922, 'epoch': 59.55555555555556}
{'loss': 1248.26, 'learning_rate': 0.00011594809028845561, 'epoch': 59.851851851851855}
{'loss': 1238.9, 'learning_rate': 0.00011502552432498922, 'epoch': 60.148148148148145}
{'loss': 1299.0, 'learning_rate': 0.00011410295836152283, 'epoch': 60.44444444444444}
{'loss': 1340.84, 'learning_rate': 0.00011318039239805644, 'epoch': 60.74074074074074}
05/25/2024 10:02:38 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/25/2024 10:03:45 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1961.85888671875
05/25/2024 10:03:45 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.665646853146853
05/25/2024 10:03:45 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 10:03:45 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/25/2024 10:04:53 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1203.663330078125
05/25/2024 10:04:53 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.8641278796426892
05/25/2024 10:04:53 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 10:04:53 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/25/2024 10:05:42 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1079.642822265625
05/25/2024 10:05:42 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.7625482625482626
05/25/2024 10:05:42 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 10:05:42 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/25/2024 10:06:27 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1834.9959716796875
05/25/2024 10:06:27 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.9792215393620134
05/25/2024 10:06:27 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 10:06:27 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/25/2024 10:07:13 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1052.861572265625
05/25/2024 10:07:13 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.9352957511802278
05/25/2024 10:07:13 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 10:07:13 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/25/2024 10:11:17 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 766.3816528320312
05/25/2024 10:11:17 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.9622252258661165
05/25/2024 10:11:17 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 10:11:17 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/25/2024 10:13:53 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1097.3599853515625
05/25/2024 10:13:53 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.8561085972850678
05/25/2024 10:13:53 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
slurmstepd-gpu-16: error: *** JOB 442678 ON gpu-16 CANCELLED AT 2024-05-25T10:14:02 DUE TO TIME LIMIT ***
