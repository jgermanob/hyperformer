05/25/2024 15:50:30 - WARNING - __main__ -   Process rank: 1, device: cuda:1, n_gpu: 1, distributed training: True, 16-bits training: False
05/25/2024 15:50:30 - WARNING - __main__ -   Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: True, 16-bits training: False
05/25/2024 15:50:30 - WARNING - __main__ -   Process rank: 2, device: cuda:2, n_gpu: 1, distributed training: True, 16-bits training: False
05/25/2024 15:50:30 - WARNING - __main__ -   Process rank: 3, device: cuda:3, n_gpu: 1, distributed training: True, 16-bits training: False
05/25/2024 15:50:30 - INFO - __main__ -   Training/evaluation parameters Seq2SeqTrainingArguments(output_dir='outputs/hyperformer_al++/', overwrite_output_dir=True, do_train=True, do_eval=True, do_predict=False, evaluate_during_training=False, evaluation_strategy=<EvaluationStrategy.STEPS: 'steps'>, prediction_loss_only=False, per_device_train_batch_size=32, per_device_eval_batch_size=32, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=0.0003, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100, max_steps=65536, warmup_steps=500, logging_dir='runs/May25_15-50-25_gpu-16', logging_first_step=True, logging_steps=200, save_steps=1000, save_total_limit=1, no_cuda=False, seed=42, fp16=False, fp16_opt_level='O1', local_rank=0, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=1000, dataloader_num_workers=0, past_index=-1, run_name='outputs/hyperformer_al++/', disable_tqdm=True, remove_unused_columns=True, label_names=None, load_best_model_at_end=True, metric_for_best_model='average_metrics', greater_is_better=True, label_smoothing=0.1, predict_with_generate=True, adafactor=False, encoder_layerdrop=None, decoder_layerdrop=None, dropout=None, attention_dropout=None, lr_scheduler='linear', temperature=10, train_adapters=True, do_test=True, eval_output_dir=None, generate_classifier_weights=False, optimize_from_scratch=False, optimize_from_scratch_with_loading_model=False, split_validation_test=True, print_num_parameters=True, compute_memory=False, compute_time=False)
05/25/2024 15:50:31 - WARNING - __main__ -   model path loaded from : t5-base
05/25/2024 15:50:31 - WARNING - __main__ -   model path loaded from : t5-base
05/25/2024 15:50:31 - WARNING - __main__ -   model path loaded from : t5-base
05/25/2024 15:50:31 - WARNING - __main__ -   model path loaded from : t5-base
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
Some weights of the model checkpoint at t5-base were not used when initializing T5ForConditionalGeneration: ['encoder.block.0.layer.0.SelfAttention.q.weight', 'encoder.block.0.layer.0.SelfAttention.v.weight', 'encoder.block.1.layer.0.SelfAttention.q.weight', 'encoder.block.1.layer.0.SelfAttention.v.weight', 'encoder.block.2.layer.0.SelfAttention.q.weight', 'encoder.block.2.layer.0.SelfAttention.v.weight', 'encoder.block.3.layer.0.SelfAttention.q.weight', 'encoder.block.3.layer.0.SelfAttention.v.weight', 'encoder.block.4.layer.0.SelfAttention.q.weight', 'encoder.block.4.layer.0.SelfAttention.v.weight', 'encoder.block.5.layer.0.SelfAttention.q.weight', 'encoder.block.5.layer.0.SelfAttention.v.weight', 'encoder.block.6.layer.0.SelfAttention.q.weight', 'encoder.block.6.layer.0.SelfAttention.v.weight', 'encoder.block.7.layer.0.SelfAttention.q.weight', 'encoder.block.7.layer.0.SelfAttention.v.weight', 'encoder.block.8.layer.0.SelfAttention.q.weight', 'encoder.block.8.layer.0.SelfAttention.v.weight', 'encoder.block.9.layer.0.SelfAttention.q.weight', 'encoder.block.9.layer.0.SelfAttention.v.weight', 'encoder.block.10.layer.0.SelfAttention.q.weight', 'encoder.block.10.layer.0.SelfAttention.v.weight', 'encoder.block.11.layer.0.SelfAttention.q.weight', 'encoder.block.11.layer.0.SelfAttention.v.weight', 'decoder.block.0.layer.0.SelfAttention.q.weight', 'decoder.block.0.layer.0.SelfAttention.v.weight', 'decoder.block.1.layer.0.SelfAttention.q.weight', 'decoder.block.1.layer.0.SelfAttention.v.weight', 'decoder.block.2.layer.0.SelfAttention.q.weight', 'decoder.block.2.layer.0.SelfAttention.v.weight', 'decoder.block.3.layer.0.SelfAttention.q.weight', 'decoder.block.3.layer.0.SelfAttention.v.weight', 'decoder.block.4.layer.0.SelfAttention.q.weight', 'decoder.block.4.layer.0.SelfAttention.v.weight', 'decoder.block.5.layer.0.SelfAttention.q.weight', 'decoder.block.5.layer.0.SelfAttention.v.weight', 'decoder.block.6.layer.0.SelfAttention.q.weight', 'decoder.block.6.layer.0.SelfAttention.v.weight', 'decoder.block.7.layer.0.SelfAttention.q.weight', 'decoder.block.7.layer.0.SelfAttention.v.weight', 'decoder.block.8.layer.0.SelfAttention.q.weight', 'decoder.block.8.layer.0.SelfAttention.v.weight', 'decoder.block.9.layer.0.SelfAttention.q.weight', 'decoder.block.9.layer.0.SelfAttention.v.weight', 'decoder.block.10.layer.0.SelfAttention.q.weight', 'decoder.block.10.layer.0.SelfAttention.v.weight', 'decoder.block.11.layer.0.SelfAttention.q.weight', 'decoder.block.11.layer.0.SelfAttention.v.weight']
- This IS expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of T5ForConditionalGeneration were not initialized from the model checkpoint at t5-base and are newly initialized: ['task_embedding_controller.task_to_embeddings.movieTrivia', 'task_embedding_controller.task_to_embeddings.movie', 'task_embedding_controller.task_to_embeddings.restaurant', 'task_embedding_controller.task_to_embeddings.atis', 'task_embedding_controller.task_to_embeddings.snips', 'task_embedding_controller.task_to_embeddings.mtod', 'task_embedding_controller.task_to_embeddings.mtop', 'encoder.block.0.layer.0.SelfAttention.q.linear.weight', 'encoder.block.0.layer.0.SelfAttention.v.linear.weight', 'encoder.block.1.layer.0.SelfAttention.q.linear.weight', 'encoder.block.1.layer.0.SelfAttention.v.linear.weight', 'encoder.block.2.layer.0.SelfAttention.q.linear.weight', 'encoder.block.2.layer.0.SelfAttention.v.linear.weight', 'encoder.block.3.layer.0.SelfAttention.q.linear.weight', 'encoder.block.3.layer.0.SelfAttention.v.linear.weight', 'encoder.block.4.layer.0.SelfAttention.q.linear.weight', 'encoder.block.4.layer.0.SelfAttention.v.linear.weight', 'encoder.block.5.layer.0.SelfAttention.q.linear.weight', 'encoder.block.5.layer.0.SelfAttention.v.linear.weight', 'encoder.block.6.layer.0.SelfAttention.q.linear.weight', 'encoder.block.6.layer.0.SelfAttention.v.linear.weight', 'encoder.block.7.layer.0.SelfAttention.q.linear.weight', 'encoder.block.7.layer.0.SelfAttention.v.linear.weight', 'encoder.block.8.layer.0.SelfAttention.q.linear.weight', 'encoder.block.8.layer.0.SelfAttention.v.linear.weight', 'encoder.block.9.layer.0.SelfAttention.q.linear.weight', 'encoder.block.9.layer.0.SelfAttention.v.linear.weight', 'encoder.block.10.layer.0.SelfAttention.q.linear.weight', 'encoder.block.10.layer.0.SelfAttention.v.linear.weight', 'encoder.block.11.layer.0.SelfAttention.q.linear.weight', 'encoder.block.11.layer.0.SelfAttention.v.linear.weight', 'encoder.adapter_layers_hyper_net.layer_id_embeddings.weight', 'encoder.adapter_layers_hyper_net.adapters_block_type.weight', 'encoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.0.weight', 'encoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.0.bias', 'encoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.2.weight', 'encoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.2.bias', 'encoder.adapter_layers_hyper_net.LayerNorm.weight', 'encoder.adapter_layers_hyper_net.LayerNorm.bias', 'encoder.adapter_layers_hyper_net.up_sampler_hyper_net.weight_generator.0.weight', 'encoder.adapter_layers_hyper_net.up_sampler_hyper_net.weight_generator.0.bias', 'encoder.adapter_layers_hyper_net.up_sampler_hyper_net.bias_generator.0.weight', 'encoder.adapter_layers_hyper_net.up_sampler_hyper_net.bias_generator.0.bias', 'encoder.adapter_layers_hyper_net.down_sampler_hyper_net.weight_generator.0.weight', 'encoder.adapter_layers_hyper_net.down_sampler_hyper_net.weight_generator.0.bias', 'encoder.adapter_layers_hyper_net.down_sampler_hyper_net.bias_generator.0.weight', 'encoder.adapter_layers_hyper_net.down_sampler_hyper_net.bias_generator.0.bias', 'encoder.adapter_layers_hyper_net.lora_query_a_hyper_net.weight_generator.0.weight', 'encoder.adapter_layers_hyper_net.lora_query_b_hyper_net.weight_generator.0.weight', 'encoder.adapter_layers_hyper_net.lora_value_a_hyper_net.weight_generator.0.weight', 'encoder.adapter_layers_hyper_net.lora_value_b_hyper_net.weight_generator.0.weight', 'encoder.adapter_layers_hyper_net.post_layernorm_hypernet.weight_generator.weight', 'encoder.adapter_layers_hyper_net.post_layernorm_hypernet.weight_generator.bias', 'encoder.adapter_layers_hyper_net.post_layernorm_hypernet.bias_generator.weight', 'encoder.adapter_layers_hyper_net.post_layernorm_hypernet.bias_generator.bias', 'decoder.block.0.layer.0.SelfAttention.q.linear.weight', 'decoder.block.0.layer.0.SelfAttention.v.linear.weight', 'decoder.block.1.layer.0.SelfAttention.q.linear.weight', 'decoder.block.1.layer.0.SelfAttention.v.linear.weight', 'decoder.block.2.layer.0.SelfAttention.q.linear.weight', 'decoder.block.2.layer.0.SelfAttention.v.linear.weight', 'decoder.block.3.layer.0.SelfAttention.q.linear.weight', 'decoder.block.3.layer.0.SelfAttention.v.linear.weight', 'decoder.block.4.layer.0.SelfAttention.q.linear.weight', 'decoder.block.4.layer.0.SelfAttention.v.linear.weight', 'decoder.block.5.layer.0.SelfAttention.q.linear.weight', 'decoder.block.5.layer.0.SelfAttention.v.linear.weight', 'decoder.block.6.layer.0.SelfAttention.q.linear.weight', 'decoder.block.6.layer.0.SelfAttention.v.linear.weight', 'decoder.block.7.layer.0.SelfAttention.q.linear.weight', 'decoder.block.7.layer.0.SelfAttention.v.linear.weight', 'decoder.block.8.layer.0.SelfAttention.q.linear.weight', 'decoder.block.8.layer.0.SelfAttention.v.linear.weight', 'decoder.block.9.layer.0.SelfAttention.q.linear.weight', 'decoder.block.9.layer.0.SelfAttention.v.linear.weight', 'decoder.block.10.layer.0.SelfAttention.q.linear.weight', 'decoder.block.10.layer.0.SelfAttention.v.linear.weight', 'decoder.block.11.layer.0.SelfAttention.q.linear.weight', 'decoder.block.11.layer.0.SelfAttention.v.linear.weight', 'decoder.adapter_layers_hyper_net.layer_id_embeddings.weight', 'decoder.adapter_layers_hyper_net.adapters_block_type.weight', 'decoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.0.weight', 'decoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.0.bias', 'decoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.2.weight', 'decoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.2.bias', 'decoder.adapter_layers_hyper_net.LayerNorm.weight', 'decoder.adapter_layers_hyper_net.LayerNorm.bias', 'decoder.adapter_layers_hyper_net.up_sampler_hyper_net.weight_generator.0.weight', 'decoder.adapter_layers_hyper_net.up_sampler_hyper_net.weight_generator.0.bias', 'decoder.adapter_layers_hyper_net.up_sampler_hyper_net.bias_generator.0.weight', 'decoder.adapter_layers_hyper_net.up_sampler_hyper_net.bias_generator.0.bias', 'decoder.adapter_layers_hyper_net.down_sampler_hyper_net.weight_generator.0.weight', 'decoder.adapter_layers_hyper_net.down_sampler_hyper_net.weight_generator.0.bias', 'decoder.adapter_layers_hyper_net.down_sampler_hyper_net.bias_generator.0.weight', 'decoder.adapter_layers_hyper_net.down_sampler_hyper_net.bias_generator.0.bias', 'decoder.adapter_layers_hyper_net.lora_query_a_hyper_net.weight_generator.0.weight', 'decoder.adapter_layers_hyper_net.lora_query_b_hyper_net.weight_generator.0.weight', 'decoder.adapter_layers_hyper_net.lora_value_a_hyper_net.weight_generator.0.weight', 'decoder.adapter_layers_hyper_net.lora_value_b_hyper_net.weight_generator.0.weight', 'decoder.adapter_layers_hyper_net.post_layernorm_hypernet.weight_generator.weight', 'decoder.adapter_layers_hyper_net.post_layernorm_hypernet.weight_generator.bias', 'decoder.adapter_layers_hyper_net.post_layernorm_hypernet.bias_generator.weight', 'decoder.adapter_layers_hyper_net.post_layernorm_hypernet.bias_generator.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Trainable param: layer_id_embeddings.weight
Trainable param: adapters_block_type.weight
Trainable param: task_hypernet.task_embeding_generator.0.weight
Trainable param: task_hypernet.task_embeding_generator.0.bias
Trainable param: task_hypernet.task_embeding_generator.2.weight
Trainable param: task_hypernet.task_embeding_generator.2.bias
Trainable param: LayerNorm.weight
Trainable param: LayerNorm.bias
Trainable param: up_sampler_hyper_net.weight_generator.0.weight
Trainable param: up_sampler_hyper_net.weight_generator.0.bias
Trainable param: up_sampler_hyper_net.bias_generator.0.weight
Trainable param: up_sampler_hyper_net.bias_generator.0.bias
Trainable param: down_sampler_hyper_net.weight_generator.0.weight
Trainable param: down_sampler_hyper_net.weight_generator.0.bias
Trainable param: down_sampler_hyper_net.bias_generator.0.weight
Trainable param: down_sampler_hyper_net.bias_generator.0.bias
Trainable param: lora_query_a_hyper_net.weight_generator.0.weight
Trainable param: lora_query_b_hyper_net.weight_generator.0.weight
Trainable param: lora_value_a_hyper_net.weight_generator.0.weight
Trainable param: lora_value_b_hyper_net.weight_generator.0.weight
Trainable param: post_layernorm_hypernet.weight_generator.weight
Trainable param: post_layernorm_hypernet.weight_generator.bias
Trainable param: post_layernorm_hypernet.bias_generator.weight
Trainable param: post_layernorm_hypernet.bias_generator.bias
Trainable param: layer_id_embeddings.weight
Trainable param: adapters_block_type.weight
Trainable param: task_hypernet.task_embeding_generator.0.weight
Trainable param: task_hypernet.task_embeding_generator.0.bias
Trainable param: task_hypernet.task_embeding_generator.2.weight
Trainable param: task_hypernet.task_embeding_generator.2.bias
Trainable param: LayerNorm.weight
Trainable param: LayerNorm.bias
Trainable param: up_sampler_hyper_net.weight_generator.0.weight
Trainable param: up_sampler_hyper_net.weight_generator.0.bias
Trainable param: up_sampler_hyper_net.bias_generator.0.weight
Trainable param: up_sampler_hyper_net.bias_generator.0.bias
Trainable param: down_sampler_hyper_net.weight_generator.0.weight
Trainable param: down_sampler_hyper_net.weight_generator.0.bias
Trainable param: down_sampler_hyper_net.bias_generator.0.weight
Trainable param: down_sampler_hyper_net.bias_generator.0.bias
Trainable param: lora_query_a_hyper_net.weight_generator.0.weight
Trainable param: lora_query_b_hyper_net.weight_generator.0.weight
Trainable param: lora_value_a_hyper_net.weight_generator.0.weight
Trainable param: lora_value_b_hyper_net.weight_generator.0.weight
Trainable param: post_layernorm_hypernet.weight_generator.weight
Trainable param: post_layernorm_hypernet.weight_generator.bias
Trainable param: post_layernorm_hypernet.bias_generator.weight
Trainable param: post_layernorm_hypernet.bias_generator.bias
05/25/2024 15:50:36 - INFO - __main__ -   T5ForConditionalGeneration(
  (task_embedding_controller): TaskEmbeddingController(
    (task_to_embeddings): ParameterDict(
        (movieTrivia): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]
        (movie): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]
        (restaurant): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]
        (atis): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]
        (snips): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]
        (mtod): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]
        (mtop): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]
    )
  )
  (shared): Embedding(32128, 768)
  (encoder): T5Stack(
    (embed_tokens): Embedding(32128, 768)
    (block): ModuleList(
      (0): T5Block(
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            (SelfAttention): T5Attention(
              (q): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (k): Linear(in_features=768, out_features=768, bias=False)
              (v): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (o): Linear(in_features=768, out_features=768, bias=False)
              (relative_attention_bias): Embedding(32, 12)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (1): T5LayerFF(
            (DenseReluDense): T5DenseReluDense(
              (wi): Linear(in_features=768, out_features=3072, bias=False)
              (wo): Linear(in_features=3072, out_features=768, bias=False)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (1): T5Block(
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            (SelfAttention): T5Attention(
              (q): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (k): Linear(in_features=768, out_features=768, bias=False)
              (v): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (o): Linear(in_features=768, out_features=768, bias=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (1): T5LayerFF(
            (DenseReluDense): T5DenseReluDense(
              (wi): Linear(in_features=768, out_features=3072, bias=False)
              (wo): Linear(in_features=3072, out_features=768, bias=False)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (2): T5Block(
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            (SelfAttention): T5Attention(
              (q): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (k): Linear(in_features=768, out_features=768, bias=False)
              (v): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (o): Linear(in_features=768, out_features=768, bias=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (1): T5LayerFF(
            (DenseReluDense): T5DenseReluDense(
              (wi): Linear(in_features=768, out_features=3072, bias=False)
              (wo): Linear(in_features=3072, out_features=768, bias=False)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (3): T5Block(
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            (SelfAttention): T5Attention(
              (q): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (k): Linear(in_features=768, out_features=768, bias=False)
              (v): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (o): Linear(in_features=768, out_features=768, bias=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (1): T5LayerFF(
            (DenseReluDense): T5DenseReluDense(
              (wi): Linear(in_features=768, out_features=3072, bias=False)
              (wo): Linear(in_features=3072, out_features=768, bias=False)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (4): T5Block(
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            (SelfAttention): T5Attention(
              (q): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (k): Linear(in_features=768, out_features=768, bias=False)
              (v): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (o): Linear(in_features=768, out_features=768, bias=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (1): T5LayerFF(
            (DenseReluDense): T5DenseReluDense(
              (wi): Linear(in_features=768, out_features=3072, bias=False)
              (wo): Linear(in_features=3072, out_features=768, bias=False)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (5): T5Block(
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            (SelfAttention): T5Attention(
              (q): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (k): Linear(in_features=768, out_features=768, bias=False)
              (v): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (o): Linear(in_features=768, out_features=768, bias=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (1): T5LayerFF(
            (DenseReluDense): T5DenseReluDense(
              (wi): Linear(in_features=768, out_features=3072, bias=False)
              (wo): Linear(in_features=3072, out_features=768, bias=False)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (6): T5Block(
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            (SelfAttention): T5Attention(
              (q): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (k): Linear(in_features=768, out_features=768, bias=False)
              (v): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (o): Linear(in_features=768, out_features=768, bias=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (1): T5LayerFF(
            (DenseReluDense): T5DenseReluDense(
              (wi): Linear(in_features=768, out_features=3072, bias=False)
              (wo): Linear(in_features=3072, out_features=768, bias=False)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (7): T5Block(
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            (SelfAttention): T5Attention(
              (q): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (k): Linear(in_features=768, out_features=768, bias=False)
              (v): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (o): Linear(in_features=768, out_features=768, bias=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (1): T5LayerFF(
            (DenseReluDense): T5DenseReluDense(
              (wi): Linear(in_features=768, out_features=3072, bias=False)
              (wo): Linear(in_features=3072, out_features=768, bias=False)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (8): T5Block(
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            (SelfAttention): T5Attention(
              (q): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (k): Linear(in_features=768, out_features=768, bias=False)
              (v): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (o): Linear(in_features=768, out_features=768, bias=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (1): T5LayerFF(
            (DenseReluDense): T5DenseReluDense(
              (wi): Linear(in_features=768, out_features=3072, bias=False)
              (wo): Linear(in_features=3072, out_features=768, bias=False)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (9): T5Block(
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            (SelfAttention): T5Attention(
              (q): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (k): Linear(in_features=768, out_features=768, bias=False)
              (v): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (o): Linear(in_features=768, out_features=768, bias=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (1): T5LayerFF(
            (DenseReluDense): T5DenseReluDense(
              (wi): Linear(in_features=768, out_features=3072, bias=False)
              (wo): Linear(in_features=3072, out_features=768, bias=False)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (10): T5Block(
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            (SelfAttention): T5Attention(
              (q): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (k): Linear(in_features=768, out_features=768, bias=False)
              (v): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (o): Linear(in_features=768, out_features=768, bias=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (1): T5LayerFF(
            (DenseReluDense): T5DenseReluDense(
              (wi): Linear(in_features=768, out_features=3072, bias=False)
              (wo): Linear(in_features=3072, out_features=768, bias=False)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (11): T5Block(
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            (SelfAttention): T5Attention(
              (q): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (k): Linear(in_features=768, out_features=768, bias=False)
              (v): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (o): Linear(in_features=768, out_features=768, bias=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (1): T5LayerFF(
            (DenseReluDense): T5DenseReluDense(
              (wi): Linear(in_features=768, out_features=3072, bias=False)
              (wo): Linear(in_features=3072, out_features=768, bias=False)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (adapter_layers_hyper_net): AdapterLayersOneHyperNetController(
      (layer_id_embeddings): Embedding(12, 64)
      (adapters_block_type): Embedding(3, 64)
      (task_hypernet): TaskHyperNet(
        (task_embeding_generator): Sequential(
          (0): Linear(in_features=192, out_features=128, bias=True)
          (1): ReLU()
          (2): Linear(in_features=128, out_features=64, bias=True)
        )
      )
      (LayerNorm): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
      (up_sampler_hyper_net): AdapterLayersHyperNet(
        (weight_generator): Sequential(
          (0): Linear(in_features=64, out_features=18432, bias=True)
        )
        (bias_generator): Sequential(
          (0): Linear(in_features=64, out_features=768, bias=True)
        )
      )
      (down_sampler_hyper_net): AdapterLayersHyperNet(
        (weight_generator): Sequential(
          (0): Linear(in_features=64, out_features=18432, bias=True)
        )
        (bias_generator): Sequential(
          (0): Linear(in_features=64, out_features=24, bias=True)
        )
      )
      (lora_query_a_hyper_net): LoRALayersHyperNet(
        (weight_generator): Sequential(
          (0): Linear(in_features=64, out_features=6144, bias=False)
        )
      )
      (lora_query_b_hyper_net): LoRALayersHyperNet(
        (weight_generator): Sequential(
          (0): Linear(in_features=64, out_features=6144, bias=False)
        )
      )
      (lora_value_a_hyper_net): LoRALayersHyperNet(
        (weight_generator): Sequential(
          (0): Linear(in_features=64, out_features=6144, bias=False)
        )
      )
      (lora_value_b_hyper_net): LoRALayersHyperNet(
        (weight_generator): Sequential(
          (0): Linear(in_features=64, out_features=6144, bias=False)
        )
      )
      (post_layernorm_hypernet): LayerNormHyperNet(
        (weight_generator): Linear(in_features=64, out_features=768, bias=True)
        (bias_generator): Linear(in_features=64, out_features=768, bias=True)
      )
    )
    (final_layer_norm): T5LayerNorm()
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (decoder): T5Stack(
    (embed_tokens): Embedding(32128, 768)
    (block): ModuleList(
      (0): T5Block(
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            (SelfAttention): T5Attention(
              (q): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (k): Linear(in_features=768, out_features=768, bias=False)
              (v): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (o): Linear(in_features=768, out_features=768, bias=False)
              (relative_attention_bias): Embedding(32, 12)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (1): T5LayerCrossAttention(
            (EncDecAttention): T5Attention(
              (q): Linear(in_features=768, out_features=768, bias=False)
              (k): Linear(in_features=768, out_features=768, bias=False)
              (v): Linear(in_features=768, out_features=768, bias=False)
              (o): Linear(in_features=768, out_features=768, bias=False)
              (relative_attention_bias): Embedding(32, 12)
            )
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (2): T5LayerFF(
            (DenseReluDense): T5DenseReluDense(
              (wi): Linear(in_features=768, out_features=3072, bias=False)
              (wo): Linear(in_features=3072, out_features=768, bias=False)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (1): T5Block(
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            (SelfAttention): T5Attention(
              (q): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (k): Linear(in_features=768, out_features=768, bias=False)
              (v): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (o): Linear(in_features=768, out_features=768, bias=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (1): T5LayerCrossAttention(
            (EncDecAttention): T5Attention(
              (q): Linear(in_features=768, out_features=768, bias=False)
              (k): Linear(in_features=768, out_features=768, bias=False)
              (v): Linear(in_features=768, out_features=768, bias=False)
              (o): Linear(in_features=768, out_features=768, bias=False)
            )
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (2): T5LayerFF(
            (DenseReluDense): T5DenseReluDense(
              (wi): Linear(in_features=768, out_features=3072, bias=False)
              (wo): Linear(in_features=3072, out_features=768, bias=False)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (2): T5Block(
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            (SelfAttention): T5Attention(
              (q): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (k): Linear(in_features=768, out_features=768, bias=False)
              (v): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (o): Linear(in_features=768, out_features=768, bias=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (1): T5LayerCrossAttention(
            (EncDecAttention): T5Attention(
              (q): Linear(in_features=768, out_features=768, bias=False)
              (k): Linear(in_features=768, out_features=768, bias=False)
              (v): Linear(in_features=768, out_features=768, bias=False)
              (o): Linear(in_features=768, out_features=768, bias=False)
            )
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (2): T5LayerFF(
            (DenseReluDense): T5DenseReluDense(
              (wi): Linear(in_features=768, out_features=3072, bias=False)
              (wo): Linear(in_features=3072, out_features=768, bias=False)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (3): T5Block(
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            (SelfAttention): T5Attention(
              (q): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (k): Linear(in_features=768, out_features=768, bias=False)
              (v): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (o): Linear(in_features=768, out_features=768, bias=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (1): T5LayerCrossAttention(
            (EncDecAttention): T5Attention(
              (q): Linear(in_features=768, out_features=768, bias=False)
              (k): Linear(in_features=768, out_features=768, bias=False)
              (v): Linear(in_features=768, out_features=768, bias=False)
              (o): Linear(in_features=768, out_features=768, bias=False)
            )
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (2): T5LayerFF(
            (DenseReluDense): T5DenseReluDense(
              (wi): Linear(in_features=768, out_features=3072, bias=False)
              (wo): Linear(in_features=3072, out_features=768, bias=False)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (4): T5Block(
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            (SelfAttention): T5Attention(
              (q): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (k): Linear(in_features=768, out_features=768, bias=False)
              (v): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (o): Linear(in_features=768, out_features=768, bias=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (1): T5LayerCrossAttention(
            (EncDecAttention): T5Attention(
              (q): Linear(in_features=768, out_features=768, bias=False)
              (k): Linear(in_features=768, out_features=768, bias=False)
              (v): Linear(in_features=768, out_features=768, bias=False)
              (o): Linear(in_features=768, out_features=768, bias=False)
            )
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (2): T5LayerFF(
            (DenseReluDense): T5DenseReluDense(
              (wi): Linear(in_features=768, out_features=3072, bias=False)
              (wo): Linear(in_features=3072, out_features=768, bias=False)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (5): T5Block(
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            (SelfAttention): T5Attention(
              (q): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (k): Linear(in_features=768, out_features=768, bias=False)
              (v): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (o): Linear(in_features=768, out_features=768, bias=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (1): T5LayerCrossAttention(
            (EncDecAttention): T5Attention(
              (q): Linear(in_features=768, out_features=768, bias=False)
              (k): Linear(in_features=768, out_features=768, bias=False)
              (v): Linear(in_features=768, out_features=768, bias=False)
              (o): Linear(in_features=768, out_features=768, bias=False)
            )
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (2): T5LayerFF(
            (DenseReluDense): T5DenseReluDense(
              (wi): Linear(in_features=768, out_features=3072, bias=False)
              (wo): Linear(in_features=3072, out_features=768, bias=False)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (6): T5Block(
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            (SelfAttention): T5Attention(
              (q): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (k): Linear(in_features=768, out_features=768, bias=False)
              (v): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (o): Linear(in_features=768, out_features=768, bias=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (1): T5LayerCrossAttention(
            (EncDecAttention): T5Attention(
              (q): Linear(in_features=768, out_features=768, bias=False)
              (k): Linear(in_features=768, out_features=768, bias=False)
              (v): Linear(in_features=768, out_features=768, bias=False)
              (o): Linear(in_features=768, out_features=768, bias=False)
            )
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (2): T5LayerFF(
            (DenseReluDense): T5DenseReluDense(
              (wi): Linear(in_features=768, out_features=3072, bias=False)
              (wo): Linear(in_features=3072, out_features=768, bias=False)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (7): T5Block(
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            (SelfAttention): T5Attention(
              (q): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (k): Linear(in_features=768, out_features=768, bias=False)
              (v): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (o): Linear(in_features=768, out_features=768, bias=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (1): T5LayerCrossAttention(
            (EncDecAttention): T5Attention(
              (q): Linear(in_features=768, out_features=768, bias=False)
              (k): Linear(in_features=768, out_features=768, bias=False)
              (v): Linear(in_features=768, out_features=768, bias=False)
              (o): Linear(in_features=768, out_features=768, bias=False)
            )
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (2): T5LayerFF(
            (DenseReluDense): T5DenseReluDense(
              (wi): Linear(in_features=768, out_features=3072, bias=False)
              (wo): Linear(in_features=3072, out_features=768, bias=False)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (8): T5Block(
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            (SelfAttention): T5Attention(
              (q): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (k): Linear(in_features=768, out_features=768, bias=False)
              (v): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (o): Linear(in_features=768, out_features=768, bias=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (1): T5LayerCrossAttention(
            (EncDecAttention): T5Attention(
              (q): Linear(in_features=768, out_features=768, bias=False)
              (k): Linear(in_features=768, out_features=768, bias=False)
              (v): Linear(in_features=768, out_features=768, bias=False)
              (o): Linear(in_features=768, out_features=768, bias=False)
            )
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (2): T5LayerFF(
            (DenseReluDense): T5DenseReluDense(
              (wi): Linear(in_features=768, out_features=3072, bias=False)
              (wo): Linear(in_features=3072, out_features=768, bias=False)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (9): T5Block(
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            (SelfAttention): T5Attention(
              (q): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (k): Linear(in_features=768, out_features=768, bias=False)
              (v): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (o): Linear(in_features=768, out_features=768, bias=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (1): T5LayerCrossAttention(
            (EncDecAttention): T5Attention(
              (q): Linear(in_features=768, out_features=768, bias=False)
              (k): Linear(in_features=768, out_features=768, bias=False)
              (v): Linear(in_features=768, out_features=768, bias=False)
              (o): Linear(in_features=768, out_features=768, bias=False)
            )
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (2): T5LayerFF(
            (DenseReluDense): T5DenseReluDense(
              (wi): Linear(in_features=768, out_features=3072, bias=False)
              (wo): Linear(in_features=3072, out_features=768, bias=False)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (10): T5Block(
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            (SelfAttention): T5Attention(
              (q): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (k): Linear(in_features=768, out_features=768, bias=False)
              (v): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (o): Linear(in_features=768, out_features=768, bias=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (1): T5LayerCrossAttention(
            (EncDecAttention): T5Attention(
              (q): Linear(in_features=768, out_features=768, bias=False)
              (k): Linear(in_features=768, out_features=768, bias=False)
              (v): Linear(in_features=768, out_features=768, bias=False)
              (o): Linear(in_features=768, out_features=768, bias=False)
            )
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (2): T5LayerFF(
            (DenseReluDense): T5DenseReluDense(
              (wi): Linear(in_features=768, out_features=3072, bias=False)
              (wo): Linear(in_features=3072, out_features=768, bias=False)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (11): T5Block(
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            (SelfAttention): T5Attention(
              (q): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (k): Linear(in_features=768, out_features=768, bias=False)
              (v): MetaLinearLoraController(
                (linear): Linear(in_features=768, out_features=768, bias=False)
                (lora): MetaLoRALayer()
              )
              (o): Linear(in_features=768, out_features=768, bias=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (1): T5LayerCrossAttention(
            (EncDecAttention): T5Attention(
              (q): Linear(in_features=768, out_features=768, bias=False)
              (k): Linear(in_features=768, out_features=768, bias=False)
              (v): Linear(in_features=768, out_features=768, bias=False)
              (o): Linear(in_features=768, out_features=768, bias=False)
            )
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (2): T5LayerFF(
            (DenseReluDense): T5DenseReluDense(
              (wi): Linear(in_features=768, out_features=3072, bias=False)
              (wo): Linear(in_features=3072, out_features=768, bias=False)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (layer_hyper_net): MetaLayersAdapterController()
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (adapter_layers_hyper_net): AdapterLayersOneHyperNetController(
      (layer_id_embeddings): Embedding(12, 64)
      (adapters_block_type): Embedding(3, 64)
      (task_hypernet): TaskHyperNet(
        (task_embeding_generator): Sequential(
          (0): Linear(in_features=192, out_features=128, bias=True)
          (1): ReLU()
          (2): Linear(in_features=128, out_features=64, bias=True)
        )
      )
      (LayerNorm): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
      (up_sampler_hyper_net): AdapterLayersHyperNet(
        (weight_generator): Sequential(
          (0): Linear(in_features=64, out_features=18432, bias=True)
        )
        (bias_generator): Sequential(
          (0): Linear(in_features=64, out_features=768, bias=True)
        )
      )
      (down_sampler_hyper_net): AdapterLayersHyperNet(
        (weight_generator): Sequential(
          (0): Linear(in_features=64, out_features=18432, bias=True)
        )
        (bias_generator): Sequential(
          (0): Linear(in_features=64, out_features=24, bias=True)
        )
      )
      (lora_query_a_hyper_net): LoRALayersHyperNet(
        (weight_generator): Sequential(
          (0): Linear(in_features=64, out_features=6144, bias=False)
        )
      )
      (lora_query_b_hyper_net): LoRALayersHyperNet(
        (weight_generator): Sequential(
          (0): Linear(in_features=64, out_features=6144, bias=False)
        )
      )
      (lora_value_a_hyper_net): LoRALayersHyperNet(
        (weight_generator): Sequential(
          (0): Linear(in_features=64, out_features=6144, bias=False)
        )
      )
      (lora_value_b_hyper_net): LoRALayersHyperNet(
        (weight_generator): Sequential(
          (0): Linear(in_features=64, out_features=6144, bias=False)
        )
      )
      (post_layernorm_hypernet): LayerNormHyperNet(
        (weight_generator): Linear(in_features=64, out_features=768, bias=True)
        (bias_generator): Linear(in_features=64, out_features=768, bias=True)
      )
    )
    (final_layer_norm): T5LayerNorm()
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (lm_head): Linear(in_features=768, out_features=32128, bias=False)
)
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name task_embedding_controller.task_to_embeddings.movieTrivia
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name task_embedding_controller.task_to_embeddings.movie
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name task_embedding_controller.task_to_embeddings.restaurant
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name task_embedding_controller.task_to_embeddings.atis
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name task_embedding_controller.task_to_embeddings.snips
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name task_embedding_controller.task_to_embeddings.mtod
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name task_embedding_controller.task_to_embeddings.mtop
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name encoder.block.0.layer.0.layer_norm.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name encoder.block.0.layer.1.layer_norm.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name encoder.block.1.layer.0.layer_norm.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name encoder.block.1.layer.1.layer_norm.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name encoder.block.2.layer.0.layer_norm.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name encoder.block.2.layer.1.layer_norm.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name encoder.block.3.layer.0.layer_norm.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name encoder.block.3.layer.1.layer_norm.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name encoder.block.4.layer.0.layer_norm.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name encoder.block.4.layer.1.layer_norm.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name encoder.block.5.layer.0.layer_norm.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name encoder.block.5.layer.1.layer_norm.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name encoder.block.6.layer.0.layer_norm.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name encoder.block.6.layer.1.layer_norm.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name encoder.block.7.layer.0.layer_norm.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name encoder.block.7.layer.1.layer_norm.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name encoder.block.8.layer.0.layer_norm.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name encoder.block.8.layer.1.layer_norm.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name encoder.block.9.layer.0.layer_norm.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name encoder.block.9.layer.1.layer_norm.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name encoder.block.10.layer.0.layer_norm.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name encoder.block.10.layer.1.layer_norm.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name encoder.block.11.layer.0.layer_norm.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name encoder.block.11.layer.1.layer_norm.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name encoder.adapter_layers_hyper_net.layer_id_embeddings.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name encoder.adapter_layers_hyper_net.adapters_block_type.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name encoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.0.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name encoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.0.bias
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name encoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.2.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name encoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.2.bias
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name encoder.adapter_layers_hyper_net.LayerNorm.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name encoder.adapter_layers_hyper_net.LayerNorm.bias
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name encoder.adapter_layers_hyper_net.up_sampler_hyper_net.weight_generator.0.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name encoder.adapter_layers_hyper_net.up_sampler_hyper_net.weight_generator.0.bias
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name encoder.adapter_layers_hyper_net.up_sampler_hyper_net.bias_generator.0.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name encoder.adapter_layers_hyper_net.up_sampler_hyper_net.bias_generator.0.bias
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name encoder.adapter_layers_hyper_net.down_sampler_hyper_net.weight_generator.0.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name encoder.adapter_layers_hyper_net.down_sampler_hyper_net.weight_generator.0.bias
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name encoder.adapter_layers_hyper_net.down_sampler_hyper_net.bias_generator.0.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name encoder.adapter_layers_hyper_net.down_sampler_hyper_net.bias_generator.0.bias
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name encoder.adapter_layers_hyper_net.lora_query_a_hyper_net.weight_generator.0.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name encoder.adapter_layers_hyper_net.lora_query_b_hyper_net.weight_generator.0.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name encoder.adapter_layers_hyper_net.lora_value_a_hyper_net.weight_generator.0.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name encoder.adapter_layers_hyper_net.lora_value_b_hyper_net.weight_generator.0.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name encoder.adapter_layers_hyper_net.post_layernorm_hypernet.weight_generator.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name encoder.adapter_layers_hyper_net.post_layernorm_hypernet.weight_generator.bias
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name encoder.adapter_layers_hyper_net.post_layernorm_hypernet.bias_generator.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name encoder.adapter_layers_hyper_net.post_layernorm_hypernet.bias_generator.bias
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name encoder.final_layer_norm.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name decoder.block.0.layer.0.layer_norm.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name decoder.block.0.layer.1.layer_norm.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name decoder.block.0.layer.2.layer_norm.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name decoder.block.1.layer.0.layer_norm.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name decoder.block.1.layer.1.layer_norm.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name decoder.block.1.layer.2.layer_norm.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name decoder.block.2.layer.0.layer_norm.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name decoder.block.2.layer.1.layer_norm.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name decoder.block.2.layer.2.layer_norm.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name decoder.block.3.layer.0.layer_norm.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name decoder.block.3.layer.1.layer_norm.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name decoder.block.3.layer.2.layer_norm.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name decoder.block.4.layer.0.layer_norm.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name decoder.block.4.layer.1.layer_norm.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name decoder.block.4.layer.2.layer_norm.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name decoder.block.5.layer.0.layer_norm.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name decoder.block.5.layer.1.layer_norm.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name decoder.block.5.layer.2.layer_norm.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name decoder.block.6.layer.0.layer_norm.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name decoder.block.6.layer.1.layer_norm.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name decoder.block.6.layer.2.layer_norm.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name decoder.block.7.layer.0.layer_norm.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name decoder.block.7.layer.1.layer_norm.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name decoder.block.7.layer.2.layer_norm.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name decoder.block.8.layer.0.layer_norm.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name decoder.block.8.layer.1.layer_norm.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name decoder.block.8.layer.2.layer_norm.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name decoder.block.9.layer.0.layer_norm.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name decoder.block.9.layer.1.layer_norm.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name decoder.block.9.layer.2.layer_norm.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name decoder.block.10.layer.0.layer_norm.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name decoder.block.10.layer.1.layer_norm.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name decoder.block.10.layer.2.layer_norm.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name decoder.block.11.layer.0.layer_norm.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name decoder.block.11.layer.1.layer_norm.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name decoder.block.11.layer.2.layer_norm.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name decoder.adapter_layers_hyper_net.layer_id_embeddings.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name decoder.adapter_layers_hyper_net.adapters_block_type.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name decoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.0.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name decoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.0.bias
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name decoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.2.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name decoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.2.bias
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name decoder.adapter_layers_hyper_net.LayerNorm.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name decoder.adapter_layers_hyper_net.LayerNorm.bias
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name decoder.adapter_layers_hyper_net.up_sampler_hyper_net.weight_generator.0.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name decoder.adapter_layers_hyper_net.up_sampler_hyper_net.weight_generator.0.bias
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name decoder.adapter_layers_hyper_net.up_sampler_hyper_net.bias_generator.0.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name decoder.adapter_layers_hyper_net.up_sampler_hyper_net.bias_generator.0.bias
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name decoder.adapter_layers_hyper_net.down_sampler_hyper_net.weight_generator.0.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name decoder.adapter_layers_hyper_net.down_sampler_hyper_net.weight_generator.0.bias
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name decoder.adapter_layers_hyper_net.down_sampler_hyper_net.bias_generator.0.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name decoder.adapter_layers_hyper_net.down_sampler_hyper_net.bias_generator.0.bias
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name decoder.adapter_layers_hyper_net.lora_query_a_hyper_net.weight_generator.0.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name decoder.adapter_layers_hyper_net.lora_query_b_hyper_net.weight_generator.0.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name decoder.adapter_layers_hyper_net.lora_value_a_hyper_net.weight_generator.0.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name decoder.adapter_layers_hyper_net.lora_value_b_hyper_net.weight_generator.0.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name decoder.adapter_layers_hyper_net.post_layernorm_hypernet.weight_generator.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name decoder.adapter_layers_hyper_net.post_layernorm_hypernet.weight_generator.bias
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name decoder.adapter_layers_hyper_net.post_layernorm_hypernet.bias_generator.weight
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name decoder.adapter_layers_hyper_net.post_layernorm_hypernet.bias_generator.bias
05/25/2024 15:50:36 - INFO - __main__ -   Parameter name decoder.final_layer_norm.weight
05/25/2024 15:50:36 - INFO - __main__ -   Total trainable parameters 8356848
05/25/2024 15:50:36 - INFO - __main__ -   Total parameters 231213168
train
Some weights of the model checkpoint at t5-base were not used when initializing T5ForConditionalGeneration: ['encoder.block.0.layer.0.SelfAttention.q.weight', 'encoder.block.0.layer.0.SelfAttention.v.weight', 'encoder.block.1.layer.0.SelfAttention.q.weight', 'encoder.block.1.layer.0.SelfAttention.v.weight', 'encoder.block.2.layer.0.SelfAttention.q.weight', 'encoder.block.2.layer.0.SelfAttention.v.weight', 'encoder.block.3.layer.0.SelfAttention.q.weight', 'encoder.block.3.layer.0.SelfAttention.v.weight', 'encoder.block.4.layer.0.SelfAttention.q.weight', 'encoder.block.4.layer.0.SelfAttention.v.weight', 'encoder.block.5.layer.0.SelfAttention.q.weight', 'encoder.block.5.layer.0.SelfAttention.v.weight', 'encoder.block.6.layer.0.SelfAttention.q.weight', 'encoder.block.6.layer.0.SelfAttention.v.weight', 'encoder.block.7.layer.0.SelfAttention.q.weight', 'encoder.block.7.layer.0.SelfAttention.v.weight', 'encoder.block.8.layer.0.SelfAttention.q.weight', 'encoder.block.8.layer.0.SelfAttention.v.weight', 'encoder.block.9.layer.0.SelfAttention.q.weight', 'encoder.block.9.layer.0.SelfAttention.v.weight', 'encoder.block.10.layer.0.SelfAttention.q.weight', 'encoder.block.10.layer.0.SelfAttention.v.weight', 'encoder.block.11.layer.0.SelfAttention.q.weight', 'encoder.block.11.layer.0.SelfAttention.v.weight', 'decoder.block.0.layer.0.SelfAttention.q.weight', 'decoder.block.0.layer.0.SelfAttention.v.weight', 'decoder.block.1.layer.0.SelfAttention.q.weight', 'decoder.block.1.layer.0.SelfAttention.v.weight', 'decoder.block.2.layer.0.SelfAttention.q.weight', 'decoder.block.2.layer.0.SelfAttention.v.weight', 'decoder.block.3.layer.0.SelfAttention.q.weight', 'decoder.block.3.layer.0.SelfAttention.v.weight', 'decoder.block.4.layer.0.SelfAttention.q.weight', 'decoder.block.4.layer.0.SelfAttention.v.weight', 'decoder.block.5.layer.0.SelfAttention.q.weight', 'decoder.block.5.layer.0.SelfAttention.v.weight', 'decoder.block.6.layer.0.SelfAttention.q.weight', 'decoder.block.6.layer.0.SelfAttention.v.weight', 'decoder.block.7.layer.0.SelfAttention.q.weight', 'decoder.block.7.layer.0.SelfAttention.v.weight', 'decoder.block.8.layer.0.SelfAttention.q.weight', 'decoder.block.8.layer.0.SelfAttention.v.weight', 'decoder.block.9.layer.0.SelfAttention.q.weight', 'decoder.block.9.layer.0.SelfAttention.v.weight', 'decoder.block.10.layer.0.SelfAttention.q.weight', 'decoder.block.10.layer.0.SelfAttention.v.weight', 'decoder.block.11.layer.0.SelfAttention.q.weight', 'decoder.block.11.layer.0.SelfAttention.v.weight']
- This IS expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of T5ForConditionalGeneration were not initialized from the model checkpoint at t5-base and are newly initialized: ['task_embedding_controller.task_to_embeddings.movieTrivia', 'task_embedding_controller.task_to_embeddings.movie', 'task_embedding_controller.task_to_embeddings.restaurant', 'task_embedding_controller.task_to_embeddings.atis', 'task_embedding_controller.task_to_embeddings.snips', 'task_embedding_controller.task_to_embeddings.mtod', 'task_embedding_controller.task_to_embeddings.mtop', 'encoder.block.0.layer.0.SelfAttention.q.linear.weight', 'encoder.block.0.layer.0.SelfAttention.v.linear.weight', 'encoder.block.1.layer.0.SelfAttention.q.linear.weight', 'encoder.block.1.layer.0.SelfAttention.v.linear.weight', 'encoder.block.2.layer.0.SelfAttention.q.linear.weight', 'encoder.block.2.layer.0.SelfAttention.v.linear.weight', 'encoder.block.3.layer.0.SelfAttention.q.linear.weight', 'encoder.block.3.layer.0.SelfAttention.v.linear.weight', 'encoder.block.4.layer.0.SelfAttention.q.linear.weight', 'encoder.block.4.layer.0.SelfAttention.v.linear.weight', 'encoder.block.5.layer.0.SelfAttention.q.linear.weight', 'encoder.block.5.layer.0.SelfAttention.v.linear.weight', 'encoder.block.6.layer.0.SelfAttention.q.linear.weight', 'encoder.block.6.layer.0.SelfAttention.v.linear.weight', 'encoder.block.7.layer.0.SelfAttention.q.linear.weight', 'encoder.block.7.layer.0.SelfAttention.v.linear.weight', 'encoder.block.8.layer.0.SelfAttention.q.linear.weight', 'encoder.block.8.layer.0.SelfAttention.v.linear.weight', 'encoder.block.9.layer.0.SelfAttention.q.linear.weight', 'encoder.block.9.layer.0.SelfAttention.v.linear.weight', 'encoder.block.10.layer.0.SelfAttention.q.linear.weight', 'encoder.block.10.layer.0.SelfAttention.v.linear.weight', 'encoder.block.11.layer.0.SelfAttention.q.linear.weight', 'encoder.block.11.layer.0.SelfAttention.v.linear.weight', 'encoder.adapter_layers_hyper_net.layer_id_embeddings.weight', 'encoder.adapter_layers_hyper_net.adapters_block_type.weight', 'encoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.0.weight', 'encoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.0.bias', 'encoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.2.weight', 'encoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.2.bias', 'encoder.adapter_layers_hyper_net.LayerNorm.weight', 'encoder.adapter_layers_hyper_net.LayerNorm.bias', 'encoder.adapter_layers_hyper_net.up_sampler_hyper_net.weight_generator.0.weight', 'encoder.adapter_layers_hyper_net.up_sampler_hyper_net.weight_generator.0.bias', 'encoder.adapter_layers_hyper_net.up_sampler_hyper_net.bias_generator.0.weight', 'encoder.adapter_layers_hyper_net.up_sampler_hyper_net.bias_generator.0.bias', 'encoder.adapter_layers_hyper_net.down_sampler_hyper_net.weight_generator.0.weight', 'encoder.adapter_layers_hyper_net.down_sampler_hyper_net.weight_generator.0.bias', 'encoder.adapter_layers_hyper_net.down_sampler_hyper_net.bias_generator.0.weight', 'encoder.adapter_layers_hyper_net.down_sampler_hyper_net.bias_generator.0.bias', 'encoder.adapter_layers_hyper_net.lora_query_a_hyper_net.weight_generator.0.weight', 'encoder.adapter_layers_hyper_net.lora_query_b_hyper_net.weight_generator.0.weight', 'encoder.adapter_layers_hyper_net.lora_value_a_hyper_net.weight_generator.0.weight', 'encoder.adapter_layers_hyper_net.lora_value_b_hyper_net.weight_generator.0.weight', 'encoder.adapter_layers_hyper_net.post_layernorm_hypernet.weight_generator.weight', 'encoder.adapter_layers_hyper_net.post_layernorm_hypernet.weight_generator.bias', 'encoder.adapter_layers_hyper_net.post_layernorm_hypernet.bias_generator.weight', 'encoder.adapter_layers_hyper_net.post_layernorm_hypernet.bias_generator.bias', 'decoder.block.0.layer.0.SelfAttention.q.linear.weight', 'decoder.block.0.layer.0.SelfAttention.v.linear.weight', 'decoder.block.1.layer.0.SelfAttention.q.linear.weight', 'decoder.block.1.layer.0.SelfAttention.v.linear.weight', 'decoder.block.2.layer.0.SelfAttention.q.linear.weight', 'decoder.block.2.layer.0.SelfAttention.v.linear.weight', 'decoder.block.3.layer.0.SelfAttention.q.linear.weight', 'decoder.block.3.layer.0.SelfAttention.v.linear.weight', 'decoder.block.4.layer.0.SelfAttention.q.linear.weight', 'decoder.block.4.layer.0.SelfAttention.v.linear.weight', 'decoder.block.5.layer.0.SelfAttention.q.linear.weight', 'decoder.block.5.layer.0.SelfAttention.v.linear.weight', 'decoder.block.6.layer.0.SelfAttention.q.linear.weight', 'decoder.block.6.layer.0.SelfAttention.v.linear.weight', 'decoder.block.7.layer.0.SelfAttention.q.linear.weight', 'decoder.block.7.layer.0.SelfAttention.v.linear.weight', 'decoder.block.8.layer.0.SelfAttention.q.linear.weight', 'decoder.block.8.layer.0.SelfAttention.v.linear.weight', 'decoder.block.9.layer.0.SelfAttention.q.linear.weight', 'decoder.block.9.layer.0.SelfAttention.v.linear.weight', 'decoder.block.10.layer.0.SelfAttention.q.linear.weight', 'decoder.block.10.layer.0.SelfAttention.v.linear.weight', 'decoder.block.11.layer.0.SelfAttention.q.linear.weight', 'decoder.block.11.layer.0.SelfAttention.v.linear.weight', 'decoder.adapter_layers_hyper_net.layer_id_embeddings.weight', 'decoder.adapter_layers_hyper_net.adapters_block_type.weight', 'decoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.0.weight', 'decoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.0.bias', 'decoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.2.weight', 'decoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.2.bias', 'decoder.adapter_layers_hyper_net.LayerNorm.weight', 'decoder.adapter_layers_hyper_net.LayerNorm.bias', 'decoder.adapter_layers_hyper_net.up_sampler_hyper_net.weight_generator.0.weight', 'decoder.adapter_layers_hyper_net.up_sampler_hyper_net.weight_generator.0.bias', 'decoder.adapter_layers_hyper_net.up_sampler_hyper_net.bias_generator.0.weight', 'decoder.adapter_layers_hyper_net.up_sampler_hyper_net.bias_generator.0.bias', 'decoder.adapter_layers_hyper_net.down_sampler_hyper_net.weight_generator.0.weight', 'decoder.adapter_layers_hyper_net.down_sampler_hyper_net.weight_generator.0.bias', 'decoder.adapter_layers_hyper_net.down_sampler_hyper_net.bias_generator.0.weight', 'decoder.adapter_layers_hyper_net.down_sampler_hyper_net.bias_generator.0.bias', 'decoder.adapter_layers_hyper_net.lora_query_a_hyper_net.weight_generator.0.weight', 'decoder.adapter_layers_hyper_net.lora_query_b_hyper_net.weight_generator.0.weight', 'decoder.adapter_layers_hyper_net.lora_value_a_hyper_net.weight_generator.0.weight', 'decoder.adapter_layers_hyper_net.lora_value_b_hyper_net.weight_generator.0.weight', 'decoder.adapter_layers_hyper_net.post_layernorm_hypernet.weight_generator.weight', 'decoder.adapter_layers_hyper_net.post_layernorm_hypernet.weight_generator.bias', 'decoder.adapter_layers_hyper_net.post_layernorm_hypernet.bias_generator.weight', 'decoder.adapter_layers_hyper_net.post_layernorm_hypernet.bias_generator.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Trainable param: layer_id_embeddings.weight
Trainable param: adapters_block_type.weight
Trainable param: task_hypernet.task_embeding_generator.0.weight
Trainable param: task_hypernet.task_embeding_generator.0.bias
Trainable param: task_hypernet.task_embeding_generator.2.weight
Trainable param: task_hypernet.task_embeding_generator.2.bias
Trainable param: LayerNorm.weight
Trainable param: LayerNorm.bias
Trainable param: up_sampler_hyper_net.weight_generator.0.weight
Trainable param: up_sampler_hyper_net.weight_generator.0.bias
Trainable param: up_sampler_hyper_net.bias_generator.0.weight
Trainable param: up_sampler_hyper_net.bias_generator.0.bias
Trainable param: down_sampler_hyper_net.weight_generator.0.weight
Trainable param: down_sampler_hyper_net.weight_generator.0.bias
Trainable param: down_sampler_hyper_net.bias_generator.0.weight
Trainable param: down_sampler_hyper_net.bias_generator.0.bias
Trainable param: lora_query_a_hyper_net.weight_generator.0.weight
Trainable param: lora_query_b_hyper_net.weight_generator.0.weight
Trainable param: lora_value_a_hyper_net.weight_generator.0.weight
Trainable param: lora_value_b_hyper_net.weight_generator.0.weight
Trainable param: post_layernorm_hypernet.weight_generator.weight
Trainable param: post_layernorm_hypernet.weight_generator.bias
Trainable param: post_layernorm_hypernet.bias_generator.weight
Trainable param: post_layernorm_hypernet.bias_generator.bias
Trainable param: layer_id_embeddings.weight
Trainable param: adapters_block_type.weight
Trainable param: task_hypernet.task_embeding_generator.0.weight
Trainable param: task_hypernet.task_embeding_generator.0.bias
Trainable param: task_hypernet.task_embeding_generator.2.weight
Trainable param: task_hypernet.task_embeding_generator.2.bias
Trainable param: LayerNorm.weight
Trainable param: LayerNorm.bias
Trainable param: up_sampler_hyper_net.weight_generator.0.weight
Trainable param: up_sampler_hyper_net.weight_generator.0.bias
Trainable param: up_sampler_hyper_net.bias_generator.0.weight
Trainable param: up_sampler_hyper_net.bias_generator.0.bias
Trainable param: down_sampler_hyper_net.weight_generator.0.weight
Trainable param: down_sampler_hyper_net.weight_generator.0.bias
Trainable param: down_sampler_hyper_net.bias_generator.0.weight
Trainable param: down_sampler_hyper_net.bias_generator.0.bias
Trainable param: lora_query_a_hyper_net.weight_generator.0.weight
Trainable param: lora_query_b_hyper_net.weight_generator.0.weight
Trainable param: lora_value_a_hyper_net.weight_generator.0.weight
Trainable param: lora_value_b_hyper_net.weight_generator.0.weight
Trainable param: post_layernorm_hypernet.weight_generator.weight
Trainable param: post_layernorm_hypernet.weight_generator.bias
Trainable param: post_layernorm_hypernet.bias_generator.weight
Trainable param: post_layernorm_hypernet.bias_generator.bias
train

  0%|          | 0/7034 [00:00<?, ?ex/s]
  0%|          | 0/7034 [00:00<?, ?ex/s]
 38%|      | 2678/7034 [00:00<00:00, 26778.94ex/s]
 37%|      | 2608/7034 [00:00<00:00, 26076.73ex/s]
 82%| | 5761/7034 [00:00<00:00, 27877.14ex/s]
 81%|  | 5709/7034 [00:00<00:00, 27382.59ex/s]
100%|| 7034/7034 [00:00<00:00, 28980.79ex/s]

100%|| 7034/7034 [00:00<00:00, 28813.74ex/s]

  0%|          | 0/8797 [00:00<?, ?ex/s]Some weights of the model checkpoint at t5-base were not used when initializing T5ForConditionalGeneration: ['encoder.block.0.layer.0.SelfAttention.q.weight', 'encoder.block.0.layer.0.SelfAttention.v.weight', 'encoder.block.1.layer.0.SelfAttention.q.weight', 'encoder.block.1.layer.0.SelfAttention.v.weight', 'encoder.block.2.layer.0.SelfAttention.q.weight', 'encoder.block.2.layer.0.SelfAttention.v.weight', 'encoder.block.3.layer.0.SelfAttention.q.weight', 'encoder.block.3.layer.0.SelfAttention.v.weight', 'encoder.block.4.layer.0.SelfAttention.q.weight', 'encoder.block.4.layer.0.SelfAttention.v.weight', 'encoder.block.5.layer.0.SelfAttention.q.weight', 'encoder.block.5.layer.0.SelfAttention.v.weight', 'encoder.block.6.layer.0.SelfAttention.q.weight', 'encoder.block.6.layer.0.SelfAttention.v.weight', 'encoder.block.7.layer.0.SelfAttention.q.weight', 'encoder.block.7.layer.0.SelfAttention.v.weight', 'encoder.block.8.layer.0.SelfAttention.q.weight', 'encoder.block.8.layer.0.SelfAttention.v.weight', 'encoder.block.9.layer.0.SelfAttention.q.weight', 'encoder.block.9.layer.0.SelfAttention.v.weight', 'encoder.block.10.layer.0.SelfAttention.q.weight', 'encoder.block.10.layer.0.SelfAttention.v.weight', 'encoder.block.11.layer.0.SelfAttention.q.weight', 'encoder.block.11.layer.0.SelfAttention.v.weight', 'decoder.block.0.layer.0.SelfAttention.q.weight', 'decoder.block.0.layer.0.SelfAttention.v.weight', 'decoder.block.1.layer.0.SelfAttention.q.weight', 'decoder.block.1.layer.0.SelfAttention.v.weight', 'decoder.block.2.layer.0.SelfAttention.q.weight', 'decoder.block.2.layer.0.SelfAttention.v.weight', 'decoder.block.3.layer.0.SelfAttention.q.weight', 'decoder.block.3.layer.0.SelfAttention.v.weight', 'decoder.block.4.layer.0.SelfAttention.q.weight', 'decoder.block.4.layer.0.SelfAttention.v.weight', 'decoder.block.5.layer.0.SelfAttention.q.weight', 'decoder.block.5.layer.0.SelfAttention.v.weight', 'decoder.block.6.layer.0.SelfAttention.q.weight', 'decoder.block.6.layer.0.SelfAttention.v.weight', 'decoder.block.7.layer.0.SelfAttention.q.weight', 'decoder.block.7.layer.0.SelfAttention.v.weight', 'decoder.block.8.layer.0.SelfAttention.q.weight', 'decoder.block.8.layer.0.SelfAttention.v.weight', 'decoder.block.9.layer.0.SelfAttention.q.weight', 'decoder.block.9.layer.0.SelfAttention.v.weight', 'decoder.block.10.layer.0.SelfAttention.q.weight', 'decoder.block.10.layer.0.SelfAttention.v.weight', 'decoder.block.11.layer.0.SelfAttention.q.weight', 'decoder.block.11.layer.0.SelfAttention.v.weight']
- This IS expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of T5ForConditionalGeneration were not initialized from the model checkpoint at t5-base and are newly initialized: ['task_embedding_controller.task_to_embeddings.movieTrivia', 'task_embedding_controller.task_to_embeddings.movie', 'task_embedding_controller.task_to_embeddings.restaurant', 'task_embedding_controller.task_to_embeddings.atis', 'task_embedding_controller.task_to_embeddings.snips', 'task_embedding_controller.task_to_embeddings.mtod', 'task_embedding_controller.task_to_embeddings.mtop', 'encoder.block.0.layer.0.SelfAttention.q.linear.weight', 'encoder.block.0.layer.0.SelfAttention.v.linear.weight', 'encoder.block.1.layer.0.SelfAttention.q.linear.weight', 'encoder.block.1.layer.0.SelfAttention.v.linear.weight', 'encoder.block.2.layer.0.SelfAttention.q.linear.weight', 'encoder.block.2.layer.0.SelfAttention.v.linear.weight', 'encoder.block.3.layer.0.SelfAttention.q.linear.weight', 'encoder.block.3.layer.0.SelfAttention.v.linear.weight', 'encoder.block.4.layer.0.SelfAttention.q.linear.weight', 'encoder.block.4.layer.0.SelfAttention.v.linear.weight', 'encoder.block.5.layer.0.SelfAttention.q.linear.weight', 'encoder.block.5.layer.0.SelfAttention.v.linear.weight', 'encoder.block.6.layer.0.SelfAttention.q.linear.weight', 'encoder.block.6.layer.0.SelfAttention.v.linear.weight', 'encoder.block.7.layer.0.SelfAttention.q.linear.weight', 'encoder.block.7.layer.0.SelfAttention.v.linear.weight', 'encoder.block.8.layer.0.SelfAttention.q.linear.weight', 'encoder.block.8.layer.0.SelfAttention.v.linear.weight', 'encoder.block.9.layer.0.SelfAttention.q.linear.weight', 'encoder.block.9.layer.0.SelfAttention.v.linear.weight', 'encoder.block.10.layer.0.SelfAttention.q.linear.weight', 'encoder.block.10.layer.0.SelfAttention.v.linear.weight', 'encoder.block.11.layer.0.SelfAttention.q.linear.weight', 'encoder.block.11.layer.0.SelfAttention.v.linear.weight', 'encoder.adapter_layers_hyper_net.layer_id_embeddings.weight', 'encoder.adapter_layers_hyper_net.adapters_block_type.weight', 'encoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.0.weight', 'encoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.0.bias', 'encoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.2.weight', 'encoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.2.bias', 'encoder.adapter_layers_hyper_net.LayerNorm.weight', 'encoder.adapter_layers_hyper_net.LayerNorm.bias', 'encoder.adapter_layers_hyper_net.up_sampler_hyper_net.weight_generator.0.weight', 'encoder.adapter_layers_hyper_net.up_sampler_hyper_net.weight_generator.0.bias', 'encoder.adapter_layers_hyper_net.up_sampler_hyper_net.bias_generator.0.weight', 'encoder.adapter_layers_hyper_net.up_sampler_hyper_net.bias_generator.0.bias', 'encoder.adapter_layers_hyper_net.down_sampler_hyper_net.weight_generator.0.weight', 'encoder.adapter_layers_hyper_net.down_sampler_hyper_net.weight_generator.0.bias', 'encoder.adapter_layers_hyper_net.down_sampler_hyper_net.bias_generator.0.weight', 'encoder.adapter_layers_hyper_net.down_sampler_hyper_net.bias_generator.0.bias', 'encoder.adapter_layers_hyper_net.lora_query_a_hyper_net.weight_generator.0.weight', 'encoder.adapter_layers_hyper_net.lora_query_b_hyper_net.weight_generator.0.weight', 'encoder.adapter_layers_hyper_net.lora_value_a_hyper_net.weight_generator.0.weight', 'encoder.adapter_layers_hyper_net.lora_value_b_hyper_net.weight_generator.0.weight', 'encoder.adapter_layers_hyper_net.post_layernorm_hypernet.weight_generator.weight', 'encoder.adapter_layers_hyper_net.post_layernorm_hypernet.weight_generator.bias', 'encoder.adapter_layers_hyper_net.post_layernorm_hypernet.bias_generator.weight', 'encoder.adapter_layers_hyper_net.post_layernorm_hypernet.bias_generator.bias', 'decoder.block.0.layer.0.SelfAttention.q.linear.weight', 'decoder.block.0.layer.0.SelfAttention.v.linear.weight', 'decoder.block.1.layer.0.SelfAttention.q.linear.weight', 'decoder.block.1.layer.0.SelfAttention.v.linear.weight', 'decoder.block.2.layer.0.SelfAttention.q.linear.weight', 'decoder.block.2.layer.0.SelfAttention.v.linear.weight', 'decoder.block.3.layer.0.SelfAttention.q.linear.weight', 'decoder.block.3.layer.0.SelfAttention.v.linear.weight', 'decoder.block.4.layer.0.SelfAttention.q.linear.weight', 'decoder.block.4.layer.0.SelfAttention.v.linear.weight', 'decoder.block.5.layer.0.SelfAttention.q.linear.weight', 'decoder.block.5.layer.0.SelfAttention.v.linear.weight', 'decoder.block.6.layer.0.SelfAttention.q.linear.weight', 'decoder.block.6.layer.0.SelfAttention.v.linear.weight', 'decoder.block.7.layer.0.SelfAttention.q.linear.weight', 'decoder.block.7.layer.0.SelfAttention.v.linear.weight', 'decoder.block.8.layer.0.SelfAttention.q.linear.weight', 'decoder.block.8.layer.0.SelfAttention.v.linear.weight', 'decoder.block.9.layer.0.SelfAttention.q.linear.weight', 'decoder.block.9.layer.0.SelfAttention.v.linear.weight', 'decoder.block.10.layer.0.SelfAttention.q.linear.weight', 'decoder.block.10.layer.0.SelfAttention.v.linear.weight', 'decoder.block.11.layer.0.SelfAttention.q.linear.weight', 'decoder.block.11.layer.0.SelfAttention.v.linear.weight', 'decoder.adapter_layers_hyper_net.layer_id_embeddings.weight', 'decoder.adapter_layers_hyper_net.adapters_block_type.weight', 'decoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.0.weight', 'decoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.0.bias', 'decoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.2.weight', 'decoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.2.bias', 'decoder.adapter_layers_hyper_net.LayerNorm.weight', 'decoder.adapter_layers_hyper_net.LayerNorm.bias', 'decoder.adapter_layers_hyper_net.up_sampler_hyper_net.weight_generator.0.weight', 'decoder.adapter_layers_hyper_net.up_sampler_hyper_net.weight_generator.0.bias', 'decoder.adapter_layers_hyper_net.up_sampler_hyper_net.bias_generator.0.weight', 'decoder.adapter_layers_hyper_net.up_sampler_hyper_net.bias_generator.0.bias', 'decoder.adapter_layers_hyper_net.down_sampler_hyper_net.weight_generator.0.weight', 'decoder.adapter_layers_hyper_net.down_sampler_hyper_net.weight_generator.0.bias', 'decoder.adapter_layers_hyper_net.down_sampler_hyper_net.bias_generator.0.weight', 'decoder.adapter_layers_hyper_net.down_sampler_hyper_net.bias_generator.0.bias', 'decoder.adapter_layers_hyper_net.lora_query_a_hyper_net.weight_generator.0.weight', 'decoder.adapter_layers_hyper_net.lora_query_b_hyper_net.weight_generator.0.weight', 'decoder.adapter_layers_hyper_net.lora_value_a_hyper_net.weight_generator.0.weight', 'decoder.adapter_layers_hyper_net.lora_value_b_hyper_net.weight_generator.0.weight', 'decoder.adapter_layers_hyper_net.post_layernorm_hypernet.weight_generator.weight', 'decoder.adapter_layers_hyper_net.post_layernorm_hypernet.weight_generator.bias', 'decoder.adapter_layers_hyper_net.post_layernorm_hypernet.bias_generator.weight', 'decoder.adapter_layers_hyper_net.post_layernorm_hypernet.bias_generator.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

  0%|          | 0/8797 [00:00<?, ?ex/s]Trainable param: layer_id_embeddings.weight
Trainable param: adapters_block_type.weight
Trainable param: task_hypernet.task_embeding_generator.0.weight
Trainable param: task_hypernet.task_embeding_generator.0.bias
Trainable param: task_hypernet.task_embeding_generator.2.weight
Trainable param: task_hypernet.task_embeding_generator.2.bias
Trainable param: LayerNorm.weight
Trainable param: LayerNorm.bias
Trainable param: up_sampler_hyper_net.weight_generator.0.weight
Trainable param: up_sampler_hyper_net.weight_generator.0.bias
Trainable param: up_sampler_hyper_net.bias_generator.0.weight
Trainable param: up_sampler_hyper_net.bias_generator.0.bias
Trainable param: down_sampler_hyper_net.weight_generator.0.weight
Trainable param: down_sampler_hyper_net.weight_generator.0.bias
Trainable param: down_sampler_hyper_net.bias_generator.0.weight
Trainable param: down_sampler_hyper_net.bias_generator.0.bias
Trainable param: lora_query_a_hyper_net.weight_generator.0.weight
Trainable param: lora_query_b_hyper_net.weight_generator.0.weight
Trainable param: lora_value_a_hyper_net.weight_generator.0.weight
Trainable param: lora_value_b_hyper_net.weight_generator.0.weight
Trainable param: post_layernorm_hypernet.weight_generator.weight
Trainable param: post_layernorm_hypernet.weight_generator.bias
Trainable param: post_layernorm_hypernet.bias_generator.weight
Trainable param: post_layernorm_hypernet.bias_generator.bias
Trainable param: layer_id_embeddings.weight
Trainable param: adapters_block_type.weight
Trainable param: task_hypernet.task_embeding_generator.0.weight
Trainable param: task_hypernet.task_embeding_generator.0.bias
Trainable param: task_hypernet.task_embeding_generator.2.weight
Trainable param: task_hypernet.task_embeding_generator.2.bias
Trainable param: LayerNorm.weight
Trainable param: LayerNorm.bias
Trainable param: up_sampler_hyper_net.weight_generator.0.weight
Trainable param: up_sampler_hyper_net.weight_generator.0.bias
Trainable param: up_sampler_hyper_net.bias_generator.0.weight
Trainable param: up_sampler_hyper_net.bias_generator.0.bias
Trainable param: down_sampler_hyper_net.weight_generator.0.weight
Trainable param: down_sampler_hyper_net.weight_generator.0.bias
Trainable param: down_sampler_hyper_net.bias_generator.0.weight
Trainable param: down_sampler_hyper_net.bias_generator.0.bias
Trainable param: lora_query_a_hyper_net.weight_generator.0.weight
Trainable param: lora_query_b_hyper_net.weight_generator.0.weight
Trainable param: lora_value_a_hyper_net.weight_generator.0.weight
Trainable param: lora_value_b_hyper_net.weight_generator.0.weight
Trainable param: post_layernorm_hypernet.weight_generator.weight
Trainable param: post_layernorm_hypernet.weight_generator.bias
Trainable param: post_layernorm_hypernet.bias_generator.weight
Trainable param: post_layernorm_hypernet.bias_generator.bias
train

  0%|          | 0/7034 [00:00<?, ?ex/s]Some weights of the model checkpoint at t5-base were not used when initializing T5ForConditionalGeneration: ['encoder.block.0.layer.0.SelfAttention.q.weight', 'encoder.block.0.layer.0.SelfAttention.v.weight', 'encoder.block.1.layer.0.SelfAttention.q.weight', 'encoder.block.1.layer.0.SelfAttention.v.weight', 'encoder.block.2.layer.0.SelfAttention.q.weight', 'encoder.block.2.layer.0.SelfAttention.v.weight', 'encoder.block.3.layer.0.SelfAttention.q.weight', 'encoder.block.3.layer.0.SelfAttention.v.weight', 'encoder.block.4.layer.0.SelfAttention.q.weight', 'encoder.block.4.layer.0.SelfAttention.v.weight', 'encoder.block.5.layer.0.SelfAttention.q.weight', 'encoder.block.5.layer.0.SelfAttention.v.weight', 'encoder.block.6.layer.0.SelfAttention.q.weight', 'encoder.block.6.layer.0.SelfAttention.v.weight', 'encoder.block.7.layer.0.SelfAttention.q.weight', 'encoder.block.7.layer.0.SelfAttention.v.weight', 'encoder.block.8.layer.0.SelfAttention.q.weight', 'encoder.block.8.layer.0.SelfAttention.v.weight', 'encoder.block.9.layer.0.SelfAttention.q.weight', 'encoder.block.9.layer.0.SelfAttention.v.weight', 'encoder.block.10.layer.0.SelfAttention.q.weight', 'encoder.block.10.layer.0.SelfAttention.v.weight', 'encoder.block.11.layer.0.SelfAttention.q.weight', 'encoder.block.11.layer.0.SelfAttention.v.weight', 'decoder.block.0.layer.0.SelfAttention.q.weight', 'decoder.block.0.layer.0.SelfAttention.v.weight', 'decoder.block.1.layer.0.SelfAttention.q.weight', 'decoder.block.1.layer.0.SelfAttention.v.weight', 'decoder.block.2.layer.0.SelfAttention.q.weight', 'decoder.block.2.layer.0.SelfAttention.v.weight', 'decoder.block.3.layer.0.SelfAttention.q.weight', 'decoder.block.3.layer.0.SelfAttention.v.weight', 'decoder.block.4.layer.0.SelfAttention.q.weight', 'decoder.block.4.layer.0.SelfAttention.v.weight', 'decoder.block.5.layer.0.SelfAttention.q.weight', 'decoder.block.5.layer.0.SelfAttention.v.weight', 'decoder.block.6.layer.0.SelfAttention.q.weight', 'decoder.block.6.layer.0.SelfAttention.v.weight', 'decoder.block.7.layer.0.SelfAttention.q.weight', 'decoder.block.7.layer.0.SelfAttention.v.weight', 'decoder.block.8.layer.0.SelfAttention.q.weight', 'decoder.block.8.layer.0.SelfAttention.v.weight', 'decoder.block.9.layer.0.SelfAttention.q.weight', 'decoder.block.9.layer.0.SelfAttention.v.weight', 'decoder.block.10.layer.0.SelfAttention.q.weight', 'decoder.block.10.layer.0.SelfAttention.v.weight', 'decoder.block.11.layer.0.SelfAttention.q.weight', 'decoder.block.11.layer.0.SelfAttention.v.weight']
- This IS expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of T5ForConditionalGeneration were not initialized from the model checkpoint at t5-base and are newly initialized: ['task_embedding_controller.task_to_embeddings.movieTrivia', 'task_embedding_controller.task_to_embeddings.movie', 'task_embedding_controller.task_to_embeddings.restaurant', 'task_embedding_controller.task_to_embeddings.atis', 'task_embedding_controller.task_to_embeddings.snips', 'task_embedding_controller.task_to_embeddings.mtod', 'task_embedding_controller.task_to_embeddings.mtop', 'encoder.block.0.layer.0.SelfAttention.q.linear.weight', 'encoder.block.0.layer.0.SelfAttention.v.linear.weight', 'encoder.block.1.layer.0.SelfAttention.q.linear.weight', 'encoder.block.1.layer.0.SelfAttention.v.linear.weight', 'encoder.block.2.layer.0.SelfAttention.q.linear.weight', 'encoder.block.2.layer.0.SelfAttention.v.linear.weight', 'encoder.block.3.layer.0.SelfAttention.q.linear.weight', 'encoder.block.3.layer.0.SelfAttention.v.linear.weight', 'encoder.block.4.layer.0.SelfAttention.q.linear.weight', 'encoder.block.4.layer.0.SelfAttention.v.linear.weight', 'encoder.block.5.layer.0.SelfAttention.q.linear.weight', 'encoder.block.5.layer.0.SelfAttention.v.linear.weight', 'encoder.block.6.layer.0.SelfAttention.q.linear.weight', 'encoder.block.6.layer.0.SelfAttention.v.linear.weight', 'encoder.block.7.layer.0.SelfAttention.q.linear.weight', 'encoder.block.7.layer.0.SelfAttention.v.linear.weight', 'encoder.block.8.layer.0.SelfAttention.q.linear.weight', 'encoder.block.8.layer.0.SelfAttention.v.linear.weight', 'encoder.block.9.layer.0.SelfAttention.q.linear.weight', 'encoder.block.9.layer.0.SelfAttention.v.linear.weight', 'encoder.block.10.layer.0.SelfAttention.q.linear.weight', 'encoder.block.10.layer.0.SelfAttention.v.linear.weight', 'encoder.block.11.layer.0.SelfAttention.q.linear.weight', 'encoder.block.11.layer.0.SelfAttention.v.linear.weight', 'encoder.adapter_layers_hyper_net.layer_id_embeddings.weight', 'encoder.adapter_layers_hyper_net.adapters_block_type.weight', 'encoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.0.weight', 'encoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.0.bias', 'encoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.2.weight', 'encoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.2.bias', 'encoder.adapter_layers_hyper_net.LayerNorm.weight', 'encoder.adapter_layers_hyper_net.LayerNorm.bias', 'encoder.adapter_layers_hyper_net.up_sampler_hyper_net.weight_generator.0.weight', 'encoder.adapter_layers_hyper_net.up_sampler_hyper_net.weight_generator.0.bias', 'encoder.adapter_layers_hyper_net.up_sampler_hyper_net.bias_generator.0.weight', 'encoder.adapter_layers_hyper_net.up_sampler_hyper_net.bias_generator.0.bias', 'encoder.adapter_layers_hyper_net.down_sampler_hyper_net.weight_generator.0.weight', 'encoder.adapter_layers_hyper_net.down_sampler_hyper_net.weight_generator.0.bias', 'encoder.adapter_layers_hyper_net.down_sampler_hyper_net.bias_generator.0.weight', 'encoder.adapter_layers_hyper_net.down_sampler_hyper_net.bias_generator.0.bias', 'encoder.adapter_layers_hyper_net.lora_query_a_hyper_net.weight_generator.0.weight', 'encoder.adapter_layers_hyper_net.lora_query_b_hyper_net.weight_generator.0.weight', 'encoder.adapter_layers_hyper_net.lora_value_a_hyper_net.weight_generator.0.weight', 'encoder.adapter_layers_hyper_net.lora_value_b_hyper_net.weight_generator.0.weight', 'encoder.adapter_layers_hyper_net.post_layernorm_hypernet.weight_generator.weight', 'encoder.adapter_layers_hyper_net.post_layernorm_hypernet.weight_generator.bias', 'encoder.adapter_layers_hyper_net.post_layernorm_hypernet.bias_generator.weight', 'encoder.adapter_layers_hyper_net.post_layernorm_hypernet.bias_generator.bias', 'decoder.block.0.layer.0.SelfAttention.q.linear.weight', 'decoder.block.0.layer.0.SelfAttention.v.linear.weight', 'decoder.block.1.layer.0.SelfAttention.q.linear.weight', 'decoder.block.1.layer.0.SelfAttention.v.linear.weight', 'decoder.block.2.layer.0.SelfAttention.q.linear.weight', 'decoder.block.2.layer.0.SelfAttention.v.linear.weight', 'decoder.block.3.layer.0.SelfAttention.q.linear.weight', 'decoder.block.3.layer.0.SelfAttention.v.linear.weight', 'decoder.block.4.layer.0.SelfAttention.q.linear.weight', 'decoder.block.4.layer.0.SelfAttention.v.linear.weight', 'decoder.block.5.layer.0.SelfAttention.q.linear.weight', 'decoder.block.5.layer.0.SelfAttention.v.linear.weight', 'decoder.block.6.layer.0.SelfAttention.q.linear.weight', 'decoder.block.6.layer.0.SelfAttention.v.linear.weight', 'decoder.block.7.layer.0.SelfAttention.q.linear.weight', 'decoder.block.7.layer.0.SelfAttention.v.linear.weight', 'decoder.block.8.layer.0.SelfAttention.q.linear.weight', 'decoder.block.8.layer.0.SelfAttention.v.linear.weight', 'decoder.block.9.layer.0.SelfAttention.q.linear.weight', 'decoder.block.9.layer.0.SelfAttention.v.linear.weight', 'decoder.block.10.layer.0.SelfAttention.q.linear.weight', 'decoder.block.10.layer.0.SelfAttention.v.linear.weight', 'decoder.block.11.layer.0.SelfAttention.q.linear.weight', 'decoder.block.11.layer.0.SelfAttention.v.linear.weight', 'decoder.adapter_layers_hyper_net.layer_id_embeddings.weight', 'decoder.adapter_layers_hyper_net.adapters_block_type.weight', 'decoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.0.weight', 'decoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.0.bias', 'decoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.2.weight', 'decoder.adapter_layers_hyper_net.task_hypernet.task_embeding_generator.2.bias', 'decoder.adapter_layers_hyper_net.LayerNorm.weight', 'decoder.adapter_layers_hyper_net.LayerNorm.bias', 'decoder.adapter_layers_hyper_net.up_sampler_hyper_net.weight_generator.0.weight', 'decoder.adapter_layers_hyper_net.up_sampler_hyper_net.weight_generator.0.bias', 'decoder.adapter_layers_hyper_net.up_sampler_hyper_net.bias_generator.0.weight', 'decoder.adapter_layers_hyper_net.up_sampler_hyper_net.bias_generator.0.bias', 'decoder.adapter_layers_hyper_net.down_sampler_hyper_net.weight_generator.0.weight', 'decoder.adapter_layers_hyper_net.down_sampler_hyper_net.weight_generator.0.bias', 'decoder.adapter_layers_hyper_net.down_sampler_hyper_net.bias_generator.0.weight', 'decoder.adapter_layers_hyper_net.down_sampler_hyper_net.bias_generator.0.bias', 'decoder.adapter_layers_hyper_net.lora_query_a_hyper_net.weight_generator.0.weight', 'decoder.adapter_layers_hyper_net.lora_query_b_hyper_net.weight_generator.0.weight', 'decoder.adapter_layers_hyper_net.lora_value_a_hyper_net.weight_generator.0.weight', 'decoder.adapter_layers_hyper_net.lora_value_b_hyper_net.weight_generator.0.weight', 'decoder.adapter_layers_hyper_net.post_layernorm_hypernet.weight_generator.weight', 'decoder.adapter_layers_hyper_net.post_layernorm_hypernet.weight_generator.bias', 'decoder.adapter_layers_hyper_net.post_layernorm_hypernet.bias_generator.weight', 'decoder.adapter_layers_hyper_net.post_layernorm_hypernet.bias_generator.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

 35%|      | 3118/8797 [00:00<00:00, 31176.46ex/s]Trainable param: layer_id_embeddings.weight
Trainable param: adapters_block_type.weight
Trainable param: task_hypernet.task_embeding_generator.0.weight
Trainable param: task_hypernet.task_embeding_generator.0.bias
Trainable param: task_hypernet.task_embeding_generator.2.weight
Trainable param: task_hypernet.task_embeding_generator.2.bias
Trainable param: LayerNorm.weight
Trainable param: LayerNorm.bias
Trainable param: up_sampler_hyper_net.weight_generator.0.weight
Trainable param: up_sampler_hyper_net.weight_generator.0.bias
Trainable param: up_sampler_hyper_net.bias_generator.0.weight
Trainable param: up_sampler_hyper_net.bias_generator.0.bias
Trainable param: down_sampler_hyper_net.weight_generator.0.weight
Trainable param: down_sampler_hyper_net.weight_generator.0.bias
Trainable param: down_sampler_hyper_net.bias_generator.0.weight
Trainable param: down_sampler_hyper_net.bias_generator.0.bias
Trainable param: lora_query_a_hyper_net.weight_generator.0.weight
Trainable param: lora_query_b_hyper_net.weight_generator.0.weight
Trainable param: lora_value_a_hyper_net.weight_generator.0.weight
Trainable param: lora_value_b_hyper_net.weight_generator.0.weight
Trainable param: post_layernorm_hypernet.weight_generator.weight
Trainable param: post_layernorm_hypernet.weight_generator.bias
Trainable param: post_layernorm_hypernet.bias_generator.weight
Trainable param: post_layernorm_hypernet.bias_generator.bias
Trainable param: layer_id_embeddings.weight
Trainable param: adapters_block_type.weight
Trainable param: task_hypernet.task_embeding_generator.0.weight
Trainable param: task_hypernet.task_embeding_generator.0.bias
Trainable param: task_hypernet.task_embeding_generator.2.weight
Trainable param: task_hypernet.task_embeding_generator.2.bias
Trainable param: LayerNorm.weight
Trainable param: LayerNorm.bias
Trainable param: up_sampler_hyper_net.weight_generator.0.weight
Trainable param: up_sampler_hyper_net.weight_generator.0.bias
Trainable param: up_sampler_hyper_net.bias_generator.0.weight
Trainable param: up_sampler_hyper_net.bias_generator.0.bias
Trainable param: down_sampler_hyper_net.weight_generator.0.weight
Trainable param: down_sampler_hyper_net.weight_generator.0.bias
Trainable param: down_sampler_hyper_net.bias_generator.0.weight
Trainable param: down_sampler_hyper_net.bias_generator.0.bias
Trainable param: lora_query_a_hyper_net.weight_generator.0.weight
Trainable param: lora_query_b_hyper_net.weight_generator.0.weight
Trainable param: lora_value_a_hyper_net.weight_generator.0.weight
Trainable param: lora_value_b_hyper_net.weight_generator.0.weight
Trainable param: post_layernorm_hypernet.weight_generator.weight
Trainable param: post_layernorm_hypernet.weight_generator.bias
Trainable param: post_layernorm_hypernet.bias_generator.weight
Trainable param: post_layernorm_hypernet.bias_generator.bias

 36%|      | 3154/8797 [00:00<00:00, 31539.80ex/s]train

  0%|          | 0/7034 [00:00<?, ?ex/s]
 43%|     | 3055/7034 [00:00<00:00, 30548.57ex/s]
 71%|   | 6225/8797 [00:00<00:00, 31144.01ex/s]
 72%|  | 6306/8797 [00:00<00:00, 31532.94ex/s]
 43%|     | 3045/7034 [00:00<00:00, 30446.76ex/s]
 87%| | 6115/7034 [00:00<00:00, 30562.90ex/s]
100%|| 7034/7034 [00:00<00:00, 30635.26ex/s]

 99%|| 8696/8797 [00:00<00:00, 24243.05ex/s]
100%|| 8797/8797 [00:00<00:00, 24564.33ex/s]

 99%|| 8696/8797 [00:00<00:00, 24347.24ex/s]
100%|| 8797/8797 [00:00<00:00, 24855.88ex/s]

  0%|          | 0/8797 [00:00<?, ?ex/s]
 87%| | 6109/7034 [00:00<00:00, 30503.96ex/s]
100%|| 7034/7034 [00:00<00:00, 30621.27ex/s]

  0%|          | 0/6894 [00:00<?, ?ex/s]
  0%|          | 0/6894 [00:00<?, ?ex/s]
  0%|          | 0/8797 [00:00<?, ?ex/s]
 35%|      | 3115/8797 [00:00<00:00, 31143.12ex/s]
 46%|     | 3176/6894 [00:00<00:00, 31753.44ex/s]
 45%|     | 3129/6894 [00:00<00:00, 31286.45ex/s]
 36%|      | 3143/8797 [00:00<00:00, 31425.16ex/s]
 71%|   | 6248/8797 [00:00<00:00, 31196.12ex/s]
 92%|| 6335/6894 [00:00<00:00, 31701.90ex/s]
 90%| | 6213/6894 [00:00<00:00, 31149.24ex/s]
 72%|  | 6305/8797 [00:00<00:00, 31480.95ex/s]
100%|| 6894/6894 [00:00<00:00, 31713.56ex/s]

100%|| 6894/6894 [00:00<00:00, 31151.83ex/s]

 99%|| 8696/8797 [00:00<00:00, 24438.72ex/s]
100%|| 8797/8797 [00:00<00:00, 24816.55ex/s]

  0%|          | 0/4478 [00:00<?, ?ex/s]
  0%|          | 0/4478 [00:00<?, ?ex/s]
  0%|          | 0/6894 [00:00<?, ?ex/s]
 99%|| 8696/8797 [00:00<00:00, 24343.43ex/s]
100%|| 8797/8797 [00:00<00:00, 24864.41ex/s]

 70%|   | 3137/4478 [00:00<00:00, 31369.13ex/s]
 67%|   | 3000/4478 [00:00<00:00, 29982.80ex/s]
  0%|          | 0/6894 [00:00<?, ?ex/s]
 46%|     | 3150/6894 [00:00<00:00, 31491.70ex/s]
100%|| 4478/4478 [00:00<00:00, 31196.07ex/s]

100%|| 4478/4478 [00:00<00:00, 30579.62ex/s]

 46%|     | 3139/6894 [00:00<00:00, 31389.43ex/s]
 91%| | 6280/6894 [00:00<00:00, 31431.15ex/s]
100%|| 6894/6894 [00:00<00:00, 31450.13ex/s]

  0%|          | 0/4478 [00:00<?, ?ex/s]
  0%|          | 0/13084 [00:00<?, ?ex/s]
  0%|          | 0/13084 [00:00<?, ?ex/s]
 91%| | 6274/6894 [00:00<00:00, 31375.87ex/s]
100%|| 6894/6894 [00:00<00:00, 31420.09ex/s]

  0%|          | 0/4478 [00:00<?, ?ex/s]
 70%|   | 3118/4478 [00:00<00:00, 31178.84ex/s]
 24%|       | 3102/13084 [00:00<00:00, 31011.60ex/s]
 20%|        | 2667/13084 [00:00<00:00, 26669.45ex/s]
100%|| 4478/4478 [00:00<00:00, 31195.66ex/s]

 70%|   | 3154/4478 [00:00<00:00, 31538.00ex/s]
 48%|     | 6239/13084 [00:00<00:00, 31116.77ex/s]
  0%|          | 0/13084 [00:00<?, ?ex/s]
 44%|     | 5759/13084 [00:00<00:00, 27814.56ex/s]
100%|| 4478/4478 [00:00<00:00, 31508.03ex/s]

 72%|  | 9402/13084 [00:00<00:00, 31268.57ex/s]
  0%|          | 0/13084 [00:00<?, ?ex/s]
 24%|       | 3090/13084 [00:00<00:00, 30890.75ex/s]
 68%|   | 8834/13084 [00:00<00:00, 28633.09ex/s]
 96%|| 12558/13084 [00:00<00:00, 31352.81ex/s]
 24%|       | 3082/13084 [00:00<00:00, 30814.81ex/s]
100%|| 13084/13084 [00:00<00:00, 31377.55ex/s]

 46%|     | 5984/13084 [00:00<00:00, 30276.38ex/s]
 91%|| 11956/13084 [00:00<00:00, 29362.93ex/s]
100%|| 13084/13084 [00:00<00:00, 29809.92ex/s]

 46%|     | 5967/13084 [00:00<00:00, 30195.67ex/s]
 68%|   | 8846/13084 [00:00<00:00, 29758.72ex/s]
  0%|          | 0/30521 [00:00<?, ?ex/s]
  0%|          | 0/30521 [00:00<?, ?ex/s]
 69%|   | 9066/13084 [00:00<00:00, 30428.24ex/s]
 92%|| 11996/13084 [00:00<00:00, 30260.51ex/s]
100%|| 13084/13084 [00:00<00:00, 30041.51ex/s]

 10%|         | 3152/30521 [00:00<00:00, 31516.57ex/s]
 10%|         | 3091/30521 [00:00<00:00, 30907.08ex/s]
 93%|| 12203/13084 [00:00<00:00, 30703.60ex/s]
100%|| 13084/13084 [00:00<00:00, 30542.24ex/s]

 21%|        | 6335/30521 [00:00<00:00, 31609.26ex/s]
  0%|          | 0/30521 [00:00<?, ?ex/s]
 20%|        | 6191/30521 [00:00<00:00, 30933.78ex/s]
  0%|          | 0/30521 [00:00<?, ?ex/s]
 31%|      | 9543/30521 [00:00<00:00, 31748.43ex/s]
 10%|         | 3120/30521 [00:00<00:00, 31194.60ex/s]
 31%|       | 9328/30521 [00:00<00:00, 31063.18ex/s]
 10%|         | 3140/30521 [00:00<00:00, 31391.12ex/s]
 42%|     | 12750/30521 [00:00<00:00, 31843.01ex/s]
 21%|        | 6271/30521 [00:00<00:00, 31286.32ex/s]
 41%|      | 12455/30521 [00:00<00:00, 31124.39ex/s]
 21%|        | 6269/30521 [00:00<00:00, 31360.70ex/s]
 52%|    | 15907/30521 [00:00<00:00, 31758.82ex/s]
 31%|       | 9435/30521 [00:00<00:00, 31391.35ex/s]
 51%|     | 15445/30521 [00:00<00:00, 30744.35ex/s]
 31%|       | 9423/30521 [00:00<00:00, 31412.83ex/s]
 63%|   | 19084/30521 [00:00<00:00, 31761.61ex/s]
 41%|      | 12585/30521 [00:00<00:00, 31422.47ex/s]
 61%|    | 18590/30521 [00:00<00:00, 30950.73ex/s]
 41%|     | 12609/30521 [00:00<00:00, 31542.94ex/s]
 73%|  | 22300/30521 [00:00<00:00, 31877.84ex/s]
 51%|    | 15701/30521 [00:00<00:00, 31342.57ex/s]
 71%|   | 21729/30521 [00:00<00:00, 31079.20ex/s]
 52%|    | 15794/30521 [00:00<00:00, 31632.24ex/s]
 83%| | 25409/30521 [00:00<00:00, 31636.07ex/s]
 61%|   | 18717/30521 [00:00<00:00, 30976.96ex/s]
 81%| | 24872/30521 [00:00<00:00, 31183.09ex/s]
 62%|   | 18986/30521 [00:00<00:00, 31716.61ex/s]
 94%|| 28631/30521 [00:00<00:00, 31806.60ex/s]
 72%|  | 21874/30521 [00:00<00:00, 31152.09ex/s]
 92%|| 28006/30521 [00:00<00:00, 31229.23ex/s]
100%|| 30521/30521 [00:00<00:00, 31822.45ex/s]

 73%|  | 22160/30521 [00:00<00:00, 31723.32ex/s]
 82%| | 25018/30521 [00:00<00:00, 31236.98ex/s]
100%|| 30521/30521 [00:00<00:00, 31021.31ex/s]

  0%|          | 0/15667 [00:00<?, ?ex/s]
 83%| | 25216/30521 [00:00<00:00, 31363.64ex/s]
 92%|| 27963/30521 [00:00<00:00, 30595.51ex/s]
  0%|          | 0/15667 [00:00<?, ?ex/s]
 17%|        | 2715/15667 [00:00<00:00, 27142.71ex/s]
100%|| 30521/30521 [00:00<00:00, 31071.82ex/s]

 92%|| 28173/30521 [00:00<00:00, 30758.15ex/s]
 16%|        | 2552/15667 [00:00<00:00, 25513.33ex/s]
 38%|      | 5913/15667 [00:00<00:00, 28432.46ex/s]
100%|| 30521/30521 [00:00<00:00, 31326.73ex/s]

  0%|          | 0/15667 [00:00<?, ?ex/s]
 35%|      | 5511/15667 [00:00<00:00, 26612.01ex/s]
  0%|          | 0/15667 [00:00<?, ?ex/s]
 58%|    | 9090/15667 [00:00<00:00, 29355.94ex/s]
 20%|        | 3124/15667 [00:00<00:00, 31230.80ex/s]
 55%|    | 8640/15667 [00:00<00:00, 27860.71ex/s]
 20%|        | 3096/15667 [00:00<00:00, 30957.45ex/s]
 79%|  | 12303/15667 [00:00<00:00, 30134.59ex/s]
 40%|      | 6265/15667 [00:00<00:00, 31282.44ex/s]
 75%|  | 11804/15667 [00:00<00:00, 28895.25ex/s]
 40%|      | 6232/15667 [00:00<00:00, 31075.48ex/s]
 99%|| 15462/15667 [00:00<00:00, 30555.80ex/s]
100%|| 15667/15667 [00:00<00:00, 30925.55ex/s]
validation

  0%|          | 0/782 [00:00<?, ?ex/s]
 60%|    | 9406/15667 [00:00<00:00, 31317.88ex/s]
100%|| 782/782 [00:00<00:00, 30401.40ex/s]

 95%|| 14954/15667 [00:00<00:00, 29629.13ex/s]
 60%|    | 9362/15667 [00:00<00:00, 31141.29ex/s]
100%|| 15667/15667 [00:00<00:00, 29458.71ex/s]
validation

  0%|          | 0/782 [00:00<?, ?ex/s]
100%|| 782/782 [00:00<00:00, 29923.24ex/s]

  0%|          | 0/978 [00:00<?, ?ex/s]
 76%|  | 11865/15667 [00:00<00:00, 28942.09ex/s]
  0%|          | 0/978 [00:00<?, ?ex/s]
 80%|  | 12507/15667 [00:00<00:00, 31232.81ex/s]
100%|| 978/978 [00:00<00:00, 23983.43ex/s]

  0%|          | 0/766 [00:00<?, ?ex/s]
100%|| 978/978 [00:00<00:00, 31794.24ex/s]

  0%|          | 0/766 [00:00<?, ?ex/s]
100%|| 766/766 [00:00<00:00, 28503.82ex/s]

100%|| 766/766 [00:00<00:00, 31747.71ex/s]

 96%|| 15000/15667 [00:00<00:00, 29591.38ex/s]
100%|| 15667/15667 [00:00<00:00, 30051.71ex/s]
validation

 99%|| 15439/15667 [00:00<00:00, 30630.91ex/s]
  0%|          | 0/782 [00:00<?, ?ex/s]
100%|| 15667/15667 [00:00<00:00, 30872.96ex/s]
validation

  0%|          | 0/500 [00:00<?, ?ex/s]
  0%|          | 0/500 [00:00<?, ?ex/s]
  0%|          | 0/782 [00:00<?, ?ex/s]
100%|| 782/782 [00:00<00:00, 31854.03ex/s]

100%|| 500/500 [00:00<00:00, 18909.79ex/s]

100%|| 782/782 [00:00<00:00, 31863.31ex/s]

100%|| 500/500 [00:00<00:00, 18750.02ex/s]

  0%|          | 0/700 [00:00<?, ?ex/s]
  0%|          | 0/700 [00:00<?, ?ex/s]
  0%|          | 0/978 [00:00<?, ?ex/s]
100%|| 700/700 [00:00<00:00, 31873.69ex/s]

  0%|          | 0/978 [00:00<?, ?ex/s]
100%|| 700/700 [00:00<00:00, 23839.21ex/s]

100%|| 978/978 [00:00<00:00, 26682.64ex/s]

100%|| 978/978 [00:00<00:00, 32490.29ex/s]

  0%|          | 0/766 [00:00<?, ?ex/s]
  0%|          | 0/766 [00:00<?, ?ex/s]
100%|| 766/766 [00:00<00:00, 31936.43ex/s]

  0%|          | 0/500 [00:00<?, ?ex/s]
100%|| 766/766 [00:00<00:00, 32382.25ex/s]

  0%|          | 0/500 [00:00<?, ?ex/s]
100%|| 500/500 [00:00<00:00, 32058.21ex/s]

100%|| 500/500 [00:00<00:00, 31720.24ex/s]

  0%|          | 0/700 [00:00<?, ?ex/s]
  0%|          | 0/700 [00:00<?, ?ex/s]
100%|| 700/700 [00:00<00:00, 22727.90ex/s]

100%|| 700/700 [00:00<00:00, 20822.34ex/s]

  0%|          | 0/4181 [00:00<?, ?ex/s]
  0%|          | 0/4181 [00:00<?, ?ex/s]
  0%|          | 0/4181 [00:00<?, ?ex/s]
  0%|          | 0/4181 [00:00<?, ?ex/s]
 72%|  | 2998/4181 [00:00<00:00, 29974.81ex/s]
 72%|  | 3026/4181 [00:00<00:00, 30256.78ex/s]
 76%|  | 3157/4181 [00:00<00:00, 31566.72ex/s]
 76%|  | 3159/4181 [00:00<00:00, 31581.97ex/s]
100%|| 4181/4181 [00:00<00:00, 31554.39ex/s]

100%|| 4181/4181 [00:00<00:00, 30696.44ex/s]

100%|| 4181/4181 [00:00<00:00, 30348.27ex/s]

100%|| 4181/4181 [00:00<00:00, 31582.24ex/s]

  0%|          | 0/2235 [00:00<?, ?ex/s]
  0%|          | 0/2235 [00:00<?, ?ex/s]
  0%|          | 0/2235 [00:00<?, ?ex/s]
  0%|          | 0/2235 [00:00<?, ?ex/s]
100%|| 2235/2235 [00:00<00:00, 31991.15ex/s]
test

100%|| 2235/2235 [00:00<00:00, 31459.39ex/s]

100%|| 2235/2235 [00:00<00:00, 31205.02ex/s]
test
test

100%|| 2235/2235 [00:00<00:00, 31671.97ex/s]
test

  0%|          | 0/1953 [00:00<?, ?ex/s]
  0%|          | 0/1953 [00:00<?, ?ex/s]
  0%|          | 0/1953 [00:00<?, ?ex/s]
  0%|          | 0/1953 [00:00<?, ?ex/s]
100%|| 1953/1953 [00:00<00:00, 31609.50ex/s]

100%|| 1953/1953 [00:00<00:00, 31219.77ex/s]

100%|| 1953/1953 [00:00<00:00, 30940.54ex/s]

100%|| 1953/1953 [00:00<00:00, 29345.82ex/s]

  0%|          | 0/2443 [00:00<?, ?ex/s]
  0%|          | 0/2443 [00:00<?, ?ex/s]
  0%|          | 0/2443 [00:00<?, ?ex/s]
  0%|          | 0/2443 [00:00<?, ?ex/s]
100%|| 2443/2443 [00:00<00:00, 31894.21ex/s]

100%|| 2443/2443 [00:00<00:00, 31662.71ex/s]

100%|| 2443/2443 [00:00<00:00, 31373.52ex/s]

100%|| 2443/2443 [00:00<00:00, 31381.88ex/s]

  0%|          | 0/1521 [00:00<?, ?ex/s]
  0%|          | 0/1521 [00:00<?, ?ex/s]
  0%|          | 0/1521 [00:00<?, ?ex/s]
  0%|          | 0/1521 [00:00<?, ?ex/s]
100%|| 1521/1521 [00:00<00:00, 31233.35ex/s]

100%|| 1521/1521 [00:00<00:00, 31193.49ex/s]

100%|| 1521/1521 [00:00<00:00, 31145.82ex/s]

100%|| 1521/1521 [00:00<00:00, 30931.54ex/s]

  0%|          | 0/893 [00:00<?, ?ex/s]
  0%|          | 0/893 [00:00<?, ?ex/s]
  0%|          | 0/893 [00:00<?, ?ex/s]
  0%|          | 0/893 [00:00<?, ?ex/s]
100%|| 893/893 [00:00<00:00, 32150.33ex/s]

100%|| 893/893 [00:00<00:00, 32030.73ex/s]

100%|| 893/893 [00:00<00:00, 31899.52ex/s]

100%|| 893/893 [00:00<00:00, 32182.10ex/s]

  0%|          | 0/700 [00:00<?, ?ex/s]
  0%|          | 0/700 [00:00<?, ?ex/s]
  0%|          | 0/700 [00:00<?, ?ex/s]
  0%|          | 0/700 [00:00<?, ?ex/s]
100%|| 700/700 [00:00<00:00, 32153.28ex/s]

100%|| 700/700 [00:00<00:00, 31817.04ex/s]

100%|| 700/700 [00:00<00:00, 30502.44ex/s]

100%|| 700/700 [00:00<00:00, 18842.70ex/s]

  0%|          | 0/8621 [00:00<?, ?ex/s]
  0%|          | 0/8621 [00:00<?, ?ex/s]
  0%|          | 0/8621 [00:00<?, ?ex/s]
  0%|          | 0/8621 [00:00<?, ?ex/s]
 37%|      | 3160/8621 [00:00<00:00, 31599.13ex/s]
 35%|      | 3035/8621 [00:00<00:00, 30345.98ex/s]
 37%|      | 3179/8621 [00:00<00:00, 31786.54ex/s]
 37%|      | 3159/8621 [00:00<00:00, 31577.91ex/s]
 73%|  | 6325/8621 [00:00<00:00, 31613.70ex/s]
 71%|   | 6085/8621 [00:00<00:00, 30391.38ex/s]
 74%|  | 6363/8621 [00:00<00:00, 31799.98ex/s]
 73%|  | 6307/8621 [00:00<00:00, 31546.51ex/s]
100%|| 8621/8621 [00:00<00:00, 31610.36ex/s]

100%|| 8621/8621 [00:00<00:00, 31518.47ex/s]

100%|| 8621/8621 [00:00<00:00, 30421.61ex/s]

100%|| 8621/8621 [00:00<00:00, 31414.75ex/s]

  0%|          | 0/4386 [00:00<?, ?ex/s]
  0%|          | 0/4386 [00:00<?, ?ex/s]
  0%|          | 0/4386 [00:00<?, ?ex/s]
  0%|          | 0/4386 [00:00<?, ?ex/s]
 72%|  | 3159/4386 [00:00<00:00, 31582.88ex/s]
 73%|  | 3181/4386 [00:00<00:00, 31809.50ex/s]
 73%|  | 3184/4386 [00:00<00:00, 31835.48ex/s]
 72%|  | 3165/4386 [00:00<00:00, 31648.82ex/s]
100%|| 4386/4386 [00:00<00:00, 31482.53ex/s]

100%|| 4386/4386 [00:00<00:00, 31843.12ex/s]

100%|| 4386/4386 [00:00<00:00, 31797.77ex/s]

100%|| 4386/4386 [00:00<00:00, 31569.84ex/s]
05/25/2024 15:50:42 - INFO - utils.utils -   ***** arguments metrics *****
05/25/2024 15:50:42 - INFO - utils.utils -     adafactor = False
05/25/2024 15:50:42 - INFO - utils.utils -     adam_beta1 = 0.9
05/25/2024 15:50:42 - INFO - utils.utils -     adam_beta2 = 0.999
05/25/2024 15:50:42 - INFO - utils.utils -     adam_epsilon = 1e-08
05/25/2024 15:50:42 - INFO - utils.utils -     adapter_config_name = meta-adapter
05/25/2024 15:50:42 - INFO - utils.utils -     adapters = None
05/25/2024 15:50:42 - INFO - utils.utils -     add_layer_norm_after_adapter = True
05/25/2024 15:50:42 - INFO - utils.utils -     add_layer_norm_before_adapter = False
05/25/2024 15:50:42 - INFO - utils.utils -     attention_dropout = None
05/25/2024 15:50:42 - INFO - utils.utils -     cache_dir = None
05/25/2024 15:50:42 - INFO - utils.utils -     compute_memory = False
05/25/2024 15:50:42 - INFO - utils.utils -     compute_time = False
05/25/2024 15:50:42 - INFO - utils.utils -     conditional_layer_norm = True
05/25/2024 15:50:42 - INFO - utils.utils -     config_name = None
05/25/2024 15:50:42 - INFO - utils.utils -     data_seed = 42
05/25/2024 15:50:42 - INFO - utils.utils -     dataloader_drop_last = False
05/25/2024 15:50:42 - INFO - utils.utils -     dataloader_num_workers = 0
05/25/2024 15:50:42 - INFO - utils.utils -     debug = False
05/25/2024 15:50:42 - INFO - utils.utils -     decoder_layerdrop = None
05/25/2024 15:50:42 - INFO - utils.utils -     disable_tqdm = True
05/25/2024 15:50:42 - INFO - utils.utils -     do_eval = True
05/25/2024 15:50:42 - INFO - utils.utils -     do_predict = False
05/25/2024 15:50:42 - INFO - utils.utils -     do_test = True
05/25/2024 15:50:42 - INFO - utils.utils -     do_train = True
05/25/2024 15:50:42 - INFO - utils.utils -     dropout = None
05/25/2024 15:50:42 - INFO - utils.utils -     efficient_unique_hyper_net = True
05/25/2024 15:50:42 - INFO - utils.utils -     encoder_layerdrop = None
05/25/2024 15:50:42 - INFO - utils.utils -     eval_accumulation_steps = None
05/25/2024 15:50:42 - INFO - utils.utils -     eval_beams = 1
05/25/2024 15:50:42 - INFO - utils.utils -     eval_output_dir = None
05/25/2024 15:50:42 - INFO - utils.utils -     eval_steps = 1000
05/25/2024 15:50:42 - INFO - utils.utils -     eval_tasks = ['movieTrivia', 'movie', 'restaurant', 'atis', 'snips', 'mtod', 'mtop']
05/25/2024 15:50:42 - INFO - utils.utils -     evaluate_during_training = False
05/25/2024 15:50:42 - INFO - utils.utils -     fp16 = False
05/25/2024 15:50:42 - INFO - utils.utils -     fp16_opt_level = O1
05/25/2024 15:50:42 - INFO - utils.utils -     freeze_embeds = False
05/25/2024 15:50:42 - INFO - utils.utils -     freeze_encoder = False
05/25/2024 15:50:42 - INFO - utils.utils -     freeze_model = False
05/25/2024 15:50:42 - INFO - utils.utils -     freeze_model_but_lm_head = False
05/25/2024 15:50:42 - INFO - utils.utils -     freeze_model_but_task_embeddings = False
05/25/2024 15:50:42 - INFO - utils.utils -     generate_classifier_weights = False
05/25/2024 15:50:42 - INFO - utils.utils -     gradient_accumulation_steps = 1
05/25/2024 15:50:42 - INFO - utils.utils -     greater_is_better = True
05/25/2024 15:50:42 - INFO - utils.utils -     hidden_dim = 128
05/25/2024 15:50:42 - INFO - utils.utils -     ignore_pad_token_for_loss = True
05/25/2024 15:50:42 - INFO - utils.utils -     label_names = None
05/25/2024 15:50:42 - INFO - utils.utils -     label_smoothing = 0.1
05/25/2024 15:50:42 - INFO - utils.utils -     learning_rate = 0.0003
05/25/2024 15:50:42 - INFO - utils.utils -     load_best_model_at_end = True
05/25/2024 15:50:42 - INFO - utils.utils -     local_rank = 0
05/25/2024 15:50:42 - INFO - utils.utils -     logging_dir = runs/May25_15-50-25_gpu-16
05/25/2024 15:50:42 - INFO - utils.utils -     logging_first_step = True
05/25/2024 15:50:42 - INFO - utils.utils -     logging_steps = 200
05/25/2024 15:50:42 - INFO - utils.utils -     lr_scheduler = linear
05/25/2024 15:50:42 - INFO - utils.utils -     max_grad_norm = 1.0
05/25/2024 15:50:42 - INFO - utils.utils -     max_source_length = 128
05/25/2024 15:50:42 - INFO - utils.utils -     max_steps = 65536
05/25/2024 15:50:42 - INFO - utils.utils -     max_target_length = 128
05/25/2024 15:50:42 - INFO - utils.utils -     metric_for_best_model = average_metrics
05/25/2024 15:50:42 - INFO - utils.utils -     model_name_or_path = t5-base
05/25/2024 15:50:42 - INFO - utils.utils -     n_test = -1
05/25/2024 15:50:42 - INFO - utils.utils -     n_train = -1
05/25/2024 15:50:42 - INFO - utils.utils -     n_val = -1
05/25/2024 15:50:42 - INFO - utils.utils -     no_cuda = False
05/25/2024 15:50:42 - INFO - utils.utils -     non_linearity = gelu_new
05/25/2024 15:50:42 - INFO - utils.utils -     not_load_t5_checkpoint = False
05/25/2024 15:50:42 - INFO - utils.utils -     num_train_epochs = 100
05/25/2024 15:50:42 - INFO - utils.utils -     optimize_from_scratch = False
05/25/2024 15:50:42 - INFO - utils.utils -     optimize_from_scratch_with_loading_model = False
05/25/2024 15:50:42 - INFO - utils.utils -     output_dir = outputs/hyperformer_al++/
05/25/2024 15:50:42 - INFO - utils.utils -     overwrite_output_dir = True
05/25/2024 15:50:42 - INFO - utils.utils -     past_index = -1
05/25/2024 15:50:42 - INFO - utils.utils -     per_device_eval_batch_size = 32
05/25/2024 15:50:42 - INFO - utils.utils -     per_device_train_batch_size = 32
05/25/2024 15:50:42 - INFO - utils.utils -     per_gpu_eval_batch_size = None
05/25/2024 15:50:42 - INFO - utils.utils -     per_gpu_train_batch_size = None
05/25/2024 15:50:42 - INFO - utils.utils -     predict_with_generate = True
05/25/2024 15:50:42 - INFO - utils.utils -     prediction_loss_only = False
05/25/2024 15:50:42 - INFO - utils.utils -     print_num_parameters = True
05/25/2024 15:50:42 - INFO - utils.utils -     projected_task_embedding_dim = 64
05/25/2024 15:50:42 - INFO - utils.utils -     reduction_factor = 32
05/25/2024 15:50:42 - INFO - utils.utils -     remove_unused_columns = False
05/25/2024 15:50:42 - INFO - utils.utils -     run_name = outputs/hyperformer_al++/
05/25/2024 15:50:42 - INFO - utils.utils -     save_steps = 1000
05/25/2024 15:50:42 - INFO - utils.utils -     save_total_limit = 1
05/25/2024 15:50:42 - INFO - utils.utils -     seed = 42
05/25/2024 15:50:42 - INFO - utils.utils -     split_validation_test = True
05/25/2024 15:50:42 - INFO - utils.utils -     task_embedding_dim = 64
05/25/2024 15:50:42 - INFO - utils.utils -     task_embeddings = None
05/25/2024 15:50:42 - INFO - utils.utils -     task_hidden_dim = 128
05/25/2024 15:50:42 - INFO - utils.utils -     tasks = ['movieTrivia', 'movie', 'restaurant', 'atis', 'snips', 'mtod', 'mtop']
05/25/2024 15:50:42 - INFO - utils.utils -     temperature = 10
05/25/2024 15:50:42 - INFO - utils.utils -     test_max_target_length = 128
05/25/2024 15:50:42 - INFO - utils.utils -     tokenizer_name = t5-base
05/25/2024 15:50:42 - INFO - utils.utils -     tpu_metrics_debug = False
05/25/2024 15:50:42 - INFO - utils.utils -     tpu_num_cores = None
05/25/2024 15:50:42 - INFO - utils.utils -     train_adapters = True
05/25/2024 15:50:42 - INFO - utils.utils -     train_adapters_blocks = True
05/25/2024 15:50:42 - INFO - utils.utils -     train_task_embeddings = False
05/25/2024 15:50:42 - INFO - utils.utils -     unfreeze_layer_norms = True
05/25/2024 15:50:42 - INFO - utils.utils -     unfreeze_lm_head = False
05/25/2024 15:50:42 - INFO - utils.utils -     unfreeze_model = False
05/25/2024 15:50:42 - INFO - utils.utils -     unique_hyper_net = False
05/25/2024 15:50:42 - INFO - utils.utils -     unique_hyper_net_layer_norm = True
05/25/2024 15:50:42 - INFO - utils.utils -     val_max_target_length = 128
05/25/2024 15:50:42 - INFO - utils.utils -     warmup_steps = 500
05/25/2024 15:50:42 - INFO - utils.utils -     weight_decay = 0.0
05/25/2024 15:50:42 - INFO - third_party.trainers.t5_trainer -   ***** Running training *****
05/25/2024 15:50:42 - INFO - third_party.trainers.t5_trainer -     Num examples = 86475
05/25/2024 15:50:42 - INFO - third_party.trainers.t5_trainer -     Num Epochs = 98
05/25/2024 15:50:42 - INFO - third_party.trainers.t5_trainer -     Instantaneous batch size per device = 32
05/25/2024 15:50:42 - INFO - third_party.trainers.t5_trainer -     Total train batch size (w. parallel, distributed & accumulation) = 128
05/25/2024 15:50:42 - INFO - third_party.trainers.t5_trainer -     Gradient Accumulation steps = 1
05/25/2024 15:50:42 - INFO - third_party.trainers.t5_trainer -     Total optimization steps = 65536
{'loss': 7197.18896484375, 'learning_rate': 6e-07, 'epoch': 0.0014814814814814814}
{'loss': 4082.9249298249056, 'learning_rate': 0.00011999999999999999, 'epoch': 0.2962962962962963}
{'loss': 2094.10625, 'learning_rate': 0.00023999999999999998, 'epoch': 0.5925925925925926}
{'loss': 1917.98, 'learning_rate': 0.00029953871701826677, 'epoch': 0.8888888888888888}
{'loss': 1740.905, 'learning_rate': 0.0002986161510548004, 'epoch': 1.1851851851851851}
{'loss': 1575.2375, 'learning_rate': 0.000297693585091334, 'epoch': 1.4814814814814814}
05/25/2024 15:56:49 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/25/2024 15:58:06 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 2132.129638671875
05/25/2024 15:58:06 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.3785473785473785
05/25/2024 15:58:06 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 15:58:06 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/25/2024 15:59:15 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1296.8662109375
05/25/2024 15:59:15 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.5907780979827091
05/25/2024 15:59:15 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 15:59:15 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/25/2024 16:00:05 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1099.0430908203125
05/25/2024 16:00:05 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.6044728434504791
05/25/2024 16:00:05 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 16:00:05 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/25/2024 16:00:48 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 2105.89697265625
05/25/2024 16:00:48 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.6540993417115499
05/25/2024 16:00:48 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 16:00:48 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/25/2024 16:01:34 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1236.9775390625
05/25/2024 16:01:34 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.505014749262537
05/25/2024 16:01:34 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 16:01:34 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/25/2024 16:05:36 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 828.51220703125
05/25/2024 16:05:36 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.7996681874740772
05/25/2024 16:05:36 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 16:05:36 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/25/2024 16:08:05 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1343.603515625
05/25/2024 16:08:05 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.33371363377067886
05/25/2024 16:08:05 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1478.58125, 'learning_rate': 0.0002967710191278676, 'epoch': 1.7777777777777777}
{'loss': 1430.07375, 'learning_rate': 0.0002958484531644012, 'epoch': 2.074074074074074}
{'loss': 1489.1, 'learning_rate': 0.00029492588720093487, 'epoch': 2.3703703703703702}
{'loss': 1453.3175, 'learning_rate': 0.00029400332123746847, 'epoch': 2.6666666666666665}
{'loss': 1417.7775, 'learning_rate': 0.00029308075527400206, 'epoch': 2.962962962962963}
05/25/2024 16:14:19 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/25/2024 16:15:33 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 2004.0218505859375
05/25/2024 16:15:33 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.5888989169675091
05/25/2024 16:15:33 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 16:15:33 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/25/2024 16:16:41 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1232.71240234375
05/25/2024 16:16:41 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.7609710550887021
05/25/2024 16:16:41 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 16:16:41 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/25/2024 16:17:32 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1056.2799072265625
05/25/2024 16:17:32 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.7164750957854406
05/25/2024 16:17:32 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 16:17:32 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/25/2024 16:18:16 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1943.2357177734375
05/25/2024 16:18:16 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.8562263050452028
05/25/2024 16:18:16 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 16:18:16 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/25/2024 16:19:02 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1131.4842529296875
05/25/2024 16:19:02 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.7695280154568036
05/25/2024 16:19:02 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 16:19:02 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/25/2024 16:23:04 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 785.1281127929688
05/25/2024 16:23:04 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.929103683202044
05/25/2024 16:23:04 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 16:23:04 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/25/2024 16:25:37 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1240.416259765625
05/25/2024 16:25:37 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.41683252772249074
05/25/2024 16:25:37 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1454.55625, 'learning_rate': 0.00029215818931053566, 'epoch': 3.259259259259259}
{'loss': 1395.97375, 'learning_rate': 0.0002912356233470693, 'epoch': 3.5555555555555554}
{'loss': 1407.7875, 'learning_rate': 0.0002903130573836029, 'epoch': 3.851851851851852}
{'loss': 1422.22, 'learning_rate': 0.0002893904914201365, 'epoch': 4.148148148148148}
{'loss': 1425.395, 'learning_rate': 0.0002884679254566701, 'epoch': 4.444444444444445}
05/25/2024 16:31:51 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/25/2024 16:33:05 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1961.3887939453125
05/25/2024 16:33:05 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.6279016318087796
05/25/2024 16:33:05 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 16:33:05 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/25/2024 16:34:13 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1210.3995361328125
05/25/2024 16:34:13 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.8199432892249527
05/25/2024 16:34:13 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 16:34:13 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/25/2024 16:35:02 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1038.267578125
05/25/2024 16:35:02 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.7543343146876023
05/25/2024 16:35:02 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 16:35:02 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/25/2024 16:35:46 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1902.8385009765625
05/25/2024 16:35:46 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.9190295235311313
05/25/2024 16:35:46 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 16:35:46 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/25/2024 16:36:33 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1091.7259521484375
05/25/2024 16:36:33 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.8371308016877635
05/25/2024 16:36:33 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 16:36:33 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/25/2024 16:40:35 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 774.5511474609375
05/25/2024 16:40:35 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.9436448263515932
05/25/2024 16:40:35 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 16:40:35 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/25/2024 16:43:07 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1173.26171875
05/25/2024 16:43:07 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.6406187491665556
05/25/2024 16:43:07 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1360.51, 'learning_rate': 0.00028754535949320376, 'epoch': 4.7407407407407405}
{'loss': 1350.825, 'learning_rate': 0.00028662279352973736, 'epoch': 5.037037037037037}
{'loss': 1403.7775, 'learning_rate': 0.00028570022756627095, 'epoch': 5.333333333333333}
{'loss': 1363.2075, 'learning_rate': 0.00028477766160280455, 'epoch': 5.62962962962963}
{'loss': 1426.3025, 'learning_rate': 0.0002838550956393382, 'epoch': 5.925925925925926}
05/25/2024 16:49:21 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/25/2024 16:50:37 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1967.04736328125
05/25/2024 16:50:37 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.624751491053678
05/25/2024 16:50:37 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 16:50:37 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/25/2024 16:51:45 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1198.3233642578125
05/25/2024 16:51:45 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.848470363288719
05/25/2024 16:51:45 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 16:51:45 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/25/2024 16:52:37 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1039.381103515625
05/25/2024 16:52:37 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.7421299397186871
05/25/2024 16:52:37 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 16:52:37 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/25/2024 16:53:21 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1876.4638671875
05/25/2024 16:53:21 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.9456140350877194
05/25/2024 16:53:21 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 16:53:21 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/25/2024 16:54:08 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1084.40771484375
05/25/2024 16:54:08 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.8698801894678183
05/25/2024 16:54:08 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 16:54:08 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/25/2024 16:58:11 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 772.1677856445312
05/25/2024 16:58:11 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.9471333909536156
05/25/2024 16:58:11 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 16:58:11 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/25/2024 17:00:47 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1162.6248779296875
05/25/2024 17:00:47 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.6693153224738445
05/25/2024 17:00:47 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1320.71, 'learning_rate': 0.0002829325296758718, 'epoch': 6.222222222222222}
{'loss': 1318.1225, 'learning_rate': 0.0002820099637124054, 'epoch': 6.518518518518518}
{'loss': 1431.2575, 'learning_rate': 0.00028108739774893905, 'epoch': 6.814814814814815}
{'loss': 1311.7675, 'learning_rate': 0.0002801648317854726, 'epoch': 7.111111111111111}
{'loss': 1328.5075, 'learning_rate': 0.00027924226582200625, 'epoch': 7.407407407407407}
05/25/2024 17:07:04 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/25/2024 17:08:16 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1944.4814453125
05/25/2024 17:08:16 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.6615764653042893
05/25/2024 17:08:16 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 17:08:16 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/25/2024 17:09:24 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1193.31494140625
05/25/2024 17:09:24 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.8482563619227145
05/25/2024 17:09:24 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 17:09:24 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/25/2024 17:10:14 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1035.296630859375
05/25/2024 17:10:14 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.7665394402035622
05/25/2024 17:10:14 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 17:10:14 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/25/2024 17:10:58 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1870.86572265625
05/25/2024 17:10:58 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.9537470725995316
05/25/2024 17:10:58 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 17:10:58 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/25/2024 17:11:45 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1076.390380859375
05/25/2024 17:11:45 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.8897571867150432
05/25/2024 17:11:45 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 17:11:45 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/25/2024 17:15:46 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 772.4722290039062
05/25/2024 17:15:46 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.9478551611296863
05/25/2024 17:15:46 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 17:15:46 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/25/2024 17:18:19 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1153.133056640625
05/25/2024 17:18:19 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.714062092355857
05/25/2024 17:18:19 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1319.575, 'learning_rate': 0.00027831969985853984, 'epoch': 7.703703703703704}
{'loss': 1308.59, 'learning_rate': 0.0002773971338950735, 'epoch': 8.0}
{'loss': 1320.42, 'learning_rate': 0.0002764745679316071, 'epoch': 8.296296296296296}
{'loss': 1355.995, 'learning_rate': 0.0002755520019681407, 'epoch': 8.592592592592592}
{'loss': 1335.63, 'learning_rate': 0.0002746294360046743, 'epoch': 8.88888888888889}
05/25/2024 17:24:47 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/25/2024 17:26:00 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1953.1646728515625
05/25/2024 17:26:00 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.6527324188983236
05/25/2024 17:26:00 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 17:26:00 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/25/2024 17:27:09 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1194.0384521484375
05/25/2024 17:27:09 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.8518691588785047
05/25/2024 17:27:09 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 17:27:09 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/25/2024 17:27:59 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1033.6103515625
05/25/2024 17:27:59 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.7602040816326531
05/25/2024 17:27:59 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 17:27:59 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/25/2024 17:28:44 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1860.7037353515625
05/25/2024 17:28:44 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.957284961966062
05/25/2024 17:28:44 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 17:28:44 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/25/2024 17:29:32 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1069.76318359375
05/25/2024 17:29:32 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.8924015529672767
05/25/2024 17:29:32 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 17:29:32 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/25/2024 17:33:35 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 769.706787109375
05/25/2024 17:33:35 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.9493166287015945
05/25/2024 17:33:35 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 17:33:35 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/25/2024 17:36:16 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1138.7720947265625
05/25/2024 17:36:16 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.7217125382262997
05/25/2024 17:36:16 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1296.085, 'learning_rate': 0.00027370687004120794, 'epoch': 9.185185185185185}
{'loss': 1303.525, 'learning_rate': 0.00027278430407774154, 'epoch': 9.481481481481481}
{'loss': 1309.89, 'learning_rate': 0.00027186173811427514, 'epoch': 9.777777777777779}
{'loss': 1345.345, 'learning_rate': 0.00027093917215080873, 'epoch': 10.074074074074074}
{'loss': 1323.665, 'learning_rate': 0.0002700166061873424, 'epoch': 10.37037037037037}
05/25/2024 17:42:36 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/25/2024 17:43:48 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1932.1943359375
05/25/2024 17:43:48 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.6678555506018725
05/25/2024 17:43:48 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 17:43:48 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/25/2024 17:44:56 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1191.0252685546875
05/25/2024 17:44:56 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.8526838496098369
05/25/2024 17:44:56 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 17:44:56 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/25/2024 17:45:46 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1028.041259765625
05/25/2024 17:45:46 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.7591810204744882
05/25/2024 17:45:46 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 17:45:46 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/25/2024 17:46:29 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1854.7098388671875
05/25/2024 17:46:29 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.9583577712609971
05/25/2024 17:46:29 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 17:46:29 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/25/2024 17:47:15 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1067.1490478515625
05/25/2024 17:47:15 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.8861971830985915
05/25/2024 17:47:15 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 17:47:15 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/25/2024 17:51:17 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 775.609375
05/25/2024 17:51:17 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.9385240162442235
05/25/2024 17:51:17 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 17:51:17 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/25/2024 17:53:48 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1136.17431640625
05/25/2024 17:53:48 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.746531483457844
05/25/2024 17:53:48 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1328.125, 'learning_rate': 0.000269094040223876, 'epoch': 10.666666666666666}
{'loss': 1363.91, 'learning_rate': 0.0002681714742604096, 'epoch': 10.962962962962964}
{'loss': 1354.615, 'learning_rate': 0.0002672489082969432, 'epoch': 11.25925925925926}
{'loss': 1304.41, 'learning_rate': 0.00026632634233347683, 'epoch': 11.555555555555555}
{'loss': 1277.02, 'learning_rate': 0.00026540377637001043, 'epoch': 11.851851851851851}
05/25/2024 18:00:03 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/25/2024 18:01:13 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1934.39404296875
05/25/2024 18:01:13 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.6559714795008913
05/25/2024 18:01:13 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 18:01:13 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/25/2024 18:02:22 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1189.4857177734375
05/25/2024 18:02:22 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.8564661297963051
05/25/2024 18:02:22 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 18:02:22 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/25/2024 18:03:11 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1033.6229248046875
05/25/2024 18:03:11 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.7675606641123882
05/25/2024 18:03:11 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 18:03:11 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/25/2024 18:03:55 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1854.1395263671875
05/25/2024 18:03:55 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.9654161781946073
05/25/2024 18:03:55 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 18:03:55 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/25/2024 18:04:41 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1065.879638671875
05/25/2024 18:04:41 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.8849307322589766
05/25/2024 18:04:41 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 18:04:41 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/25/2024 18:08:43 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 767.745849609375
05/25/2024 18:08:43 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.9579723634280805
05/25/2024 18:08:43 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 18:08:43 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/25/2024 18:11:15 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1148.09814453125
05/25/2024 18:11:15 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.7061767417358094
05/25/2024 18:11:15 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1334.475, 'learning_rate': 0.000264481210406544, 'epoch': 12.148148148148149}
{'loss': 1319.785, 'learning_rate': 0.0002635586444430776, 'epoch': 12.444444444444445}
{'loss': 1326.015, 'learning_rate': 0.0002626360784796113, 'epoch': 12.74074074074074}
{'loss': 1284.91, 'learning_rate': 0.0002617135125161449, 'epoch': 13.037037037037036}
{'loss': 1267.905, 'learning_rate': 0.0002607909465526785, 'epoch': 13.333333333333334}
05/25/2024 18:17:27 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/25/2024 18:18:38 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1928.0635986328125
05/25/2024 18:18:38 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.6645655110310671
05/25/2024 18:18:38 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 18:18:38 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/25/2024 18:19:46 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1186.145751953125
05/25/2024 18:19:46 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.8709829867674859
05/25/2024 18:19:46 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 18:19:46 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/25/2024 18:20:35 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1034.1307373046875
05/25/2024 18:20:35 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.7666021921341071
05/25/2024 18:20:35 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 18:20:35 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/25/2024 18:21:20 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1847.2208251953125
05/25/2024 18:21:20 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.9701579871269749
05/25/2024 18:21:20 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 18:21:20 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/25/2024 18:22:06 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1064.9910888671875
05/25/2024 18:22:06 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.9047091412742382
05/25/2024 18:22:06 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 18:22:06 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/25/2024 18:26:08 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 765.9810791015625
05/25/2024 18:26:08 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.9546488484503839
05/25/2024 18:26:08 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 18:26:08 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/25/2024 18:28:41 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1120.57421875
05/25/2024 18:28:41 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.7839130997025735
05/25/2024 18:28:41 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1337.53, 'learning_rate': 0.0002598683805892121, 'epoch': 13.62962962962963}
{'loss': 1341.365, 'learning_rate': 0.0002589458146257457, 'epoch': 13.925925925925926}
{'loss': 1319.775, 'learning_rate': 0.0002580232486622793, 'epoch': 14.222222222222221}
{'loss': 1302.575, 'learning_rate': 0.00025710068269881297, 'epoch': 14.518518518518519}
{'loss': 1338.035, 'learning_rate': 0.00025617811673534657, 'epoch': 14.814814814814815}
05/25/2024 18:35:00 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/25/2024 18:36:12 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1927.552490234375
05/25/2024 18:36:12 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.6653386454183267
05/25/2024 18:36:12 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 18:36:12 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/25/2024 18:37:20 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1185.0609130859375
05/25/2024 18:37:20 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.8564066526118529
05/25/2024 18:37:20 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 18:37:20 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/25/2024 18:38:09 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1039.3365478515625
05/25/2024 18:38:09 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.7588403950302643
05/25/2024 18:38:09 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 18:38:09 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/25/2024 18:38:53 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1854.5416259765625
05/25/2024 18:38:53 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.9657594381035997
05/25/2024 18:38:53 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 18:38:53 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/25/2024 18:39:40 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1059.7703857421875
05/25/2024 18:39:40 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.9031543995572773
05/25/2024 18:39:40 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 18:39:40 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/25/2024 18:43:45 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 766.7933349609375
05/25/2024 18:43:45 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.9559095434504338
05/25/2024 18:43:45 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 18:43:45 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/25/2024 18:46:17 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1115.46533203125
05/25/2024 18:46:17 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.7941214387005284
05/25/2024 18:46:17 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1353.815, 'learning_rate': 0.00025525555077188017, 'epoch': 15.11111111111111}
{'loss': 1331.6, 'learning_rate': 0.00025433298480841376, 'epoch': 15.407407407407407}
{'loss': 1235.075, 'learning_rate': 0.0002534104188449474, 'epoch': 15.703703703703704}
{'loss': 1365.49, 'learning_rate': 0.000252487852881481, 'epoch': 16.0}
{'loss': 1305.565, 'learning_rate': 0.0002515652869180146, 'epoch': 16.296296296296298}
05/25/2024 18:52:28 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/25/2024 18:53:38 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1928.721923828125
05/25/2024 18:53:38 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.6656312402928779
05/25/2024 18:53:38 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 18:53:38 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/25/2024 18:54:47 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1187.47607421875
05/25/2024 18:54:47 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.8620527306967984
05/25/2024 18:54:47 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 18:54:47 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/25/2024 18:55:36 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1032.884033203125
05/25/2024 18:55:36 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.7723916532905296
05/25/2024 18:55:36 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 18:55:36 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/25/2024 18:56:21 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1850.7137451171875
05/25/2024 18:56:21 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.9626168224299065
05/25/2024 18:56:21 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 18:56:21 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/25/2024 18:57:08 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1061.7640380859375
05/25/2024 18:57:08 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.9098474341192788
05/25/2024 18:57:08 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 18:57:08 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/25/2024 19:01:10 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 766.2473754882812
05/25/2024 19:01:10 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.9565030762626986
05/25/2024 19:01:10 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 19:01:10 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/25/2024 19:03:45 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1114.10986328125
05/25/2024 19:03:45 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.7919689119170985
05/25/2024 19:03:45 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1310.355, 'learning_rate': 0.0002506427209545482, 'epoch': 16.59259259259259}
{'loss': 1322.71, 'learning_rate': 0.00024972015499108186, 'epoch': 16.88888888888889}
{'loss': 1342.665, 'learning_rate': 0.00024879758902761546, 'epoch': 17.185185185185187}
{'loss': 1328.23, 'learning_rate': 0.00024787502306414905, 'epoch': 17.48148148148148}
{'loss': 1351.4, 'learning_rate': 0.00024695245710068265, 'epoch': 17.77777777777778}
05/25/2024 19:10:13 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/25/2024 19:11:23 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1929.3131103515625
05/25/2024 19:11:23 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.6682991985752449
05/25/2024 19:11:23 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 19:11:23 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/25/2024 19:12:31 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1187.39794921875
05/25/2024 19:12:31 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.8667450058754407
05/25/2024 19:12:31 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 19:12:31 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/25/2024 19:13:20 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1030.73193359375
05/25/2024 19:13:20 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.7589776771271433
05/25/2024 19:13:20 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 19:13:20 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/25/2024 19:14:04 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1849.856689453125
05/25/2024 19:14:04 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.9713282621416033
05/25/2024 19:14:04 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 19:14:04 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/25/2024 19:14:50 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1057.5081787109375
05/25/2024 19:14:50 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.9232480533926585
05/25/2024 19:14:50 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 19:14:50 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/25/2024 19:18:52 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 765.917724609375
05/25/2024 19:18:52 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.957396703061443
05/25/2024 19:18:52 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 19:18:52 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/25/2024 19:21:25 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1111.061767578125
05/25/2024 19:21:25 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.8087872091511764
05/25/2024 19:21:25 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1259.56, 'learning_rate': 0.00024602989113721625, 'epoch': 18.074074074074073}
{'loss': 1270.12, 'learning_rate': 0.0002451073251737499, 'epoch': 18.37037037037037}
{'loss': 1298.62, 'learning_rate': 0.0002441847592102835, 'epoch': 18.666666666666668}
{'loss': 1267.76, 'learning_rate': 0.00024326219324681712, 'epoch': 18.962962962962962}
{'loss': 1300.37, 'learning_rate': 0.00024233962728335072, 'epoch': 19.25925925925926}
05/25/2024 19:27:41 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/25/2024 19:28:52 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1921.9769287109375
05/25/2024 19:28:52 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.6675579322638147
05/25/2024 19:28:52 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 19:28:52 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/25/2024 19:30:00 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1185.3173828125
05/25/2024 19:30:00 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.8679602460955987
05/25/2024 19:30:00 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 19:30:00 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/25/2024 19:30:50 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1031.1656494140625
05/25/2024 19:30:50 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.7694784288473921
05/25/2024 19:30:50 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 19:30:50 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/25/2024 19:31:34 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1849.189697265625
05/25/2024 19:31:34 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.9692712906057944
05/25/2024 19:31:34 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 19:31:34 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/25/2024 19:32:20 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1056.1278076171875
05/25/2024 19:32:20 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.9184239733629301
05/25/2024 19:32:20 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 19:32:20 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/25/2024 19:36:22 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 765.3279418945312
05/25/2024 19:36:22 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.9563359213619202
05/25/2024 19:36:22 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 19:36:22 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/25/2024 19:38:57 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1107.1357421875
05/25/2024 19:38:57 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.8127448419952991
05/25/2024 19:38:57 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1327.97, 'learning_rate': 0.00024141706131988435, 'epoch': 19.555555555555557}
{'loss': 1285.6, 'learning_rate': 0.00024049449535641794, 'epoch': 19.85185185185185}
{'loss': 1370.63, 'learning_rate': 0.00023957192939295157, 'epoch': 20.14814814814815}
{'loss': 1294.67, 'learning_rate': 0.00023864936342948517, 'epoch': 20.444444444444443}
{'loss': 1273.16, 'learning_rate': 0.0002377267974660188, 'epoch': 20.74074074074074}
05/25/2024 19:45:11 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/25/2024 19:46:21 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1926.167236328125
05/25/2024 19:46:21 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.6752098983650022
05/25/2024 19:46:21 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 19:46:21 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/25/2024 19:47:31 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1187.217041015625
05/25/2024 19:47:31 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.8602150537634409
05/25/2024 19:47:31 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 19:47:31 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/25/2024 19:48:22 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1036.9537353515625
05/25/2024 19:48:22 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.770077720207254
05/25/2024 19:48:22 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 19:48:22 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/25/2024 19:49:07 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1844.3201904296875
05/25/2024 19:49:07 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.9701055099648299
05/25/2024 19:49:07 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 19:49:07 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/25/2024 19:49:54 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1060.336181640625
05/25/2024 19:49:54 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.9137787635153868
05/25/2024 19:49:54 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 19:49:54 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/25/2024 19:53:59 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 766.5771484375
05/25/2024 19:53:59 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.9551454932576295
05/25/2024 19:53:59 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 19:53:59 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/25/2024 19:56:40 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1109.440185546875
05/25/2024 19:56:40 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.8061975468043899
05/25/2024 19:56:40 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1294.31, 'learning_rate': 0.0002368042315025524, 'epoch': 21.037037037037038}
{'loss': 1299.5, 'learning_rate': 0.00023588166553908604, 'epoch': 21.333333333333332}
{'loss': 1275.94, 'learning_rate': 0.0002349590995756196, 'epoch': 21.62962962962963}
{'loss': 1317.53, 'learning_rate': 0.00023403653361215326, 'epoch': 21.925925925925927}
{'loss': 1281.43, 'learning_rate': 0.00023311396764868686, 'epoch': 22.22222222222222}
05/25/2024 20:02:51 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/25/2024 20:04:02 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1923.22412109375
05/25/2024 20:04:02 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.6769505924435503
05/25/2024 20:04:02 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 20:04:02 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/25/2024 20:05:11 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1186.869140625
05/25/2024 20:05:11 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.8670411985018728
05/25/2024 20:05:11 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 20:05:11 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/25/2024 20:06:00 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1038.0609130859375
05/25/2024 20:06:00 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.7658207516864761
05/25/2024 20:06:00 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 20:06:00 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/25/2024 20:06:44 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1850.9560546875
05/25/2024 20:06:44 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.9698389458272328
05/25/2024 20:06:44 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 20:06:44 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/25/2024 20:07:31 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1057.2840576171875
05/25/2024 20:07:31 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.9146341463414634
05/25/2024 20:07:31 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 20:07:31 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/25/2024 20:11:36 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 765.57666015625
05/25/2024 20:11:36 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.9563796533105996
05/25/2024 20:11:36 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 20:11:36 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/25/2024 20:14:15 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1107.0091552734375
05/25/2024 20:14:15 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.8161143599740093
05/25/2024 20:14:15 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1313.12, 'learning_rate': 0.00023219140168522049, 'epoch': 22.51851851851852}
{'loss': 1351.11, 'learning_rate': 0.00023126883572175408, 'epoch': 22.814814814814813}
{'loss': 1287.74, 'learning_rate': 0.0002303462697582877, 'epoch': 23.11111111111111}
{'loss': 1319.03, 'learning_rate': 0.0002294237037948213, 'epoch': 23.40740740740741}
{'loss': 1289.91, 'learning_rate': 0.00022850113783135493, 'epoch': 23.703703703703702}
05/25/2024 20:20:26 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/25/2024 20:21:36 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1930.0546875
05/25/2024 20:21:36 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.6769028295678877
05/25/2024 20:21:36 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 20:21:36 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/25/2024 20:22:46 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1188.222900390625
05/25/2024 20:22:46 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.8610851262862488
05/25/2024 20:22:46 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 20:22:46 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/25/2024 20:23:35 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1040.0189208984375
05/25/2024 20:23:35 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.7746113989637305
05/25/2024 20:23:35 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 20:23:35 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/25/2024 20:24:20 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1843.5926513671875
05/25/2024 20:24:20 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.9742388758782202
05/25/2024 20:24:20 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 20:24:20 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/25/2024 20:25:07 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1055.46923828125
05/25/2024 20:25:07 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.9141428174492916
05/25/2024 20:25:07 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 20:25:07 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/25/2024 20:29:15 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 765.951416015625
05/25/2024 20:29:15 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.9574059588992392
05/25/2024 20:29:15 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 20:29:15 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/25/2024 20:31:50 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1109.071044921875
05/25/2024 20:31:50 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.8027106508119167
05/25/2024 20:31:50 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1336.36, 'learning_rate': 0.00022757857186788853, 'epoch': 24.0}
{'loss': 1277.71, 'learning_rate': 0.00022665600590442215, 'epoch': 24.296296296296298}
{'loss': 1254.67, 'learning_rate': 0.00022573343994095575, 'epoch': 24.59259259259259}
{'loss': 1311.6, 'learning_rate': 0.00022481087397748938, 'epoch': 24.88888888888889}
{'loss': 1251.42, 'learning_rate': 0.00022388830801402297, 'epoch': 25.185185185185187}
05/25/2024 20:37:54 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/25/2024 20:39:05 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1925.5804443359375
05/25/2024 20:39:05 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.676963812886143
05/25/2024 20:39:05 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 20:39:05 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/25/2024 20:40:13 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1187.880859375
05/25/2024 20:40:13 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.8708469817501171
05/25/2024 20:40:13 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 20:40:13 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/25/2024 20:41:01 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1037.60546875
05/25/2024 20:41:01 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.7678972712680577
05/25/2024 20:41:01 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 20:41:01 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/25/2024 20:41:46 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1844.2021484375
05/25/2024 20:41:46 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.9748538011695906
05/25/2024 20:41:46 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 20:41:46 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/25/2024 20:42:33 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1057.75732421875
05/25/2024 20:42:33 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.9150943396226414
05/25/2024 20:42:33 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 20:42:33 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/25/2024 20:46:38 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 765.2944946289062
05/25/2024 20:46:38 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.9569915404848226
05/25/2024 20:46:38 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 20:46:38 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/25/2024 20:49:11 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1111.3060302734375
05/25/2024 20:49:11 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.8252527871402645
05/25/2024 20:49:11 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1316.37, 'learning_rate': 0.0002229657420505566, 'epoch': 25.48148148148148}
{'loss': 1282.43, 'learning_rate': 0.0002220431760870902, 'epoch': 25.77777777777778}
{'loss': 1269.09, 'learning_rate': 0.00022112061012362382, 'epoch': 26.074074074074073}
{'loss': 1307.5, 'learning_rate': 0.00022019804416015742, 'epoch': 26.37037037037037}
{'loss': 1328.32, 'learning_rate': 0.00021927547819669104, 'epoch': 26.666666666666668}
05/25/2024 20:55:17 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/25/2024 20:56:26 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1925.443359375
05/25/2024 20:56:26 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.669279338123231
05/25/2024 20:56:26 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 20:56:26 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/25/2024 20:57:34 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1188.1265869140625
05/25/2024 20:57:34 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.8588616381304952
05/25/2024 20:57:34 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 20:57:34 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/25/2024 20:58:23 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1036.6846923828125
05/25/2024 20:58:23 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.7692307692307692
05/25/2024 20:58:23 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 20:58:23 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/25/2024 20:59:07 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1843.8802490234375
05/25/2024 20:59:07 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.9736688121708601
05/25/2024 20:59:07 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 20:59:07 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/25/2024 20:59:53 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1057.7734375
05/25/2024 20:59:53 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.9099473538376281
05/25/2024 20:59:53 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 20:59:53 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/25/2024 21:03:55 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 765.068603515625
05/25/2024 21:03:55 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.9605974395448078
05/25/2024 21:03:55 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 21:03:55 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/25/2024 21:06:27 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1102.167236328125
05/25/2024 21:06:27 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.8279444228022336
05/25/2024 21:06:27 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1313.67, 'learning_rate': 0.00021835291223322464, 'epoch': 26.962962962962962}
{'loss': 1295.92, 'learning_rate': 0.0002174303462697583, 'epoch': 27.25925925925926}
{'loss': 1399.9, 'learning_rate': 0.0002165077803062919, 'epoch': 27.555555555555557}
{'loss': 1264.18, 'learning_rate': 0.00021558521434282552, 'epoch': 27.85185185185185}
{'loss': 1244.0, 'learning_rate': 0.0002146626483793591, 'epoch': 28.14814814814815}
05/25/2024 21:12:34 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/25/2024 21:13:44 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1931.550537109375
05/25/2024 21:13:44 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.6722763507528787
05/25/2024 21:13:44 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 21:13:44 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/25/2024 21:14:53 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1191.1396484375
05/25/2024 21:14:53 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.8508626802174427
05/25/2024 21:14:53 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 21:14:53 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/25/2024 21:15:43 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1041.5472412109375
05/25/2024 21:15:43 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.7686809616634178
05/25/2024 21:15:43 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 21:15:43 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/25/2024 21:16:27 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1840.69384765625
05/25/2024 21:16:27 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.9754385964912281
05/25/2024 21:16:27 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 21:16:27 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/25/2024 21:17:13 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1058.0902099609375
05/25/2024 21:17:13 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.9163191548512648
05/25/2024 21:17:13 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 21:17:13 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/25/2024 21:21:15 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 766.665283203125
05/25/2024 21:21:15 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.958131586442609
05/25/2024 21:21:15 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 21:21:15 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/25/2024 21:23:49 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1107.166259765625
05/25/2024 21:23:49 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.8223888314374354
05/25/2024 21:23:49 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1272.47, 'learning_rate': 0.00021374008241589274, 'epoch': 28.444444444444443}
{'loss': 1280.08, 'learning_rate': 0.00021281751645242634, 'epoch': 28.74074074074074}
{'loss': 1294.86, 'learning_rate': 0.00021189495048895996, 'epoch': 29.037037037037038}
{'loss': 1296.73, 'learning_rate': 0.00021097238452549356, 'epoch': 29.333333333333332}
{'loss': 1365.44, 'learning_rate': 0.00021004981856202716, 'epoch': 29.62962962962963}
05/25/2024 21:30:02 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/25/2024 21:31:12 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1927.880615234375
05/25/2024 21:31:12 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.6874861572535992
05/25/2024 21:31:12 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 21:31:12 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/25/2024 21:32:22 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1188.4261474609375
05/25/2024 21:32:22 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.8597390493942219
05/25/2024 21:32:22 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 21:32:22 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/25/2024 21:33:12 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1039.850830078125
05/25/2024 21:33:12 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.7682417229186757
05/25/2024 21:33:12 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 21:33:12 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/25/2024 21:33:57 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1835.09716796875
05/25/2024 21:33:57 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.977465613110916
05/25/2024 21:33:57 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 21:33:57 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/25/2024 21:34:44 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1054.845947265625
05/25/2024 21:34:44 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.914428136250346
05/25/2024 21:34:44 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 21:34:44 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/25/2024 21:38:48 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 764.7146606445312
05/25/2024 21:38:48 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.9583511016346837
05/25/2024 21:38:48 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 21:38:48 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/25/2024 21:41:28 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1098.4395751953125
05/25/2024 21:41:28 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.8337398895878804
05/25/2024 21:41:28 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1323.96, 'learning_rate': 0.00020912725259856078, 'epoch': 29.925925925925927}
{'loss': 1304.09, 'learning_rate': 0.00020820468663509438, 'epoch': 30.22222222222222}
{'loss': 1337.23, 'learning_rate': 0.000207282120671628, 'epoch': 30.51851851851852}
{'loss': 1273.39, 'learning_rate': 0.0002063595547081616, 'epoch': 30.814814814814813}
{'loss': 1327.43, 'learning_rate': 0.00020543698874469523, 'epoch': 31.11111111111111}
05/25/2024 21:47:39 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/25/2024 21:48:51 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1940.7462158203125
05/25/2024 21:48:51 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.6704103671706263
05/25/2024 21:48:51 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 21:48:51 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/25/2024 21:50:00 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1187.1783447265625
05/25/2024 21:50:00 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.8653576437587658
05/25/2024 21:50:00 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 21:50:00 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/25/2024 21:50:51 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1052.5201416015625
05/25/2024 21:50:51 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.7612655800575263
05/25/2024 21:50:51 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 21:50:51 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/25/2024 21:51:35 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1839.72265625
05/25/2024 21:51:35 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.9739689967826849
05/25/2024 21:51:35 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 21:51:35 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/25/2024 21:52:23 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1053.90087890625
05/25/2024 21:52:23 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.9214979195561721
05/25/2024 21:52:23 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 21:52:23 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/25/2024 21:56:29 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 766.6309204101562
05/25/2024 21:56:29 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.9566635931626357
05/25/2024 21:56:29 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 21:56:29 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/25/2024 21:59:06 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1102.642578125
05/25/2024 21:59:06 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.8308168795973674
05/25/2024 21:59:06 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1209.55, 'learning_rate': 0.00020451442278122882, 'epoch': 31.40740740740741}
{'loss': 1233.43, 'learning_rate': 0.00020359185681776245, 'epoch': 31.703703703703702}
{'loss': 1309.7, 'learning_rate': 0.00020266929085429605, 'epoch': 32.0}
{'loss': 1330.65, 'learning_rate': 0.00020174672489082967, 'epoch': 32.2962962962963}
{'loss': 1281.44, 'learning_rate': 0.00020082415892736327, 'epoch': 32.592592592592595}
05/25/2024 22:05:16 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/25/2024 22:06:28 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1930.5484619140625
05/25/2024 22:06:28 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.6785071942446044
05/25/2024 22:06:28 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 22:06:28 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/25/2024 22:07:38 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1191.52587890625
05/25/2024 22:07:38 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.8704271890488554
05/25/2024 22:07:38 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 22:07:38 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/25/2024 22:08:29 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1048.74462890625
05/25/2024 22:08:29 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.7658473479948253
05/25/2024 22:08:29 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 22:08:29 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/25/2024 22:09:14 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1842.5670166015625
05/25/2024 22:09:14 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.9777647747220597
05/25/2024 22:09:14 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 22:09:14 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/25/2024 22:10:01 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1055.813232421875
05/25/2024 22:10:01 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.9253399944490703
05/25/2024 22:10:01 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 22:10:01 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/25/2024 22:14:04 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 766.4701538085938
05/25/2024 22:14:04 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.9587636208247275
05/25/2024 22:14:04 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 22:14:04 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/25/2024 22:16:40 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1104.814697265625
05/25/2024 22:16:40 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.8326827998959145
05/25/2024 22:16:40 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1316.33, 'learning_rate': 0.00019990159296389692, 'epoch': 32.888888888888886}
{'loss': 1241.63, 'learning_rate': 0.0001989790270004305, 'epoch': 33.18518518518518}
{'loss': 1292.86, 'learning_rate': 0.00019805646103696414, 'epoch': 33.48148148148148}
{'loss': 1301.63, 'learning_rate': 0.00019713389507349774, 'epoch': 33.77777777777778}
{'loss': 1293.6, 'learning_rate': 0.00019621132911003136, 'epoch': 34.074074074074076}
05/25/2024 22:22:52 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/25/2024 22:24:03 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1927.53515625
05/25/2024 22:24:03 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.6798313734191259
05/25/2024 22:24:03 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 22:24:03 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/25/2024 22:25:11 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1186.5848388671875
05/25/2024 22:25:11 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.8693181818181818
05/25/2024 22:25:11 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 22:25:11 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/25/2024 22:26:00 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1044.681884765625
05/25/2024 22:26:00 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.7590673575129533
05/25/2024 22:26:00 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 22:26:00 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/25/2024 22:26:44 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1838.0885009765625
05/25/2024 22:26:44 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.9762949956101844
05/25/2024 22:26:44 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 22:26:44 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/25/2024 22:27:31 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1050.9794921875
05/25/2024 22:27:31 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.9251738525730181
05/25/2024 22:27:31 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 22:27:31 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/25/2024 22:31:36 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 764.4313354492188
05/25/2024 22:31:36 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.9619169875909285
05/25/2024 22:31:36 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 22:31:36 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/25/2024 22:34:07 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1099.16650390625
05/25/2024 22:34:07 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.837434554973822
05/25/2024 22:34:07 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1232.39, 'learning_rate': 0.00019528876314656496, 'epoch': 34.370370370370374}
{'loss': 1310.02, 'learning_rate': 0.0001943661971830986, 'epoch': 34.666666666666664}
{'loss': 1282.74, 'learning_rate': 0.00019344363121963218, 'epoch': 34.96296296296296}
{'loss': 1258.15, 'learning_rate': 0.0001925210652561658, 'epoch': 35.25925925925926}
{'loss': 1286.06, 'learning_rate': 0.0001915984992926994, 'epoch': 35.55555555555556}
05/25/2024 22:40:12 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/25/2024 22:41:22 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1930.1297607421875
05/25/2024 22:41:22 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.6756637168141594
05/25/2024 22:41:22 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 22:41:22 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/25/2024 22:42:31 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1189.738037109375
05/25/2024 22:42:31 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.863326276170313
05/25/2024 22:42:31 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 22:42:31 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/25/2024 22:43:20 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1051.910400390625
05/25/2024 22:43:20 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.757487922705314
05/25/2024 22:43:20 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 22:43:20 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/25/2024 22:44:05 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1838.0498046875
05/25/2024 22:44:05 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.978050921861282
05/25/2024 22:44:05 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 22:44:05 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/25/2024 22:44:52 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1057.9049072265625
05/25/2024 22:44:52 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.9125728559533721
05/25/2024 22:44:52 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 22:44:52 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/25/2024 22:48:58 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 765.357177734375
05/25/2024 22:48:58 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.9591067491643552
05/25/2024 22:48:58 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 22:48:58 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/25/2024 22:51:30 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1098.0552978515625
05/25/2024 22:51:30 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.8430840759395584
05/25/2024 22:51:30 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1283.89, 'learning_rate': 0.00019067593332923303, 'epoch': 35.851851851851855}
{'loss': 1295.13, 'learning_rate': 0.00018975336736576663, 'epoch': 36.148148148148145}
{'loss': 1291.09, 'learning_rate': 0.00018883080140230025, 'epoch': 36.44444444444444}
{'loss': 1267.96, 'learning_rate': 0.00018790823543883385, 'epoch': 36.74074074074074}
{'loss': 1275.24, 'learning_rate': 0.00018698566947536748, 'epoch': 37.03703703703704}
05/25/2024 22:57:34 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/25/2024 22:58:42 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1938.0299072265625
05/25/2024 22:58:42 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.6846254927726675
05/25/2024 22:58:42 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 22:58:42 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/25/2024 22:59:51 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1191.745361328125
05/25/2024 22:59:51 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.8601496725912067
05/25/2024 22:59:51 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 22:59:51 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/25/2024 23:00:41 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1054.3973388671875
05/25/2024 23:00:41 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.7555123216601816
05/25/2024 23:00:41 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 23:00:41 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/25/2024 23:01:25 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1838.9010009765625
05/25/2024 23:01:25 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.9809774656131109
05/25/2024 23:01:25 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 23:01:25 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/25/2024 23:02:11 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1053.638916015625
05/25/2024 23:02:11 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.9242298084929226
05/25/2024 23:02:11 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 23:02:11 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/25/2024 23:06:14 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 764.159912109375
05/25/2024 23:06:14 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.9608500320901378
05/25/2024 23:06:14 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 23:06:14 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/25/2024 23:08:50 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1099.7689208984375
05/25/2024 23:08:50 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.8448119912133351
05/25/2024 23:08:50 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1308.64, 'learning_rate': 0.00018606310351190107, 'epoch': 37.333333333333336}
{'loss': 1267.1, 'learning_rate': 0.0001851405375484347, 'epoch': 37.629629629629626}
{'loss': 1331.14, 'learning_rate': 0.0001842179715849683, 'epoch': 37.925925925925924}
{'loss': 1220.64, 'learning_rate': 0.00018329540562150192, 'epoch': 38.22222222222222}
{'loss': 1239.5, 'learning_rate': 0.00018237283965803552, 'epoch': 38.51851851851852}
05/25/2024 23:15:00 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/25/2024 23:16:07 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1924.483642578125
05/25/2024 23:16:07 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.6784922394678492
05/25/2024 23:16:07 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 23:16:07 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/25/2024 23:17:17 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1189.03857421875
05/25/2024 23:17:17 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.8666196189131968
05/25/2024 23:17:17 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 23:17:17 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/25/2024 23:18:06 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1049.08056640625
05/25/2024 23:18:06 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.7552986512524085
05/25/2024 23:18:06 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 23:18:06 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/25/2024 23:18:49 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1838.8270263671875
05/25/2024 23:18:49 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.9724824355971896
05/25/2024 23:18:49 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 23:18:49 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/25/2024 23:19:36 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1050.8756103515625
05/25/2024 23:19:36 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.9328151027207108
05/25/2024 23:19:36 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 23:19:36 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/25/2024 23:23:41 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 765.2450561523438
05/25/2024 23:23:41 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.9590402498757719
05/25/2024 23:23:41 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 23:23:41 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/25/2024 23:26:13 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1096.3369140625
05/25/2024 23:26:13 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.8396749645298595
05/25/2024 23:26:13 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1326.52, 'learning_rate': 0.00018145027369456917, 'epoch': 38.81481481481482}
{'loss': 1307.92, 'learning_rate': 0.00018052770773110277, 'epoch': 39.111111111111114}
{'loss': 1249.94, 'learning_rate': 0.0001796051417676364, 'epoch': 39.407407407407405}
{'loss': 1321.36, 'learning_rate': 0.00017868257580417, 'epoch': 39.7037037037037}
{'loss': 1262.64, 'learning_rate': 0.00017776000984070362, 'epoch': 40.0}
05/25/2024 23:32:21 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/25/2024 23:33:28 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1926.6005859375
05/25/2024 23:33:28 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.6779431664411367
05/25/2024 23:33:28 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 23:33:28 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/25/2024 23:34:37 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1193.3929443359375
05/25/2024 23:34:37 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.8563327032136105
05/25/2024 23:34:37 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 23:34:37 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/25/2024 23:35:26 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1051.2552490234375
05/25/2024 23:35:26 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.7656808579785507
05/25/2024 23:35:26 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 23:35:26 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/25/2024 23:36:10 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1838.049560546875
05/25/2024 23:36:10 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.9768803043605502
05/25/2024 23:36:10 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 23:36:10 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/25/2024 23:36:57 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1055.329345703125
05/25/2024 23:36:57 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.9312169312169312
05/25/2024 23:36:57 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 23:36:57 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/25/2024 23:40:58 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 765.0851440429688
05/25/2024 23:40:58 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.9615082482325217
05/25/2024 23:40:58 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 23:40:58 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/25/2024 23:43:31 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1096.7694091796875
05/25/2024 23:43:31 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.8518229166666667
05/25/2024 23:43:31 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1265.82, 'learning_rate': 0.0001768374438772372, 'epoch': 40.2962962962963}
{'loss': 1249.56, 'learning_rate': 0.00017591487791377084, 'epoch': 40.592592592592595}
{'loss': 1309.96, 'learning_rate': 0.00017499231195030444, 'epoch': 40.888888888888886}
{'loss': 1229.48, 'learning_rate': 0.00017406974598683803, 'epoch': 41.18518518518518}
{'loss': 1279.14, 'learning_rate': 0.00017314718002337166, 'epoch': 41.48148148148148}
05/25/2024 23:49:38 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/25/2024 23:50:48 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1926.6798095703125
05/25/2024 23:50:48 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.6758711374095988
05/25/2024 23:50:48 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 23:50:48 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/25/2024 23:51:56 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1191.434814453125
05/25/2024 23:51:56 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.8602200889721376
05/25/2024 23:51:56 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 23:51:56 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/25/2024 23:52:46 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1059.982666015625
05/25/2024 23:52:46 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.7657657657657658
05/25/2024 23:52:46 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 23:52:46 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/25/2024 23:53:30 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1836.3997802734375
05/25/2024 23:53:30 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.9754242246928029
05/25/2024 23:53:30 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 23:53:30 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/25/2024 23:54:16 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1054.0501708984375
05/25/2024 23:54:16 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.9243138342112559
05/25/2024 23:54:16 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 23:54:16 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/25/2024 23:58:21 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 766.3389282226562
05/25/2024 23:58:21 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.959356537831874
05/25/2024 23:58:21 - INFO - utils.utils -   config is reset to the initial values.
05/25/2024 23:58:21 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/26/2024 00:00:53 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1093.98193359375
05/26/2024 00:00:53 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.8479917344698437
05/26/2024 00:00:53 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1299.24, 'learning_rate': 0.00017222461405990526, 'epoch': 41.77777777777778}
{'loss': 1287.9, 'learning_rate': 0.00017130204809643888, 'epoch': 42.074074074074076}
{'loss': 1311.74, 'learning_rate': 0.00017037948213297248, 'epoch': 42.370370370370374}
{'loss': 1288.88, 'learning_rate': 0.0001694569161695061, 'epoch': 42.666666666666664}
{'loss': 1356.46, 'learning_rate': 0.0001685343502060397, 'epoch': 42.96296296296296}
05/26/2024 00:07:03 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/26/2024 00:08:10 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1926.317138671875
05/26/2024 00:08:10 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.681999115435648
05/26/2024 00:08:10 - INFO - utils.utils -   config is reset to the initial values.
05/26/2024 00:08:10 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/26/2024 00:09:18 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1192.7830810546875
05/26/2024 00:09:18 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.8541423570595098
05/26/2024 00:09:18 - INFO - utils.utils -   config is reset to the initial values.
05/26/2024 00:09:18 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/26/2024 00:10:07 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1057.965576171875
05/26/2024 00:10:07 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.7537072856221793
05/26/2024 00:10:07 - INFO - utils.utils -   config is reset to the initial values.
05/26/2024 00:10:07 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/26/2024 00:10:50 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1833.2181396484375
05/26/2024 00:10:50 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.9774392030471726
05/26/2024 00:10:50 - INFO - utils.utils -   config is reset to the initial values.
05/26/2024 00:10:50 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/26/2024 00:11:37 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1054.60595703125
05/26/2024 00:11:37 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.9257714762301918
05/26/2024 00:11:37 - INFO - utils.utils -   config is reset to the initial values.
05/26/2024 00:11:37 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/26/2024 00:15:38 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 764.9207763671875
05/26/2024 00:15:38 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.9608262108262107
05/26/2024 00:15:38 - INFO - utils.utils -   config is reset to the initial values.
05/26/2024 00:15:38 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/26/2024 00:18:12 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1098.3670654296875
05/26/2024 00:18:12 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.8457968024755029
05/26/2024 00:18:12 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1277.96, 'learning_rate': 0.00016761178424257333, 'epoch': 43.25925925925926}
{'loss': 1254.12, 'learning_rate': 0.00016668921827910692, 'epoch': 43.55555555555556}
{'loss': 1273.1, 'learning_rate': 0.00016576665231564055, 'epoch': 43.851851851851855}
{'loss': 1316.22, 'learning_rate': 0.00016484408635217415, 'epoch': 44.148148148148145}
{'loss': 1285.9, 'learning_rate': 0.00016392152038870777, 'epoch': 44.44444444444444}
05/26/2024 00:24:21 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/26/2024 00:25:29 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1930.4110107421875
05/26/2024 00:25:29 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.6788013318534961
05/26/2024 00:25:29 - INFO - utils.utils -   config is reset to the initial values.
05/26/2024 00:25:29 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/26/2024 00:26:37 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1193.8214111328125
05/26/2024 00:26:37 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.8621908127208481
05/26/2024 00:26:37 - INFO - utils.utils -   config is reset to the initial values.
05/26/2024 00:26:37 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/26/2024 00:27:26 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1061.0885009765625
05/26/2024 00:27:26 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.7550096961861668
05/26/2024 00:27:26 - INFO - utils.utils -   config is reset to the initial values.
05/26/2024 00:27:26 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/26/2024 00:28:10 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1837.9705810546875
05/26/2024 00:28:10 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.9771395076201641
05/26/2024 00:28:10 - INFO - utils.utils -   config is reset to the initial values.
05/26/2024 00:28:10 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/26/2024 00:28:56 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1055.5372314453125
05/26/2024 00:28:56 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.9299610894941636
05/26/2024 00:28:56 - INFO - utils.utils -   config is reset to the initial values.
05/26/2024 00:28:56 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/26/2024 00:32:58 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 766.5330200195312
05/26/2024 00:32:58 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.9591923787857244
05/26/2024 00:32:58 - INFO - utils.utils -   config is reset to the initial values.
05/26/2024 00:32:58 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/26/2024 00:35:30 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1095.6845703125
05/26/2024 00:35:30 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.8550137272846123
05/26/2024 00:35:30 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1253.98, 'learning_rate': 0.00016299895442524137, 'epoch': 44.74074074074074}
{'loss': 1197.3, 'learning_rate': 0.00016207638846177502, 'epoch': 45.03703703703704}
{'loss': 1314.04, 'learning_rate': 0.00016115382249830862, 'epoch': 45.333333333333336}
{'loss': 1321.76, 'learning_rate': 0.00016023125653484224, 'epoch': 45.629629629629626}
{'loss': 1311.36, 'learning_rate': 0.00015930869057137584, 'epoch': 45.925925925925924}
05/26/2024 00:41:40 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/26/2024 00:42:43 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1937.82421875
05/26/2024 00:42:43 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.6649168853893264
05/26/2024 00:42:43 - INFO - utils.utils -   config is reset to the initial values.
05/26/2024 00:42:43 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/26/2024 00:43:51 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1195.3204345703125
05/26/2024 00:43:51 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.8586190699859089
05/26/2024 00:43:51 - INFO - utils.utils -   config is reset to the initial values.
05/26/2024 00:43:51 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/26/2024 00:44:40 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1057.3759765625
05/26/2024 00:44:40 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.7558851983231216
05/26/2024 00:44:40 - INFO - utils.utils -   config is reset to the initial values.
05/26/2024 00:44:40 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/26/2024 00:45:24 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1837.80078125
05/26/2024 00:45:24 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.9792093704245974
05/26/2024 00:45:24 - INFO - utils.utils -   config is reset to the initial values.
05/26/2024 00:45:24 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/26/2024 00:46:10 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1051.5042724609375
05/26/2024 00:46:10 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.9335926646290637
05/26/2024 00:46:10 - INFO - utils.utils -   config is reset to the initial values.
05/26/2024 00:46:10 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/26/2024 00:50:12 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 770.4487915039062
05/26/2024 00:50:12 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.9384433470125895
05/26/2024 00:50:12 - INFO - utils.utils -   config is reset to the initial values.
05/26/2024 00:50:12 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/26/2024 00:52:45 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1096.073974609375
05/26/2024 00:52:45 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.8549323017408124
05/26/2024 00:52:45 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1233.64, 'learning_rate': 0.00015838612460790946, 'epoch': 46.22222222222222}
{'loss': 1255.72, 'learning_rate': 0.00015746355864444306, 'epoch': 46.51851851851852}
{'loss': 1271.14, 'learning_rate': 0.0001565409926809767, 'epoch': 46.81481481481482}
{'loss': 1249.12, 'learning_rate': 0.00015561842671751028, 'epoch': 47.111111111111114}
{'loss': 1229.86, 'learning_rate': 0.0001546958607540439, 'epoch': 47.407407407407405}
05/26/2024 00:58:53 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/26/2024 00:59:59 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1939.8084716796875
05/26/2024 00:59:59 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.6624119718309859
05/26/2024 00:59:59 - INFO - utils.utils -   config is reset to the initial values.
05/26/2024 00:59:59 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/26/2024 01:01:07 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1201.3289794921875
05/26/2024 01:01:07 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.8504781898763704
05/26/2024 01:01:07 - INFO - utils.utils -   config is reset to the initial values.
05/26/2024 01:01:07 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/26/2024 01:01:56 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1060.986083984375
05/26/2024 01:01:56 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.7657920310981537
05/26/2024 01:01:56 - INFO - utils.utils -   config is reset to the initial values.
05/26/2024 01:01:56 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/26/2024 01:02:39 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1834.962158203125
05/26/2024 01:02:39 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.9774392030471726
05/26/2024 01:02:39 - INFO - utils.utils -   config is reset to the initial values.
05/26/2024 01:02:39 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/26/2024 01:03:26 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1052.514404296875
05/26/2024 01:03:26 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.9286309358511524
05/26/2024 01:03:26 - INFO - utils.utils -   config is reset to the initial values.
05/26/2024 01:03:26 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/26/2024 01:07:27 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 766.7237548828125
05/26/2024 01:07:27 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.9608708025042687
05/26/2024 01:07:27 - INFO - utils.utils -   config is reset to the initial values.
05/26/2024 01:07:27 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/26/2024 01:10:00 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1095.98291015625
05/26/2024 01:10:00 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.8578501628664497
05/26/2024 01:10:00 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1243.34, 'learning_rate': 0.0001537732947905775, 'epoch': 47.7037037037037}
{'loss': 1320.08, 'learning_rate': 0.00015285072882711113, 'epoch': 48.0}
{'loss': 1294.46, 'learning_rate': 0.00015192816286364473, 'epoch': 48.2962962962963}
{'loss': 1258.94, 'learning_rate': 0.00015100559690017835, 'epoch': 48.592592592592595}
{'loss': 1273.48, 'learning_rate': 0.00015008303093671195, 'epoch': 48.888888888888886}
05/26/2024 01:16:08 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/26/2024 01:17:17 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1934.7841796875
05/26/2024 01:17:17 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.6810004387889426
05/26/2024 01:17:17 - INFO - utils.utils -   config is reset to the initial values.
05/26/2024 01:17:17 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/26/2024 01:18:25 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1195.8155517578125
05/26/2024 01:18:25 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.8636684718624912
05/26/2024 01:18:25 - INFO - utils.utils -   config is reset to the initial values.
05/26/2024 01:18:25 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/26/2024 01:19:13 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1068.8798828125
05/26/2024 01:19:13 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.7534246575342465
05/26/2024 01:19:13 - INFO - utils.utils -   config is reset to the initial values.
05/26/2024 01:19:13 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/26/2024 01:19:57 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1837.2135009765625
05/26/2024 01:19:57 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.9789350497366881
05/26/2024 01:19:57 - INFO - utils.utils -   config is reset to the initial values.
05/26/2024 01:19:57 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/26/2024 01:20:43 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1053.19873046875
05/26/2024 01:20:43 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.9307756463719766
05/26/2024 01:20:43 - INFO - utils.utils -   config is reset to the initial values.
05/26/2024 01:20:43 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/26/2024 01:24:45 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 766.1057739257812
05/26/2024 01:24:45 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.9618668184405237
05/26/2024 01:24:45 - INFO - utils.utils -   config is reset to the initial values.
05/26/2024 01:24:45 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/26/2024 01:27:17 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1094.051025390625
05/26/2024 01:27:17 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.8524334847501622
05/26/2024 01:27:17 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1292.84, 'learning_rate': 0.00014916046497324558, 'epoch': 49.18518518518518}
{'loss': 1253.6, 'learning_rate': 0.00014823789900977917, 'epoch': 49.48148148148148}
{'loss': 1281.2, 'learning_rate': 0.0001473153330463128, 'epoch': 49.77777777777778}
{'loss': 1351.02, 'learning_rate': 0.0001463927670828464, 'epoch': 50.074074074074076}
{'loss': 1262.06, 'learning_rate': 0.00014547020111938002, 'epoch': 50.370370370370374}
05/26/2024 01:33:27 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/26/2024 01:34:34 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1931.4140625
05/26/2024 01:34:34 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.6814782226132864
05/26/2024 01:34:34 - INFO - utils.utils -   config is reset to the initial values.
05/26/2024 01:34:34 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/26/2024 01:35:42 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1195.6231689453125
05/26/2024 01:35:42 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.8629751290473957
05/26/2024 01:35:42 - INFO - utils.utils -   config is reset to the initial values.
05/26/2024 01:35:42 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/26/2024 01:36:32 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1058.5689697265625
05/26/2024 01:36:32 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.7639291465378422
05/26/2024 01:36:32 - INFO - utils.utils -   config is reset to the initial values.
05/26/2024 01:36:32 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/26/2024 01:37:16 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1836.1722412109375
05/26/2024 01:37:16 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.977465613110916
05/26/2024 01:37:16 - INFO - utils.utils -   config is reset to the initial values.
05/26/2024 01:37:16 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/26/2024 01:38:02 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1055.637939453125
05/26/2024 01:38:02 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.9377777777777778
05/26/2024 01:38:02 - INFO - utils.utils -   config is reset to the initial values.
05/26/2024 01:38:02 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/26/2024 01:42:03 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 767.4067993164062
05/26/2024 01:42:03 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.9587988329893973
05/26/2024 01:42:03 - INFO - utils.utils -   config is reset to the initial values.
05/26/2024 01:42:03 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/26/2024 01:44:37 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1093.7269287109375
05/26/2024 01:44:37 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.8476889403888245
05/26/2024 01:44:37 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1266.96, 'learning_rate': 0.00014454763515591362, 'epoch': 50.666666666666664}
{'loss': 1272.02, 'learning_rate': 0.00014362506919244724, 'epoch': 50.96296296296296}
{'loss': 1269.02, 'learning_rate': 0.00014270250322898087, 'epoch': 51.25925925925926}
{'loss': 1273.52, 'learning_rate': 0.00014177993726551447, 'epoch': 51.55555555555556}
{'loss': 1279.2, 'learning_rate': 0.0001408573713020481, 'epoch': 51.851851851851855}
05/26/2024 01:50:46 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/26/2024 01:51:57 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1939.057373046875
05/26/2024 01:51:57 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.6634488810881966
05/26/2024 01:51:57 - INFO - utils.utils -   config is reset to the initial values.
05/26/2024 01:51:57 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/26/2024 01:53:05 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1196.27783203125
05/26/2024 01:53:05 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.8664632715325041
05/26/2024 01:53:05 - INFO - utils.utils -   config is reset to the initial values.
05/26/2024 01:53:05 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/26/2024 01:53:54 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1065.5074462890625
05/26/2024 01:53:54 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.7636480411046885
05/26/2024 01:53:54 - INFO - utils.utils -   config is reset to the initial values.
05/26/2024 01:53:54 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/26/2024 01:54:38 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1836.9688720703125
05/26/2024 01:54:38 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.9768803043605502
05/26/2024 01:54:38 - INFO - utils.utils -   config is reset to the initial values.
05/26/2024 01:54:38 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/26/2024 01:55:24 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1051.84326171875
05/26/2024 01:55:24 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.9378123264852859
05/26/2024 01:55:24 - INFO - utils.utils -   config is reset to the initial values.
05/26/2024 01:55:24 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/26/2024 01:59:26 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 765.4976196289062
05/26/2024 01:59:26 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.9608094627333619
05/26/2024 01:59:26 - INFO - utils.utils -   config is reset to the initial values.
05/26/2024 01:59:26 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/26/2024 02:01:58 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1094.9776611328125
05/26/2024 02:01:58 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.848770277341706
05/26/2024 02:01:58 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1300.9, 'learning_rate': 0.0001399348053385817, 'epoch': 52.148148148148145}
{'loss': 1264.42, 'learning_rate': 0.00013901223937511531, 'epoch': 52.44444444444444}
{'loss': 1288.24, 'learning_rate': 0.0001380896734116489, 'epoch': 52.74074074074074}
{'loss': 1257.52, 'learning_rate': 0.00013716710744818254, 'epoch': 53.03703703703704}
{'loss': 1336.26, 'learning_rate': 0.00013624454148471613, 'epoch': 53.333333333333336}
05/26/2024 02:08:09 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/26/2024 02:09:17 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1934.479248046875
05/26/2024 02:09:17 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.6744959007312209
05/26/2024 02:09:17 - INFO - utils.utils -   config is reset to the initial values.
05/26/2024 02:09:17 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/26/2024 02:10:25 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1196.995849609375
05/26/2024 02:10:25 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.8741440377804015
05/26/2024 02:10:25 - INFO - utils.utils -   config is reset to the initial values.
05/26/2024 02:10:25 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/26/2024 02:11:13 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1064.178955078125
05/26/2024 02:11:13 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.7692307692307692
05/26/2024 02:11:13 - INFO - utils.utils -   config is reset to the initial values.
05/26/2024 02:11:13 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/26/2024 02:11:57 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1835.3912353515625
05/26/2024 02:11:57 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.9774787949692894
05/26/2024 02:11:57 - INFO - utils.utils -   config is reset to the initial values.
05/26/2024 02:11:57 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/26/2024 02:12:44 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1054.002197265625
05/26/2024 02:12:44 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.9302971396834212
05/26/2024 02:12:44 - INFO - utils.utils -   config is reset to the initial values.
05/26/2024 02:12:44 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/26/2024 02:16:46 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 765.7010498046875
05/26/2024 02:16:46 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.962515114873035
05/26/2024 02:16:46 - INFO - utils.utils -   config is reset to the initial values.
05/26/2024 02:16:46 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/26/2024 02:19:18 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1094.4451904296875
05/26/2024 02:19:18 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.8554326610279765
05/26/2024 02:19:18 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1335.94, 'learning_rate': 0.00013532197552124976, 'epoch': 53.629629629629626}
{'loss': 1278.5, 'learning_rate': 0.00013439940955778338, 'epoch': 53.925925925925924}
{'loss': 1256.36, 'learning_rate': 0.00013347684359431698, 'epoch': 54.22222222222222}
{'loss': 1250.6, 'learning_rate': 0.0001325542776308506, 'epoch': 54.51851851851852}
{'loss': 1272.6, 'learning_rate': 0.0001316317116673842, 'epoch': 54.81481481481482}
05/26/2024 02:25:29 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/26/2024 02:26:35 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1933.2081298828125
05/26/2024 02:26:35 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.6741573033707865
05/26/2024 02:26:35 - INFO - utils.utils -   config is reset to the initial values.
05/26/2024 02:26:35 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/26/2024 02:27:43 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1196.020751953125
05/26/2024 02:27:43 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.8650292397660819
05/26/2024 02:27:43 - INFO - utils.utils -   config is reset to the initial values.
05/26/2024 02:27:43 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/26/2024 02:28:32 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1065.803955078125
05/26/2024 02:28:32 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.7597549177684618
05/26/2024 02:28:32 - INFO - utils.utils -   config is reset to the initial values.
05/26/2024 02:28:32 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/26/2024 02:29:16 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1835.7587890625
05/26/2024 02:29:16 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.9772063120981882
05/26/2024 02:29:16 - INFO - utils.utils -   config is reset to the initial values.
05/26/2024 02:29:16 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/26/2024 02:30:02 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1053.043701171875
05/26/2024 02:30:02 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.932259855635758
05/26/2024 02:30:02 - INFO - utils.utils -   config is reset to the initial values.
05/26/2024 02:30:02 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/26/2024 02:34:03 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 765.6578979492188
05/26/2024 02:34:03 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.9610925385873816
05/26/2024 02:34:03 - INFO - utils.utils -   config is reset to the initial values.
05/26/2024 02:34:03 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/26/2024 02:36:39 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1093.189208984375
05/26/2024 02:36:39 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.8586224754013463
05/26/2024 02:36:39 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1309.72, 'learning_rate': 0.00013070914570391783, 'epoch': 55.111111111111114}
{'loss': 1289.28, 'learning_rate': 0.00012978657974045143, 'epoch': 55.407407407407405}
{'loss': 1267.02, 'learning_rate': 0.00012886401377698505, 'epoch': 55.7037037037037}
{'loss': 1251.38, 'learning_rate': 0.00012794144781351865, 'epoch': 56.0}
{'loss': 1244.96, 'learning_rate': 0.00012701888185005227, 'epoch': 56.2962962962963}
05/26/2024 02:42:48 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/26/2024 02:43:56 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1936.53466796875
05/26/2024 02:43:56 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.6854521625163826
05/26/2024 02:43:56 - INFO - utils.utils -   config is reset to the initial values.
05/26/2024 02:43:56 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/26/2024 02:45:04 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1197.840576171875
05/26/2024 02:45:04 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.8643592142188962
05/26/2024 02:45:04 - INFO - utils.utils -   config is reset to the initial values.
05/26/2024 02:45:04 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/26/2024 02:45:53 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1065.333251953125
05/26/2024 02:45:53 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.7652005174644243
05/26/2024 02:45:53 - INFO - utils.utils -   config is reset to the initial values.
05/26/2024 02:45:53 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/26/2024 02:46:36 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1835.655029296875
05/26/2024 02:46:36 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.978337236533958
05/26/2024 02:46:36 - INFO - utils.utils -   config is reset to the initial values.
05/26/2024 02:46:36 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/26/2024 02:47:23 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1054.2823486328125
05/26/2024 02:47:23 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.9340751043115438
05/26/2024 02:47:23 - INFO - utils.utils -   config is reset to the initial values.
05/26/2024 02:47:23 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/26/2024 02:51:24 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 765.9967651367188
05/26/2024 02:51:24 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.9597496799886218
05/26/2024 02:51:24 - INFO - utils.utils -   config is reset to the initial values.
05/26/2024 02:51:24 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/26/2024 02:53:57 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1094.972412109375
05/26/2024 02:53:57 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.8547118731468352
05/26/2024 02:53:57 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1304.18, 'learning_rate': 0.0001260963158865859, 'epoch': 56.592592592592595}
{'loss': 1266.36, 'learning_rate': 0.0001251737499231195, 'epoch': 56.888888888888886}
{'loss': 1278.88, 'learning_rate': 0.00012425118395965312, 'epoch': 57.18518518518518}
{'loss': 1203.94, 'learning_rate': 0.00012332861799618672, 'epoch': 57.48148148148148}
{'loss': 1298.72, 'learning_rate': 0.00012240605203272034, 'epoch': 57.77777777777778}
05/26/2024 03:00:07 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/26/2024 03:01:14 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1935.826904296875
05/26/2024 03:01:14 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.6787290379523389
05/26/2024 03:01:14 - INFO - utils.utils -   config is reset to the initial values.
05/26/2024 03:01:14 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/26/2024 03:02:22 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1196.5743408203125
05/26/2024 03:02:22 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.8665259207131127
05/26/2024 03:02:22 - INFO - utils.utils -   config is reset to the initial values.
05/26/2024 03:02:22 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/26/2024 03:03:11 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1064.8568115234375
05/26/2024 03:03:11 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.767404555662496
05/26/2024 03:03:11 - INFO - utils.utils -   config is reset to the initial values.
05/26/2024 03:03:11 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/26/2024 03:03:55 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1833.78076171875
05/26/2024 03:03:55 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.9789596727060199
05/26/2024 03:03:55 - INFO - utils.utils -   config is reset to the initial values.
05/26/2024 03:03:55 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/26/2024 03:04:42 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1052.394775390625
05/26/2024 03:04:42 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.9281553398058252
05/26/2024 03:04:42 - INFO - utils.utils -   config is reset to the initial values.
05/26/2024 03:04:42 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/26/2024 03:08:43 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 766.5148315429688
05/26/2024 03:08:43 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.9598974285917801
05/26/2024 03:08:43 - INFO - utils.utils -   config is reset to the initial values.
05/26/2024 03:08:43 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/26/2024 03:11:15 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1095.719482421875
05/26/2024 03:11:15 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.8549202644885259
05/26/2024 03:11:15 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1252.04, 'learning_rate': 0.00012148348606925395, 'epoch': 58.074074074074076}
{'loss': 1284.64, 'learning_rate': 0.00012056092010578755, 'epoch': 58.370370370370374}
{'loss': 1259.94, 'learning_rate': 0.00011963835414232116, 'epoch': 58.666666666666664}
{'loss': 1258.74, 'learning_rate': 0.00011871578817885477, 'epoch': 58.96296296296296}
{'loss': 1312.76, 'learning_rate': 0.00011779322221538839, 'epoch': 59.25925925925926}
05/26/2024 03:17:25 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/26/2024 03:18:32 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1940.698486328125
05/26/2024 03:18:32 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.6782113108285841
05/26/2024 03:18:32 - INFO - utils.utils -   config is reset to the initial values.
05/26/2024 03:18:32 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/26/2024 03:19:39 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1199.2998046875
05/26/2024 03:19:39 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.8656786638438015
05/26/2024 03:19:39 - INFO - utils.utils -   config is reset to the initial values.
05/26/2024 03:19:39 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/26/2024 03:20:28 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1064.669921875
05/26/2024 03:20:28 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.7658615136876006
05/26/2024 03:20:28 - INFO - utils.utils -   config is reset to the initial values.
05/26/2024 03:20:28 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/26/2024 03:21:12 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1833.366455078125
05/26/2024 03:21:12 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.9812865497076023
05/26/2024 03:21:12 - INFO - utils.utils -   config is reset to the initial values.
05/26/2024 03:21:12 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/26/2024 03:21:58 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1052.67333984375
05/26/2024 03:21:58 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.9375173562899195
05/26/2024 03:21:58 - INFO - utils.utils -   config is reset to the initial values.
05/26/2024 03:21:58 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/26/2024 03:25:59 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 765.6006469726562
05/26/2024 03:25:59 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.960746598275985
05/26/2024 03:25:59 - INFO - utils.utils -   config is reset to the initial values.
05/26/2024 03:25:59 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/26/2024 03:28:33 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1095.8109130859375
05/26/2024 03:28:33 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.8553279751101892
05/26/2024 03:28:33 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1314.52, 'learning_rate': 0.000116870656251922, 'epoch': 59.55555555555556}
{'loss': 1250.3, 'learning_rate': 0.00011594809028845561, 'epoch': 59.851851851851855}
{'loss': 1241.16, 'learning_rate': 0.00011502552432498922, 'epoch': 60.148148148148145}
{'loss': 1301.06, 'learning_rate': 0.00011410295836152283, 'epoch': 60.44444444444444}
{'loss': 1343.1, 'learning_rate': 0.00011318039239805644, 'epoch': 60.74074074074074}
05/26/2024 03:34:45 - INFO - utils.utils -   using task specific params for movieTrivia: {'max_length': 128}
05/26/2024 03:35:51 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_loss = 1942.726318359375
05/26/2024 03:35:51 - INFO - third_party.trainers.t5_trainer -     movieTrivia_eval_micro_f1_score = 0.6775618374558304
05/26/2024 03:35:51 - INFO - utils.utils -   config is reset to the initial values.
05/26/2024 03:35:51 - INFO - utils.utils -   using task specific params for movie: {'max_length': 128}
05/26/2024 03:36:59 - INFO - third_party.trainers.t5_trainer -     movie_eval_loss = 1198.413818359375
05/26/2024 03:36:59 - INFO - third_party.trainers.t5_trainer -     movie_eval_micro_f1_score = 0.8628370457209847
05/26/2024 03:36:59 - INFO - utils.utils -   config is reset to the initial values.
05/26/2024 03:36:59 - INFO - utils.utils -   using task specific params for restaurant: {'max_length': 128}
05/26/2024 03:37:48 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_loss = 1068.05810546875
05/26/2024 03:37:48 - INFO - third_party.trainers.t5_trainer -     restaurant_eval_micro_f1_score = 0.7693303138142996
05/26/2024 03:37:48 - INFO - utils.utils -   config is reset to the initial values.
05/26/2024 03:37:48 - INFO - utils.utils -   using task specific params for atis: {'max_length': 128}
05/26/2024 03:38:32 - INFO - third_party.trainers.t5_trainer -     atis_eval_loss = 1836.0740966796875
05/26/2024 03:38:32 - INFO - third_party.trainers.t5_trainer -     atis_eval_micro_f1_score = 0.9777647747220597
05/26/2024 03:38:32 - INFO - utils.utils -   config is reset to the initial values.
05/26/2024 03:38:32 - INFO - utils.utils -   using task specific params for snips: {'max_length': 128}
05/26/2024 03:39:18 - INFO - third_party.trainers.t5_trainer -     snips_eval_loss = 1054.2860107421875
05/26/2024 03:39:18 - INFO - third_party.trainers.t5_trainer -     snips_eval_micro_f1_score = 0.9327777777777778
05/26/2024 03:39:18 - INFO - utils.utils -   config is reset to the initial values.
05/26/2024 03:39:18 - INFO - utils.utils -   using task specific params for mtod: {'max_length': 128}
05/26/2024 03:43:20 - INFO - third_party.trainers.t5_trainer -     mtod_eval_loss = 766.2920532226562
05/26/2024 03:43:20 - INFO - third_party.trainers.t5_trainer -     mtod_eval_micro_f1_score = 0.9608094627333619
05/26/2024 03:43:20 - INFO - utils.utils -   config is reset to the initial values.
05/26/2024 03:43:20 - INFO - utils.utils -   using task specific params for mtop: {'max_length': 128}
05/26/2024 03:45:52 - INFO - third_party.trainers.t5_trainer -     mtop_eval_loss = 1094.868408203125
05/26/2024 03:45:52 - INFO - third_party.trainers.t5_trainer -     mtop_eval_micro_f1_score = 0.8574018909467686
05/26/2024 03:45:52 - INFO - utils.utils -   config is reset to the initial values.
/home/jesus.ortizbarajas/.conda/envs/hyperformer/lib/python3.8/site-packages/torch-1.7.0+cu110-py3.8-linux-x86_64.egg/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
{'loss': 1285.7, 'learning_rate': 0.00011225782643459005, 'epoch': 61.03703703703704}
slurmstepd-gpu-16: error: *** JOB 443683 ON gpu-16 CANCELLED AT 2024-05-26T03:47:55 DUE TO TIME LIMIT ***
